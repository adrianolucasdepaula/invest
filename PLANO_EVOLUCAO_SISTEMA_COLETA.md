# PLANO DE EVOLUÃ‡ÃƒO DO SISTEMA DE COLETA DE DADOS

**Data:** 2025-12-02
**VersÃ£o:** 1.0
**Objetivo:** Aumentar confianÃ§a de 2 para 3+ fontes com rastreamento completo de origem dos dados

---

## ğŸ“Š DIAGNÃ“STICO DO SISTEMA ATUAL

### ConfiguraÃ§Ã£o Atual
```typescript
// scrapers.service.ts
MIN_SOURCES = 2  // Reduzido de 3 para 2
MIN_CONFIDENCE = 0.5  // Reduzido de 0.7 para 0.5

// Scrapers ativos (6 total):
1. fundamentus    âŒ NÃƒO requer login
2. brapi          âŒ NÃƒO requer login (API Key)
3. statusinvest   âŒ NÃƒO requer login
4. investidor10   âŒ NÃƒO requer login
5. fundamentei    âœ… REQUER Google OAuth
6. investsite     âŒ NÃƒO requer login
```

### Problema do "Early Exit"
```typescript
// Linha 73-77 de scrapers.service.ts
if (successfulResults.length >= this.minSources) {
  this.logger.debug(`Got ${successfulResults.length} sources, stopping early`);
  break;  // âš ï¸ Para com apenas 2 fontes!
}
```

**Impacto:** Sistema para de coletar apÃ³s obter 2 fontes, mesmo tendo 6 disponÃ­veis.

### Armazenamento Atual de Metadados
```typescript
// FundamentalData.metadata (JSONB)
{
  sources: ["fundamentus", "brapi"],       // âœ… Lista de fontes
  sourcesCount: 2,                         // âœ… Quantidade
  confidence: 0.67,                        // âœ… ConfianÃ§a geral
  discrepancies: [...],                    // âœ… DiscrepÃ¢ncias
  rawData: {...}                           // âš ï¸ Dados brutos misturados
}
```

**Problema:** NÃ£o hÃ¡ rastreamento de QUAL fonte forneceu QUAL campo especÃ­fico.

---

## ğŸ¯ OBJETIVOS DO PLANO

### Objetivos PrimÃ¡rios
1. **Aumentar mÃ­nimo de fontes de 2 para 3** para maior confianÃ§a
2. **Rastrear origem de cada campo individualmente**
3. **Implementar sistema de priorizaÃ§Ã£o de fontes por campo**
4. **Criar visualizaÃ§Ã£o de proveniÃªncia dos dados no frontend**

### Objetivos SecundÃ¡rios
5. **Remover early exit** para coletar de TODAS as fontes disponÃ­veis
6. **Implementar merge inteligente** (mediana em vez de primeiro valor)
7. **Detectar e alertar sobre outliers** por fonte
8. **Dashboard de qualidade de dados** por scraper

---

## ğŸ“‹ FASES DE IMPLEMENTAÃ‡ÃƒO

### FASE 1: Rastreamento de Origem por Campo (2-3 dias)

#### 1.1 Nova Estrutura de Dados
```typescript
// Novo tipo para rastreamento granular
interface FieldSourceInfo {
  value: number | string | null;
  source: string;
  scrapedAt: Date;
  confidence?: number;
}

interface FundamentalDataWithProvenance {
  // Campo com rastreamento
  pl: {
    value: number;
    sources: FieldSourceInfo[];
    finalSource: string;       // Fonte escolhida para o valor final
    consensus: number;         // % de fontes que concordam
    variance: number;          // VariÃ¢ncia entre fontes
  };
  // ... outros campos
}
```

#### 1.2 AlteraÃ§Ã£o na Entity FundamentalData
```typescript
// fundamental-data.entity.ts - Adicionar nova coluna
@Column({ type: 'jsonb', name: 'field_sources', nullable: true })
fieldSources: Record<string, {
  values: Array<{
    source: string;
    value: number | null;
    scrapedAt: string;
  }>;
  finalValue: number | null;
  finalSource: string;
  sourcesCount: number;
  variance: number;
}>;
```

#### 1.3 Migration
```sql
-- Migration: AddFieldSourcesToFundamentalData
ALTER TABLE fundamental_data
ADD COLUMN field_sources JSONB DEFAULT '{}';

-- Ãndice para queries por fonte
CREATE INDEX idx_fundamental_data_field_sources
ON fundamental_data USING GIN (field_sources);
```

#### 1.4 Tarefas
- [ ] Criar migration para nova coluna `field_sources`
- [ ] Atualizar `FundamentalData` entity
- [ ] Criar interface `FieldSourceInfo`
- [ ] Atualizar `saveFundamentalData()` para popular `field_sources`

---

### FASE 2: Coleta Completa de Todas as Fontes (1-2 dias)

#### 2.1 Remover Early Exit
```typescript
// scrapers.service.ts - ANTES
for (const { name, scraper } of scrapers) {
  // ...
  if (successfulResults.length >= this.minSources) {
    break;  // âŒ REMOVER ISSO
  }
}

// DEPOIS
for (const { name, scraper } of scrapers) {
  try {
    const result = await scraper.scrape(ticker);
    if (result.success) {
      successfulResults.push(result);
    }
  } catch (error) {
    this.logger.debug(`[${ticker}] ${name}: ERROR`);
  }
  // âœ… Continua para TODAS as fontes
}
```

#### 2.2 Aumentar MÃ­nimo para 3
```typescript
// .env
MIN_DATA_SOURCES=3

// scrapers.service.ts
this.minSources = this.configService.get<number>('MIN_DATA_SOURCES', 3);
```

#### 2.3 Tarefas
- [ ] Remover early exit do loop de scrapers
- [ ] Atualizar MIN_DATA_SOURCES para 3
- [ ] Ajustar testes unitÃ¡rios
- [ ] Validar que todos 6 scrapers sÃ£o consultados

---

### FASE 3: Merge Inteligente de Dados (2-3 dias)

#### 3.1 EstratÃ©gias de Merge por Tipo de Campo
```typescript
enum MergeStrategy {
  MEDIAN = 'median',           // Para valores numÃ©ricos (mais robusto)
  AVERAGE = 'average',         // Para valores menos volÃ¡teis
  MOST_RECENT = 'most_recent', // Para dados que mudam frequentemente
  CONSENSUS = 'consensus',     // Para campos categÃ³ricos
  PRIORITY = 'priority',       // Para campos com fonte preferencial
}

// ConfiguraÃ§Ã£o por campo
const fieldMergeConfig: Record<string, MergeStrategy> = {
  // Valuation - usar MEDIANA (robusto a outliers)
  pl: MergeStrategy.MEDIAN,
  pvp: MergeStrategy.MEDIAN,
  psr: MergeStrategy.MEDIAN,
  evEbit: MergeStrategy.MEDIAN,
  evEbitda: MergeStrategy.MEDIAN,

  // Rentabilidade - usar MEDIANA
  roe: MergeStrategy.MEDIAN,
  roic: MergeStrategy.MEDIAN,
  roa: MergeStrategy.MEDIAN,

  // Margens - usar MEDIANA
  margemBruta: MergeStrategy.MEDIAN,
  margemEbit: MergeStrategy.MEDIAN,
  margemLiquida: MergeStrategy.MEDIAN,

  // Dividendos - usar AVERAGE (menos variaÃ§Ã£o)
  dividendYield: MergeStrategy.AVERAGE,
  payout: MergeStrategy.AVERAGE,

  // Financials (valores absolutos) - usar PRIORITY
  receitaLiquida: MergeStrategy.PRIORITY,
  lucroLiquido: MergeStrategy.PRIORITY,
  patrimonioLiquido: MergeStrategy.PRIORITY,

  // ClassificaÃ§Ã£o - usar CONSENSUS
  sector: MergeStrategy.CONSENSUS,
  subsector: MergeStrategy.CONSENSUS,
};

// Prioridade de fontes para estratÃ©gia PRIORITY
const sourcePriority = [
  'fundamentus',   // 1Âº - Mais completo
  'statusinvest',  // 2Âº - Boa qualidade
  'investidor10',  // 3Âº - Dados extras
  'brapi',         // 4Âº - API oficial
  'investsite',    // 5Âº - Backup
  'fundamentei',   // 6Âº - Requer login
];
```

#### 3.2 ImplementaÃ§Ã£o do Merge
```typescript
private mergeFieldValues(
  fieldName: string,
  values: Array<{ source: string; value: number | null }>
): { finalValue: number; finalSource: string; variance: number } {
  const strategy = fieldMergeConfig[fieldName] || MergeStrategy.MEDIAN;
  const validValues = values.filter(v => v.value !== null && !isNaN(v.value));

  if (validValues.length === 0) {
    return { finalValue: null, finalSource: 'none', variance: 0 };
  }

  switch (strategy) {
    case MergeStrategy.MEDIAN:
      return this.calculateMedian(validValues);

    case MergeStrategy.AVERAGE:
      return this.calculateAverage(validValues);

    case MergeStrategy.PRIORITY:
      return this.selectByPriority(validValues);

    case MergeStrategy.MOST_RECENT:
      return this.selectMostRecent(validValues);

    default:
      return this.calculateMedian(validValues);
  }
}

private calculateMedian(values: Array<{ source: string; value: number }>): {...} {
  const sorted = values.map(v => v.value).sort((a, b) => a - b);
  const mid = Math.floor(sorted.length / 2);

  const medianValue = sorted.length % 2 === 0
    ? (sorted[mid - 1] + sorted[mid]) / 2
    : sorted[mid];

  // Encontrar qual fonte tem o valor mais prÃ³ximo da mediana
  const closestSource = values.reduce((prev, curr) =>
    Math.abs(curr.value - medianValue) < Math.abs(prev.value - medianValue)
      ? curr : prev
  );

  // Calcular variÃ¢ncia
  const variance = this.calculateVariance(sorted);

  return {
    finalValue: medianValue,
    finalSource: closestSource.source,
    variance,
  };
}
```

#### 3.3 Tarefas
- [ ] Criar enum `MergeStrategy`
- [ ] Definir configuraÃ§Ã£o de merge por campo
- [ ] Implementar `mergeFieldValues()`
- [ ] Implementar `calculateMedian()`, `calculateAverage()`, etc.
- [ ] Atualizar `crossValidateData()` para usar novo merge
- [ ] Adicionar logs de decisÃ£o de merge

---

### FASE 4: API e Frontend de ProveniÃªncia (2-3 dias)

#### 4.1 Novo Endpoint de Detalhes de Fontes
```typescript
// assets.controller.ts
@Get(':ticker/data-sources')
@ApiOperation({ summary: 'Get data sources for an asset' })
async getAssetDataSources(@Param('ticker') ticker: string) {
  return this.assetsService.getDataSources(ticker);
}

// Response
{
  ticker: "PETR4",
  lastUpdate: "2025-12-02T10:30:00Z",
  overallConfidence: 0.85,
  sourcesUsed: ["fundamentus", "statusinvest", "investidor10"],
  fields: {
    pl: {
      finalValue: 5.42,
      finalSource: "fundamentus",
      allValues: [
        { source: "fundamentus", value: 5.42 },
        { source: "statusinvest", value: 5.45 },
        { source: "investidor10", value: 5.38 }
      ],
      consensus: 100,  // % de fontes com valor similar
      variance: 0.012
    },
    // ... outros campos
  }
}
```

#### 4.2 Componente React de ProveniÃªncia
```tsx
// components/DataSourceIndicator.tsx
interface DataSourceIndicatorProps {
  fieldName: string;
  sources: FieldSourceInfo[];
  finalSource: string;
  consensus: number;
}

export function DataSourceIndicator({
  fieldName, sources, finalSource, consensus
}: DataSourceIndicatorProps) {
  return (
    <Tooltip content={
      <div>
        <p className="font-bold">Fontes para {fieldName}:</p>
        {sources.map(s => (
          <p key={s.source}>
            {s.source}: {s.value}
            {s.source === finalSource && " âœ“"}
          </p>
        ))}
        <p className="text-xs mt-2">Consenso: {consensus}%</p>
      </div>
    }>
      <Badge variant={consensus >= 80 ? "success" : consensus >= 50 ? "warning" : "destructive"}>
        {sources.length} fontes
      </Badge>
    </Tooltip>
  );
}
```

#### 4.3 AtualizaÃ§Ã£o da PÃ¡gina de Ativos
```tsx
// assets/[ticker]/page.tsx
<Card>
  <CardHeader>
    <CardTitle>Indicadores Fundamentalistas</CardTitle>
    <Badge variant="outline">
      {fundamentalData.metadata.sourcesCount} fontes
    </Badge>
  </CardHeader>
  <CardContent>
    <Table>
      <TableBody>
        <TableRow>
          <TableCell>P/L</TableCell>
          <TableCell>{fundamentalData.pl}</TableCell>
          <TableCell>
            <DataSourceIndicator
              fieldName="P/L"
              sources={fundamentalData.fieldSources?.pl?.values}
              finalSource={fundamentalData.fieldSources?.pl?.finalSource}
              consensus={calculateConsensus(fundamentalData.fieldSources?.pl)}
            />
          </TableCell>
        </TableRow>
        {/* ... outros indicadores */}
      </TableBody>
    </Table>
  </CardContent>
</Card>
```

#### 4.4 Tarefas
- [ ] Criar endpoint GET `/assets/:ticker/data-sources`
- [ ] Criar DTO de resposta `AssetDataSourcesDto`
- [ ] Criar componente `DataSourceIndicator`
- [ ] Atualizar pÃ¡gina de detalhes do ativo
- [ ] Adicionar tooltip com detalhes por campo

---

### FASE 5: Dashboard de Qualidade de Scrapers (2-3 dias)

#### 5.1 Nova Entity para MÃ©tricas de Scrapers
```typescript
// scraper-metrics.entity.ts
@Entity('scraper_metrics')
export class ScraperMetrics {
  @PrimaryGeneratedColumn('uuid')
  id: string;

  @Column()
  scraperName: string;

  @Column({ type: 'date' })
  date: Date;

  @Column({ type: 'int' })
  totalRequests: number;

  @Column({ type: 'int' })
  successfulRequests: number;

  @Column({ type: 'int' })
  failedRequests: number;

  @Column({ type: 'decimal', precision: 5, scale: 2 })
  successRate: number;

  @Column({ type: 'decimal', precision: 10, scale: 2 })
  avgResponseTime: number;

  @Column({ type: 'int' })
  outliersDetected: number;

  @Column({ type: 'jsonb', nullable: true })
  fieldCoverage: Record<string, number>;  // % de campos preenchidos

  @CreateDateColumn()
  createdAt: Date;
}
```

#### 5.2 Dashboard de Qualidade
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUALIDADE DOS SCRAPERS                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Scraper         Taxa Sucesso   Tempo MÃ©dio   Cobertura    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  fundamentus     98.5%          2.3s          95%    â–ˆâ–ˆâ–ˆâ–ˆ  â”‚
â”‚  statusinvest    97.2%          1.8s          92%    â–ˆâ–ˆâ–ˆâ–ˆ  â”‚
â”‚  investidor10    96.8%          2.1s          88%    â–ˆâ–ˆâ–ˆ   â”‚
â”‚  brapi           94.5%          3.5s          75%    â–ˆâ–ˆâ–ˆ   â”‚
â”‚  investsite      93.2%          2.5s          70%    â–ˆâ–ˆ    â”‚
â”‚  fundamentei     85.0%          4.2s          65%    â–ˆâ–ˆ    â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Campos com Maior DiscrepÃ¢ncia (Ãºltimos 7 dias)     â”‚   â”‚
â”‚  â”‚  â€¢ EV/EBITDA: 15% variÃ¢ncia mÃ©dia                   â”‚   â”‚
â”‚  â”‚  â€¢ ROE: 12% variÃ¢ncia mÃ©dia                         â”‚   â”‚
â”‚  â”‚  â€¢ Margem LÃ­quida: 10% variÃ¢ncia mÃ©dia              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.3 Tarefas
- [ ] Criar entity `ScraperMetrics`
- [ ] Criar migration para tabela `scraper_metrics`
- [ ] Implementar coleta de mÃ©tricas em `ScrapersService`
- [ ] Criar endpoint GET `/scrapers/metrics`
- [ ] Criar pÃ¡gina `/admin/scrapers-quality`
- [ ] Implementar grÃ¡ficos de tendÃªncia

---

### FASE 6: DetecÃ§Ã£o de Outliers e Alertas (2 dias)

#### 6.1 Sistema de DetecÃ§Ã£o de Outliers
```typescript
// outlier-detection.service.ts
@Injectable()
export class OutlierDetectionService {
  private readonly ZSCORE_THRESHOLD = 2.5;  // 2.5 desvios padrÃ£o

  detectOutliers(
    fieldName: string,
    values: Array<{ source: string; value: number }>
  ): Array<{ source: string; value: number; isOutlier: boolean; zScore: number }> {
    const validValues = values.filter(v => v.value !== null);
    if (validValues.length < 3) return validValues.map(v => ({ ...v, isOutlier: false, zScore: 0 }));

    const mean = validValues.reduce((sum, v) => sum + v.value, 0) / validValues.length;
    const stdDev = Math.sqrt(
      validValues.reduce((sum, v) => sum + Math.pow(v.value - mean, 2), 0) / validValues.length
    );

    return validValues.map(v => {
      const zScore = stdDev > 0 ? (v.value - mean) / stdDev : 0;
      return {
        ...v,
        isOutlier: Math.abs(zScore) > this.ZSCORE_THRESHOLD,
        zScore,
      };
    });
  }
}
```

#### 6.2 Sistema de Alertas
```typescript
// alerts.service.ts
enum AlertType {
  HIGH_VARIANCE = 'high_variance',
  SCRAPER_DOWN = 'scraper_down',
  INSUFFICIENT_SOURCES = 'insufficient_sources',
  OUTLIER_DETECTED = 'outlier_detected',
}

interface DataAlert {
  type: AlertType;
  ticker?: string;
  scraper?: string;
  field?: string;
  message: string;
  severity: 'low' | 'medium' | 'high';
  createdAt: Date;
}
```

#### 6.3 Tarefas
- [ ] Criar `OutlierDetectionService`
- [ ] Integrar detecÃ§Ã£o no fluxo de merge
- [ ] Criar entity `DataAlert`
- [ ] Implementar notificaÃ§Ãµes WebSocket
- [ ] Criar pÃ¡gina de alertas no frontend

---

## ğŸ“… CRONOGRAMA SUGERIDO

```
Semana 1:
â”œâ”€â”€ Dia 1-2: FASE 1 - Rastreamento de Origem
â”œâ”€â”€ Dia 3:   FASE 2 - Coleta Completa
â””â”€â”€ Dia 4-5: FASE 3 - Merge Inteligente

Semana 2:
â”œâ”€â”€ Dia 1-3: FASE 4 - API e Frontend
â”œâ”€â”€ Dia 4-5: FASE 5 - Dashboard de Qualidade

Semana 3:
â”œâ”€â”€ Dia 1-2: FASE 6 - Outliers e Alertas
â”œâ”€â”€ Dia 3:   Testes de integraÃ§Ã£o
â”œâ”€â”€ Dia 4:   DocumentaÃ§Ã£o
â””â”€â”€ Dia 5:   Deploy e monitoramento
```

---

## ğŸ”§ ARQUIVOS A MODIFICAR

### Backend
```
backend/src/
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ scrapers.service.ts          # Remover early exit, novo merge
â”‚   â”œâ”€â”€ outlier-detection.service.ts # NOVO
â”‚   â””â”€â”€ scraper-metrics.service.ts   # NOVO
â”œâ”€â”€ api/assets/
â”‚   â”œâ”€â”€ assets.controller.ts         # Novo endpoint data-sources
â”‚   â””â”€â”€ assets.service.ts            # MÃ©todo getDataSources
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”œâ”€â”€ fundamental-data.entity.ts  # Adicionar field_sources
â”‚   â”‚   â”œâ”€â”€ scraper-metrics.entity.ts   # NOVO
â”‚   â”‚   â””â”€â”€ data-alert.entity.ts        # NOVO
â”‚   â””â”€â”€ migrations/
â”‚       â””â”€â”€ XXXXXX-AddFieldSources.ts   # NOVA
â””â”€â”€ websocket/
    â””â”€â”€ websocket.gateway.ts         # Eventos de alerta
```

### Frontend
```
frontend/src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ data-source-indicator.tsx  # NOVO
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ fundamental-table.tsx      # Atualizar
â”œâ”€â”€ app/(dashboard)/
â”‚   â”œâ”€â”€ assets/[ticker]/
â”‚   â”‚   â””â”€â”€ page.tsx                   # Adicionar indicadores
â”‚   â””â”€â”€ admin/
â”‚       â””â”€â”€ scrapers-quality/
â”‚           â””â”€â”€ page.tsx               # NOVO
â””â”€â”€ lib/
    â””â”€â”€ api.ts                         # Novo endpoint
```

---

## ğŸ“Š MÃ‰TRICAS DE SUCESSO

### KPIs do Projeto
| MÃ©trica | Atual | Meta |
|---------|-------|------|
| Fontes mÃ­nimas | 2 | 3 |
| Fontes mÃ©dias usadas | ~2.1 | 4+ |
| ConfianÃ§a mÃ©dia | 0.55 | 0.75+ |
| Campos com rastreamento | 0% | 100% |
| Tempo mÃ©dio de coleta | ~8s | <15s |

### CritÃ©rios de Aceite
- [ ] Todos os 6 scrapers sÃ£o consultados em cada atualizaÃ§Ã£o
- [ ] Cada campo tem origem rastreada em `field_sources`
- [ ] Frontend mostra indicador de fontes por campo
- [ ] Dashboard de qualidade funcionando
- [ ] Alertas de outliers funcionando
- [ ] DocumentaÃ§Ã£o atualizada

---

## âš ï¸ RISCOS E MITIGAÃ‡Ã•ES

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|--------------|---------|-----------|
| Aumento do tempo de coleta | Alta | MÃ©dio | Paralelizar scrapers sem login |
| Mais falhas por scraper | MÃ©dia | Baixo | Sistema jÃ¡ tolerante a falhas |
| Complexidade do merge | MÃ©dia | MÃ©dio | Testes unitÃ¡rios extensivos |
| Performance do JSONB | Baixa | Alto | Ãndices GIN, queries otimizadas |

---

## ğŸ“š REFERÃŠNCIAS

- `scrapers.service.ts:40-87` - Fluxo atual de coleta
- `assets-update.service.ts:548-616` - Salvamento de dados
- `fundamental-data.entity.ts` - Estrutura atual
- `MAPEAMENTO_FONTES_DADOS_COMPLETO.md` - Campos por fonte

---

*Documento criado em 2025-12-02 - VersÃ£o 1.0*
