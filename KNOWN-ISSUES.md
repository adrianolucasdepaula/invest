# üîç KNOWN ISSUES - B3 AI Analysis Platform

**Projeto:** B3 AI Analysis Platform (invest-claude-web)
**√öltima Atualiza√ß√£o:** 2025-11-29
**Vers√£o:** 1.1.0
**Mantenedor:** Claude Code (Opus 4.5)

---

## üìã √çNDICE

1. [Vis√£o Geral](#vis√£o-geral)
2. [Issues Ativos (N√ÉO Resolvidos)](#issues-ativos-n√£o-resolvidos)
3. [Issues Resolvidos](#issues-resolvidos)
4. [Li√ß√µes Aprendidas](#li√ß√µes-aprendidas)
5. [Procedimentos de Recupera√ß√£o](#procedimentos-de-recupera√ß√£o)
6. [Checklist de Preven√ß√£o](#checklist-de-preven√ß√£o)

---

## üéØ VIS√ÉO GERAL

Este documento centraliza **todos os problemas conhecidos** encontrados durante o desenvolvimento e opera√ß√£o da plataforma, incluindo:

- ‚úÖ Root cause analysis completa
- ‚úÖ Solu√ß√µes aplicadas ou workarounds tempor√°rios
- ‚úÖ Procedimentos de recupera√ß√£o
- ‚úÖ Li√ß√µes aprendidas
- ‚úÖ Checklist de preven√ß√£o

**Refer√™ncia Detalhada:** Ver `.gemini/context/known-issues.md` para an√°lise t√©cnica aprofundada.

---

## üî¥ ISSUES ATIVOS (N√ÉO RESOLVIDOS)

*Nenhum issue cr√≠tico em aberto no momento.*

---

## ‚úÖ ISSUES RESOLVIDOS

### Resumo de Issues Resolvidos

| Issue | Descri√ß√£o | Severidade | Data Resolu√ß√£o | Documenta√ß√£o |
|-------|-----------|-----------|----------------|--------------|
| #5 | Popula√ß√£o de Dados Ap√≥s Database Wipe | üî¥ Cr√≠tica | 2025-12-04 | `scripts/backup-db.ps1`, `scripts/restore-db.ps1` |
| #4 | Frontend Cache - Docker Volume | üî¥ Cr√≠tica | 2025-12-04 | `docker-compose.yml` (volume removed) |
| #NEW | Valida√ß√£o Visual Final da UI de Op√ß√µes | üü° M√©dia | 2025-12-04 | `VALIDACAO_UI_OPCOES_2025-12-04.md` |
| #1 | Incorrect Login Selectors (OpcoesScraper) | üî¥ Alta | 2025-11-24 | `.gemini/context/known-issues.md` #1 |
| #2 | Pagination Only First Page | üî¥ Alta | 2025-11-24 | `.gemini/context/known-issues.md` #2 |
| #3 | TypeScript Error on Element Click | üü° M√©dia | 2025-11-24 | `.gemini/context/known-issues.md` #3 |
| #6 | JWT Authentication Errors | üü° M√©dia | 2025-11-24 | `.gemini/context/known-issues.md` #6 |
| #7 | Sync Reporting 0 Updates | üü¢ Baixa | 2025-11-24 | `.gemini/context/known-issues.md` #7 |
| #8 | Migration Already Applied Error | üü° M√©dia | 2025-11-24 | `.gemini/context/known-issues.md` #8 |
| #BUG1 | Resource Leak in Python Script | üî¥ Cr√≠tica | 2025-11-25 | `CHANGELOG.md` v1.2.1 |
| #BUG2 | Crash on Invalid Date (Seed) | üî¥ Cr√≠tica | 2025-11-25 | `CHANGELOG.md` v1.2.1 |
| #BUG3 | TypeError on null stock_type | üî¥ Cr√≠tica | 2025-11-25 | `CHANGELOG.md` v1.2.1 |
| #BUG4 | Silent Invalid Date (Ticker Changes) | üî¥ Cr√≠tica | 2025-11-25 | `CHANGELOG.md` v1.2.1 |
| #BUG5 | Broken DTO Validation (Sync Bulk) | üî¥ Cr√≠tica | 2025-11-25 | `CHANGELOG.md` v1.2.1 |
| #EXIT137 | Exit Code 137 (SIGKILL) - Python Scrapers | üî¥ Cr√≠tica | 2025-11-28 | `ERROR_137_ANALYSIS.md`, `FASE_ATUAL_SUMMARY.md` |

**Total Resolvidos:** 15 issues
**Comportamento Normal:** 1 (n√£o √© bug, √© comportamento esperado - Issue #7)
**Taxa de Resolu√ß√£o:** 100% (15/15 issues reais)

---

### Issue #EXIT137: Exit Code 137 (SIGKILL) - Python Scrapers

**Severidade:** üî¥ **CR√çTICA**
**Status:** ‚úÖ **RESOLVIDO DEFINITIVAMENTE**
**Data Identificado:** 2025-11-28
**Data Resolu√ß√£o:** 2025-11-28
**Tempo de Resolu√ß√£o:** ~8 horas (an√°lise + solu√ß√£o + valida√ß√£o)

#### Sintomas

- Processo Python morto abruptamente com **Exit Code 137 (SIGKILL)**
- Container `invest_scrapers` executava sem mensagens de erro Python
- Morte ocorria ap√≥s ~8 segundos de extra√ß√£o de dados
- Nenhum stack trace ou mensagem de erro capturada
- Taxa de sucesso: **0%** (100% dos scrapes falhavam)

#### Hip√≥tese Inicial (REFUTADA)

**Hip√≥tese:** OOM (Out of Memory) Killer estava matando processo por excesso de mem√≥ria.

**Evid√™ncia que refutou:**
- Monitoramento revelou uso m√°ximo de **376MB de 4GB dispon√≠veis** (9.4%)
- Testes com 2GB e 4GB de memory limit: resultado id√™ntico
- Logs do sistema n√£o mostravam mensagens de OOM killer
- Mem√≥ria est√°vel durante toda execu√ß√£o

**Conclus√£o:** N√ÉO era problema de mem√≥ria.

#### Root Cause Identificado

**Causa Real:** M√∫ltiplas opera√ß√µes `await` lentas durante extra√ß√£o de dados.

**An√°lise T√©cnica:**

```python
# ‚ùå PADR√ÉO ANTIGO (Selenium adaptado para Playwright)
# Problema: 50 campos √ó m√∫ltiplos awaits √ó 140ms cada = ~35 segundos

tables = await page.query_selector_all("table")  # await #1
for table in tables:
    rows = await table.query_selector_all("tr")  # await #2
    for row in rows:
        cells = await row.query_selector_all("td")  # await #3
        label = await cells[0].text_content()  # await #4
        value = await cells[1].text_content()  # await #5
```

**Timeline de Eventos:**
1. **0.0s:** Inicializa√ß√£o Playwright (~0.7s)
2. **0.7s:** Navega√ß√£o para URL (~3s)
3. **3.7s:** In√≠cio extra√ß√£o de dados
4. **3.7s - 11.7s:** M√∫ltiplos awaits (140ms cada) = timeout/SIGKILL
5. **~11.7s:** Container mata processo (Exit 137)

**Problema:** Opera√ß√µes lentas acumuladas causando timeout e morte do processo.

#### Solu√ß√£o Implementada

**Padr√£o BeautifulSoup Single Fetch:**

```python
# ‚úÖ PADR√ÉO NOVO (Otimizado com BeautifulSoup)
# Solu√ß√£o: 1 await apenas + parsing local = ~7.72 segundos

from bs4 import BeautifulSoup

# OPTIMIZATION: Single HTML fetch
html_content = await self.page.content()  # await #1 (√öNICO)
soup = BeautifulSoup(html_content, 'html.parser')

# ALL parsing is local (NO await operations)
tables = soup.select("table")  # Local, instant√¢neo
for table in tables:
    rows = table.select("tr")  # Local, instant√¢neo
    for row in rows:
        cells = row.select("td")  # Local, instant√¢neo
        label = cells[0].get_text()  # Local, instant√¢neo
        value = cells[1].get_text()  # Local, instant√¢neo
```

**Resultado:**
- **Performance:** ~10x mais r√°pido (7.72s vs timeout)
- **Taxa de sucesso:** 0% ‚Üí **100%**
- **Mem√≥ria:** Est√°vel em 376MB (sem aumento)
- **Reprodutibilidade:** 100% (testado 10+ vezes)

#### Mudan√ßas Implementadas

**1. base_scraper.py** - Refatora√ß√£o da arquitetura
- Browser individual (n√£o compartilhado) - alinhado com backend TypeScript
- `asyncio.Lock` criado em async context (n√£o `__init__`)
- Cleanup completo: page + browser + playwright

**2. fundamentus_scraper.py** - Otimiza√ß√£o BeautifulSoup
- Single HTML fetch implementado
- 30 campos extra√≠dos com sucesso
- Tempo: 7.72s (validado com PETR4)

**3. bcb_scraper.py** - Web fallback otimizado
- API-first (17 indicadores via BCB SGS API)
- Web fallback com BeautifulSoup single fetch
- Tempo: <1s (API), ~3s (web)

**4. Documenta√ß√£o Criada**
- `PLAYWRIGHT_SCRAPER_PATTERN.md` (849 linhas) - Template standardizado
- `VALIDACAO_MIGRACAO_PLAYWRIGHT.md` (643 linhas) - Relat√≥rio valida√ß√£o
- `ERROR_137_ANALYSIS.md` (393 linhas) - An√°lise t√©cnica
- `FASE_ATUAL_SUMMARY.md` (351 linhas) - Executive summary

#### M√©tricas de Performance

| M√©trica | Antes (Selenium) | Depois (Playwright) | Melhoria |
|---------|------------------|---------------------|----------|
| **Inicializa√ß√£o** | ~1.5s | ~0.7s | 2x ‚ö° |
| **Navega√ß√£o** | ~5s | ~3s | 1.67x ‚ö° |
| **Extra√ß√£o** | Timeout (>14s) | 7.72s | Funcional ‚úÖ |
| **Taxa de sucesso** | 0% (Exit 137) | 100% | ‚àû üéâ |
| **Mem√≥ria** | N/A | 376MB max | Est√°vel üìä |

#### Li√ß√µes Aprendidas Cr√≠ticas

1. **Exit 137 ‚â† OOM**: SIGKILL pode ser causado por performance (timeout), n√£o apenas mem√≥ria
2. **Monitorar Performance**: Timeline de eventos √© essencial para debug
3. **BeautifulSoup √© ~10x Mais R√°pido**: Single fetch + local parsing >> m√∫ltiplos awaits
4. **Seguir Padr√£o do Backend**: Alinhar com backend funcional antes de "otimizar"
5. **Async Strictness**: Python async tem regras estritas (event loop, Lock creation, etc)

#### Procedimento de Preven√ß√£o

**Para TODOS os novos scrapers Python:**

- ‚úÖ **SEMPRE** usar padr√£o BeautifulSoup single fetch
- ‚úÖ **NUNCA** usar m√∫ltiplas opera√ß√µes `await` em loops
- ‚úÖ Seguir template: `backend/python-scrapers/PLAYWRIGHT_SCRAPER_PATTERN.md`
- ‚úÖ Validar performance: meta <10s por scrape
- ‚úÖ Browser individual (n√£o compartilhado)
- ‚úÖ `wait_until='load'` (n√£o `'networkidle'`)

#### Refer√™ncias

- **Template:** `backend/python-scrapers/PLAYWRIGHT_SCRAPER_PATTERN.md`
- **Valida√ß√£o:** `backend/python-scrapers/VALIDACAO_MIGRACAO_PLAYWRIGHT.md`
- **An√°lise T√©cnica:** `backend/python-scrapers/ERROR_137_ANALYSIS.md`
- **Summary Executivo:** `FASE_ATUAL_SUMMARY.md`
- **Changelog:** `CHANGELOG.md` v1.3.0

---

## üìö LI√á√ïES APRENDIDAS

### 1. Docker Volume Management

#### Entender Escopo de Volumes

```yaml
volumes:
  postgres_data:          # üî¥ Dados persistentes - BACKUP obrigat√≥rio
  redis_data:             # üü° Cache - Pode recriar sem perda
  frontend_next:          # üü¢ Build cache - Pode limpar
  backend_node_modules:   # üü¢ Depend√™ncias - Reinstal√°vel
  frontend_node_modules:  # üü¢ Depend√™ncias - Reinstal√°vel
```

#### Limpeza Targeted (N√ÉO Destrutiva)

```bash
# ‚úÖ CORRETO: Remove APENAS cache do frontend
docker stop invest_frontend
docker volume rm invest-claude-web_frontend_next
docker-compose up -d --build frontend

# ‚ùå ERRADO: Remove TUDO (incluindo database!)
docker-compose down -v  # NUNCA USAR EM PRODU√á√ÉO
```

#### Verificar Antes de Destruir

```bash
# Listar volumes
docker volume ls

# Inspecionar volume espec√≠fico
docker volume inspect invest-claude-web_postgres_data

# Ver uso de espa√ßo
docker system df -v
```

---

### 2. Scraper Development

#### Checklist de Desenvolvimento

- [x] ‚úÖ Implementar pagina√ß√£o desde o in√≠cio
- [x] ‚úÖ Adicionar logging detalhado em cada etapa
- [x] ‚úÖ Usar m√∫ltiplas estrat√©gias de seletores (sites mudam)
- [x] ‚úÖ Testar com navega√ß√£o real (n√£o s√≥ primeira p√°gina)
- [x] ‚úÖ Validar HTML real da p√°gina antes de escrever c√≥digo
- [x] ‚úÖ Usar IDs quando dispon√≠veis (mais est√°veis)
- [x] ‚úÖ Adicionar timeouts e retry logic
- [x] ‚úÖ Testar login isoladamente antes de integrar

#### Exemplo de Logging Adequado

```typescript
this.logger.log(`[OpcoesScraper] Starting login...`);
this.logger.log(`[OpcoesScraper] Waiting for #CPF selector...`);
this.logger.log(`[OpcoesScraper] Typing credentials...`);
this.logger.log(`[OpcoesScraper] Login successful!`);
this.logger.log(`[OpcoesScraper] Scraping page ${pageNum}...`);
this.logger.log(`[OpcoesScraper] Found ${allTickers.size} unique tickers`);
```

---

### 3. Frontend Development in Docker

#### Hot Reload N√£o √© Confi√°vel

- ‚úÖ Rebuild expl√≠cito ap√≥s mudan√ßas importantes
- ‚úÖ Verificar conte√∫do **dentro do container** antes de debugar c√≥digo
- ‚úÖ Usar `CHOKIDAR_USEPOLLING=true` para melhor detec√ß√£o
- ‚úÖ Limpar cache `.next` quando houver d√∫vida

```bash
# Verificar conte√∫do dentro do container
docker exec invest_frontend cat src/components/dashboard/asset-table.tsx | head -50

# Rebuild for√ßado
docker-compose up -d --build frontend
```

---

### 4. Database Operations

#### Regra de Ouro: SEMPRE Backup

```bash
# Backup ANTES de qualquer opera√ß√£o destrutiva
./scripts/backup-db.sh

# Validar backup foi criado
ls -lh backups/

# Testar restore em ambiente de teste
cat backups/backup_20251127.sql | docker exec -i invest_postgres_test psql -U invest_user invest_db_test
```

#### Migrations Idempotentes

```typescript
// ‚úÖ CORRETO: Verifica se coluna j√° existe
if (!(await queryRunner.hasColumn("assets", "has_options"))) {
  await queryRunner.addColumn("assets", new TableColumn({
    name: "has_options",
    type: "boolean",
    default: false,
  }));
}

// ‚ùå ERRADO: Sempre tenta adicionar
await queryRunner.addColumn("assets", ...);  // Erro se j√° existir
```

---

## üîß PROCEDIMENTOS DE RECUPERA√á√ÉO

### Frontend Cache Quebrado

```bash
# Procedimento Completo (5-10 minutos)

# 1. Parar frontend
docker stop invest_frontend

# 2. Limpar cache Next.js
docker volume rm invest-claude-web_frontend_next

# 3. Rebuild completo
docker-compose up -d --build frontend

# 4. Aguardar build completar (verificar logs)
docker logs invest_frontend --tail 100 --follow

# 5. Validar no browser (Ctrl+Shift+R para hard refresh)
# http://localhost:3100
```

---

### Database Perdido (Restore Completo)

```bash
# Procedimento Completo (30-60 minutos)

# OP√á√ÉO A: Restore de Backup (se existir)
cat backups/backup_20251127.sql | docker exec -i invest_postgres psql -U invest_user invest_db

# OP√á√ÉO B: Recria√ß√£o do Zero (sem backup)
# 1. Recriar containers
docker-compose up -d --build

# 2. Executar migrations
docker exec invest_backend npm run migration:run

# 3. Seed dados b√°sicos
docker exec invest_backend npm run seed

# 4. Re-popular assets (via UI - LENTO)
# Acessar: http://localhost:3100/assets
# Clicar: "Atualizar Todos"
# Aguardar: ~10-15 minutos

# 5. Validar popula√ß√£o
docker exec invest_postgres psql -U invest_user invest_db -c "SELECT COUNT(*) FROM assets;"
# Esperado: 861 (ativos B3 n√£o-fracion√°rios)
```

---

### Scraper N√£o Encontrando Todos os Dados

```bash
# 1. Verificar logs do scraper
docker logs invest_backend --tail 200 | grep OpcoesScraper

# 2. Procurar mensagens de pagina√ß√£o
# Esperado: "Scraping page 1...", "Scraping page 2...", etc.

# 3. Verificar contagem final
# Esperado: "Found 174 unique tickers with liquid options"

# 4. Se contagem baixa, validar manualmente
# https://opcoes.net.br/estudos/liquidez/opcoes
# Contar p√°ginas manualmente, comparar

# 5. Se persistir, inspecionar HTML da p√°gina
# Seletores podem ter mudado - atualizar c√≥digo do scraper
```

---

## ‚úÖ CHECKLIST DE PREVEN√á√ÉO

### Antes de Opera√ß√µes Destrutivas

**SEMPRE executar este checklist ANTES de qualquer comando destrutivo:**

- [ ] **Backup do database criado** (ou confirmado que √© ambiente de teste)
  ```bash
  ./scripts/backup-db.sh
  ls -lh backups/ | tail -5
  ```

- [ ] **Entender quais volumes ser√£o afetados**
  ```bash
  docker volume ls
  # Identificar volumes cr√≠ticos (postgres_data, redis_data)
  ```

- [ ] **Tentar solu√ß√£o targeted primeiro**
  ```bash
  # Exemplo: Limpar APENAS cache frontend
  docker volume rm invest-claude-web_frontend_next
  # N√ÉO usar: docker-compose down -v
  ```

- [ ] **Plano de recupera√ß√£o documentado**
  - Consultar este arquivo: `KNOWN-ISSUES.md` se√ß√£o "Procedimentos de Recupera√ß√£o"
  - Ter script de backup √† m√£o: `./scripts/backup-db.sh`

- [ ] **Commit/push de mudan√ßas de c√≥digo**
  ```bash
  git status  # Verificar mudan√ßas n√£o commitadas
  git add .
  git commit -m "chore: checkpoint before infrastructure changes"
  git push origin main
  ```

- [ ] **Comunicar ao time** (se aplic√°vel)
  - Avisar sobre downtime esperado
  - Confirmar ningu√©m est√° usando o ambiente

---

### Desenvolvimento de Scrapers

**Checklist antes de marcar scraper como "completo":**

- [ ] Pagina√ß√£o implementada e testada
- [ ] Logging detalhado em cada etapa
- [ ] M√∫ltiplas estrat√©gias de seletores CSS
- [ ] Testado com navega√ß√£o real (n√£o apenas primeira p√°gina)
- [ ] HTML da p√°gina validado (inspecionar Developer Tools)
- [ ] Retry logic para falhas transit√≥rias
- [ ] Timeout configurado adequadamente
- [ ] Login testado isoladamente (se aplic√°vel)
- [ ] Cross-validation com outras fontes
- [ ] Documentado no `DATA_SOURCES.md`

---

### Desenvolvimento Frontend em Docker

**Checklist antes de reportar "bug de hot reload":**

- [ ] Verificar arquivo dentro do container (n√£o apenas filesystem local)
  ```bash
  docker exec invest_frontend cat src/components/[arquivo].tsx | head -50
  ```

- [ ] Rebuild expl√≠cito testado
  ```bash
  docker-compose up -d --build frontend
  ```

- [ ] Cache `.next` limpo
  ```bash
  docker volume rm invest-claude-web_frontend_next
  ```

- [ ] Hard refresh no browser (Ctrl+Shift+R)

- [ ] Logs verificados
  ```bash
  docker logs invest_frontend --tail 100
  ```

- [ ] `CHOKIDAR_USEPOLLING=true` configurado no `docker-compose.yml`

---

## üìä M√âTRICAS DE PROBLEMAS

### Resumo Geral

| Categoria | Quantidade | Taxa de Resolu√ß√£o |
|-----------|-----------|------------------|
| **Total de Issues Documentados** | 16 | - |
| **Issues Resolvidos** | 15 | 100% |
| **Issues Ativos (Em Aberto)** | 0 | 0% |
| **Comportamento Normal (n√£o √© bug)** | 1 | N/A |

### Por Severidade

| Severidade | Total | Resolvidos | Em Aberto |
|-----------|-------|-----------|-----------|
| üî¥ **Cr√≠tica** | 9 | 9 | 0 |
| üü° **M√©dia** | 5 | 6 | 0 |
| üü¢ **Baixa** | 2 | 1 | 0 |

### Tempo M√©dio de Resolu√ß√£o

| Severidade | Tempo M√©dio |
|-----------|-------------|
| üî¥ Cr√≠tica | 2.5 horas* |
| üü° M√©dia | 15 minutos |
| üü¢ Baixa | N/A |

*Atualizado com Exit Code 137 (8 horas de resolu√ß√£o) - issue mais complexo do projeto

---

## üîó REFER√äNCIAS

### Documenta√ß√£o Relacionada

- **An√°lise T√©cnica Detalhada:** `.gemini/context/known-issues.md`
- **Troubleshooting Geral:** `TROUBLESHOOTING.md`
- **Changelog:** `CHANGELOG.md`
- **Architecture:** `ARCHITECTURE.md`
- **Docker Compose:** `docker-compose.yml`
- **System Manager:** `system-manager.ps1`

### Scripts de Recupera√ß√£o

- **Backup Database:** `scripts/backup-db.sh` (PENDENTE - criar)
- **Complete Restore:** `backend/src/database/seeds/complete-restore.seed.ts` (PENDENTE - criar)

---

## üìù CONTRIBUINDO

**Quando adicionar novo issue conhecido:**

1. Documentar em `.gemini/context/known-issues.md` (an√°lise t√©cnica)
2. Atualizar este arquivo `KNOWN-ISSUES.md` (resumo executivo)
3. Adicionar ao `CHANGELOG.md` se for bugfix
4. Atualizar m√©tricas de problemas
5. Commit com mensagem descritiva:
   ```bash
   git commit -m "docs: add known issue #XX - [descri√ß√£o curta]"
   ```

**Quando resolver issue:**

1. Atualizar status para ‚úÖ Resolvido
2. Documentar solu√ß√£o aplicada
3. Mover para se√ß√£o "Issues Resolvidos"
4. Atualizar m√©tricas
5. Commit:
   ```bash
   git commit -m "fix: resolve known issue #XX - [descri√ß√£o]"
   ```

---

**√öltima Atualiza√ß√£o:** 2025-12-04
**Pr√≥xima Revis√£o:** Ap√≥s resolu√ß√£o de issues #4 e #5
**Respons√°vel:** Claude Code (Opus 4.5)
