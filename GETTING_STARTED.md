# Getting Started - B3 AI Analysis Platform

Este guia irÃ¡ ajudÃ¡-lo a configurar e executar a plataforma localmente.

## PrÃ©-requisitos

- Node.js 20+
- Python 3.11+ (para scrapers)
- Docker & Docker Compose
- Git

## InstalaÃ§Ã£o RÃ¡pida com Docker

A maneira mais rÃ¡pida de comeÃ§ar Ã© usando Docker Compose:

```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd invest

# 2. Configure as variÃ¡veis de ambiente
cp .env.example .env
# Edite o .env com suas credenciais

# 3. Inicie todos os serviÃ§os
docker-compose up -d

# 4. Aguarde os serviÃ§os iniciarem (pode levar alguns minutos)
docker-compose logs -f
```

Acesse:
- Frontend: http://localhost:3100
- Backend API: http://localhost:3101
- API Docs: http://localhost:3101/api/docs
- PgAdmin: http://localhost:5150 (opcional, use profile dev)
- Redis Commander: http://localhost:8181 (opcional, use profile dev)

## InstalaÃ§Ã£o Manual (Desenvolvimento)

### 1. Backend

```bash
cd backend

# Instalar dependÃªncias
npm install

# Configurar variÃ¡veis de ambiente
cp ../.env.example .env
# Edite o .env conforme necessÃ¡rio

# Executar migrations
npm run migration:run

# Executar seeds (popular banco de dados)
npm run seed

# Iniciar em modo desenvolvimento
npm run start:dev
```

O backend estarÃ¡ rodando em http://localhost:3101

### 2. Frontend

```bash
cd frontend

# Instalar dependÃªncias
npm install

# Iniciar em modo desenvolvimento
npm run dev
```

O frontend estarÃ¡ rodando em http://localhost:3100

### 3. Banco de Dados (PostgreSQL + TimescaleDB)

Se vocÃª nÃ£o estiver usando Docker, precisarÃ¡ instalar PostgreSQL com TimescaleDB:

```bash
# Instalar PostgreSQL 15+
# Instalar TimescaleDB extension

# Criar banco de dados
createdb invest_db

# Executar script de inicializaÃ§Ã£o
psql -U postgres -d invest_db -f database/init.sql
```

### 4. Redis

```bash
# Instalar Redis
# ou usar Docker:
docker run -d -p 6379:6379 redis:7-alpine
```

## ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente

### Backend (.env)

```env
# Database
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=invest_user
DB_PASSWORD=invest_password
DB_DATABASE=invest_db

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# JWT
JWT_SECRET=your-secret-key
JWT_EXPIRATION=7d

# Google OAuth (opcional - desabilitado automaticamente se nÃ£o configurado)
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
GOOGLE_CALLBACK_URL=http://localhost:3101/api/auth/google/callback
FRONTEND_URL=http://localhost:3100

# BRAPI
BRAPI_API_KEY=mVcy3EFZaBdza27tPQjdC1

# Scraping Credentials
OPCOES_USERNAME=your-username
OPCOES_PASSWORD=your-password

# Google Credentials para scrapers (opcional)
GOOGLE_EMAIL=your-email@gmail.com
GOOGLE_PASSWORD=your-password
```

### Frontend (.env.local)

```env
NEXT_PUBLIC_API_URL=http://localhost:3101/api
NEXT_PUBLIC_WS_URL=http://localhost:3101
```

## Configurando Google OAuth (Login Social)

O sistema suporta login com Google OAuth. Siga estes passos para habilitar:

### 1. Obter Credenciais do Google

1. Acesse: https://console.cloud.google.com/
2. Crie um projeto ou selecione um existente
3. VÃ¡ em **APIs & Services** > **Credentials**
4. Crie **OAuth 2.0 Client ID**:
   - **Application type**: Web application
   - **Authorized JavaScript origins**:
     - `http://localhost:3100`
     - `http://localhost:3101`
   - **Authorized redirect URIs**:
     - `http://localhost:3101/api/auth/google/callback`
5. Copie o **Client ID** e **Client Secret**

### 2. Configurar Backend

Edite `backend/.env`:

```env
GOOGLE_CLIENT_ID=seu-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=GOCSPX-seu-secret
GOOGLE_CALLBACK_URL=http://localhost:3101/api/auth/google/callback
FRONTEND_URL=http://localhost:3100
```

### 3. Testar Login

1. Inicie backend e frontend
2. Acesse: http://localhost:3100/login
3. Clique em **"Entrar com Google"**
4. Complete o fluxo OAuth
5. VocÃª serÃ¡ redirecionado para o dashboard

**ðŸ“š Guia completo**: Veja [SETUP_GUIDE.md](./SETUP_GUIDE.md#configuraÃ§Ã£o-do-google-oauth-login-social) para troubleshooting e detalhes.

## Populando o Banco de Dados

ApÃ³s configurar o backend, vocÃª pode popular o banco com dados iniciais:

```bash
cd backend
npm run seed
```

Isso irÃ¡:
- Criar as fontes de dados configuradas
- Adicionar alguns ativos de exemplo
- Criar dados de teste

## Testando a API

### Usando a documentaÃ§Ã£o Swagger

Acesse http://localhost:3101/api/docs para ver a documentaÃ§Ã£o interativa da API.

### Usando curl

```bash
# Health check
curl http://localhost:3101/api/v1/health

# Listar ativos
curl http://localhost:3101/api/v1/assets

# Buscar ativo especÃ­fico
curl http://localhost:3101/api/v1/assets/PETR4

# Listar fontes de dados
curl http://localhost:3101/api/v1/data-sources
```

## Estrutura do Projeto

```
invest/
â”œâ”€â”€ backend/              # Backend NestJS
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/         # Controllers
â”‚   â”‚   â”œâ”€â”€ services/    # Business logic
â”‚   â”‚   â”œâ”€â”€ scrapers/    # Data scrapers
â”‚   â”‚   â”œâ”€â”€ database/    # Database models
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ frontend/            # Frontend Next.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/        # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ components/ # React components
â”‚   â”‚   â””â”€â”€ services/   # API clients
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ database/           # Database scripts
â”œâ”€â”€ docker/             # Docker configs
â””â”€â”€ docker-compose.yml
```

## PrÃ³ximos Passos

1. **Configurar scrapers**: Edite as credenciais dos scrapers no .env
2. **Testar coleta de dados**: Use a API para testar os scrapers
3. **Explorar o dashboard**: Acesse o frontend e navegue pelas funcionalidades
4. **Adicionar ativos**: Use a API para adicionar novos ativos ao sistema

## Problemas Comuns

### Porta jÃ¡ em uso

Se as portas 3100, 3101 ou 5532 jÃ¡ estiverem em uso, vocÃª pode alterÃ¡-las no docker-compose.yml.

### Erro de conexÃ£o com banco de dados

Verifique se o PostgreSQL estÃ¡ rodando e se as credenciais no .env estÃ£o corretas.

### Erro ao instalar dependÃªncias

Certifique-se de estar usando Node.js 20+ e npm atualizado:

```bash
node --version  # deve ser 20+
npm --version   # deve ser 10+
```

### Scrapers nÃ£o funcionam

Os scrapers podem falhar por vÃ¡rios motivos:
- Credenciais incorretas
- Site mudou estrutura
- Rate limiting
- Necessidade de login manual primeiro

Verifique os logs para mais detalhes:
```bash
docker-compose logs backend
```

## Desenvolvimento

### Executar testes

```bash
# Backend
cd backend
npm test

# Frontend
cd frontend
npm test
```

### Gerar migration

```bash
cd backend
npm run migration:generate -- src/database/migrations/YourMigrationName
```

### Build para produÃ§Ã£o

```bash
# Backend
cd backend
npm run build

# Frontend
cd frontend
npm run build
```

## Suporte

Para problemas ou dÃºvidas, abra uma issue no GitHub ou consulte a documentaÃ§Ã£o completa em `/docs`.
