# Selenium â†’ Playwright Migration Report

**Data:** 2025-11-27
**Executor:** Claude Code
**Fase:** 3 - Mass Migration

---

## ğŸ“Š Status Atual

| MÃ©trica | Quantidade |
|---------|------------|
| **Total de scrapers** | 30 |
| **JÃ¡ migrados** | 2 (bcb_scraper.py, advfn_scraper.py) |
| **Restantes (Selenium)** | 24 |
| **API-only (nÃ£o precisam)** | 4 (anbima, fred, ipeadata, coinmarketcap) |

---

## âœ… Scrapers Migrados (2/30)

1. âœ… **bcb_scraper.py** - Migrado como piloto (FASE 2)
2. âœ… **advfn_scraper.py** - Migrado (FASE 3 inicial)

---

## ğŸ”„ Scrapers Pendentes (24/30)

### Scraping Web (requer Playwright):

1. âŒ b3_scraper.py
2. âŒ bloomberg_scraper.py
3. âŒ chatgpt_scraper.py
4. âŒ claude_scraper.py
5. âŒ deepseek_scraper.py
6. âŒ estadao_scraper.py
7. âŒ exame_scraper.py
8. âŒ fundamentei_scraper.py
9. âŒ fundamentus_scraper.py
10. âŒ gemini_scraper.py
11. âŒ googlefinance_scraper.py
12. âŒ googlenews_scraper.py
13. âŒ griffin_scraper.py
14. âŒ grok_scraper.py
15. âŒ infomoney_scraper.py
16. âŒ investidor10_scraper.py
17. âŒ investing_news_scraper.py
18. âŒ investing_scraper.py
19. âŒ investsite_scraper.py
20. âŒ maisretorno_scraper.py
21. âŒ opcoes_scraper.py
22. âŒ statusinvest_scraper.py
23. âŒ tradingview_scraper.py
24. âŒ valor_scraper.py

### API-only (nÃ£o precisam migraÃ§Ã£o):

- âœ”ï¸ anbima_scraper.py (usa API)
- âœ”ï¸ fred_scraper.py (usa API)
- âœ”ï¸ ipeadata_scraper.py (usa API)
- âœ”ï¸ coinmarketcap_scraper.py (usa API/aiohttp)

---

## ğŸ› ï¸ Ferramentas Criadas

### Script de MigraÃ§Ã£o AutomÃ¡tica

**Arquivo:** `migrate_selenium_to_playwright.py`

**ConversÃµes Implementadas:**

1. **Imports:**
   - Remove `from selenium import webdriver`
   - Remove `from selenium.webdriver.common.by import By`
   - Remove `from selenium.webdriver.support.ui import WebDriverWait`
   - Remove `from selenium.webdriver.support import expected_conditions as EC`

2. **Driver Operations:**
   - `self.driver = self._create_driver()` â†’ comentado (base_scraper cuida)
   - `if not self.driver:` â†’ `if not self.page:`
   - `self.driver.get(url)` â†’ `await self.page.goto(url, wait_until="networkidle")`
   - `self.driver.refresh()` â†’ `await self.page.reload()`
   - `self.driver.page_source` â†’ `await self.page.content()`
   - `self.driver.current_url` â†’ `self.page.url`

3. **Element Finding (CSS):**
   - `self.driver.find_element(By.CSS_SELECTOR, "css")` â†’ `await self.page.query_selector("css")`
   - `self.driver.find_elements(By.CSS_SELECTOR, "css")` â†’ `await self.page.query_selector_all("css")`
   - `elem.find_element(By.CSS_SELECTOR, "css")` â†’ `await elem.query_selector("css")`

4. **Element Finding (XPATH):**
   - `self.driver.find_element(By.XPATH, "xpath")` â†’ `await self.page.query_selector(f"xpath={xpath}")`
   - `elem.find_element(By.XPATH, "xpath")` â†’ `await elem.query_selector(f"xpath={xpath}")`

5. **Element Finding (ID/NAME/TAG):**
   - `By.ID, "id"` â†’ `"#id"`
   - `By.NAME, "name"` â†’ `"[name='name']"`
   - `By.TAG_NAME, "tag"` â†’ `"tag"`

6. **Element Properties:**
   - `elem.text` â†’ `await elem.text_content()`
   - `elem.text.strip()` â†’ `(await elem.text_content()).strip()`
   - `elem.get_attribute(attr)` â†’ `await elem.get_attribute(attr)`
   - `elem.is_displayed()` â†’ `await elem.is_visible()`

7. **Element Actions:**
   - `elem.click()` â†’ `await elem.click()`
   - `elem.send_keys(text)` â†’ `await elem.fill(text)`
   - `elem.clear()` â†’ `await elem.clear()`

8. **Cookies:**
   - `self.driver.add_cookie(cookie)` â†’ `await self.context.add_cookies([cookie])`
   - `self.driver.get_cookies()` â†’ `await self.context.cookies()`

---

## ğŸ“ Mapeamento Completo (SELENIUM_TO_PLAYWRIGHT_MIGRATION.md)

**Arquivo de referÃªncia:** `backend/python-scrapers/SELENIUM_TO_PLAYWRIGHT_MIGRATION.md`

ContÃ©m todos os mapeamentos detalhados com exemplos.

---

## ğŸš€ Como Completar a MigraÃ§Ã£o

### OpÃ§Ã£o 1: Script AutomÃ¡tico (Recomendado)

```bash
cd backend/python-scrapers
python migrate_selenium_to_playwright.py
```

**ObservaÃ§Ã£o:** Requer Python 3.7+ no PATH do Windows.

### OpÃ§Ã£o 2: MigraÃ§Ã£o Manual

Para cada scraper pendente:

1. **Adicionar header de migraÃ§Ã£o:**
   ```python
   # MIGRATED TO PLAYWRIGHT - 2025-11-27
   ```

2. **Remover imports de Selenium:**
   ```python
   # Remove:
   from selenium import webdriver
   from selenium.webdriver.common.by import By
   from selenium.webdriver.support.ui import WebDriverWait
   from selenium.webdriver.support import expected_conditions as EC
   ```

3. **Converter operaÃ§Ãµes de driver:**
   ```python
   # Antes:
   self.driver = self._create_driver()
   self.driver.get(url)
   elem = self.driver.find_element(By.CSS_SELECTOR, ".price")
   price = elem.text

   # Depois:
   # self.driver criado no base_scraper
   await self.page.goto(url, wait_until="networkidle")
   elem = await self.page.query_selector(".price")
   price = await elem.text_content()
   ```

4. **Adicionar `await` em todas operaÃ§Ãµes I/O:**
   - `page.goto()` â†’ `await page.goto()`
   - `page.query_selector()` â†’ `await page.query_selector()`
   - `elem.text_content()` â†’ `await elem.text_content()`
   - `elem.click()` â†’ `await elem.click()`
   - `elem.fill()` â†’ `await elem.fill()`

5. **Testar individualmente:**
   ```bash
   cd backend/python-scrapers
   python scrapers/fundamentus_scraper.py
   ```

### OpÃ§Ã£o 3: MigraÃ§Ã£o com Regex (Bash)

```bash
cd backend/python-scrapers/scrapers

# Para cada arquivo
for file in *_scraper.py; do
    # Adicionar header
    sed -i '1s/^/# MIGRATED TO PLAYWRIGHT - 2025-11-27\n/' "$file"

    # Remover imports
    sed -i '/from selenium/d' "$file"

    # Converter driver.get â†’ page.goto
    sed -i 's/self\.driver\.get(\(.*\))/await self.page.goto(\1, wait_until="networkidle")/g' "$file"

    # ... (adicionar mais conversÃµes conforme necessÃ¡rio)
done
```

---

## âœ… Checklist de ValidaÃ§Ã£o

ApÃ³s migrar TODOS os scrapers:

- [ ] Todos os arquivos tÃªm header `# MIGRATED TO PLAYWRIGHT - 2025-11-27`
- [ ] Nenhum arquivo importa `from selenium`
- [ ] Todos usam `self.page` ao invÃ©s de `self.driver`
- [ ] Todos usam `await` nas operaÃ§Ãµes de I/O
- [ ] Todos usam `query_selector` ao invÃ©s de `find_element`
- [ ] Testar scrapers principais:
  - [ ] fundamentus_scraper.py
  - [ ] statusinvest_scraper.py
  - [ ] investidor10_scraper.py
  - [ ] fundamentei_scraper.py
  - [ ] investing_scraper.py
- [ ] Executar `grep -r "from selenium" scrapers/` deve retornar 0 resultados

---

## ğŸ“Š BenefÃ­cios Esperados

### Performance
- âš¡ **~30% mais rÃ¡pido** que Selenium
- ğŸš€ Auto-wait automÃ¡tico (sem WebDriverWait explÃ­cito)
- ğŸ”„ Async/await nativo (paralelizaÃ§Ã£o)

### Confiabilidade
- âœ… Menos timeouts
- âœ… Menos flaky tests
- âœ… Melhor handling de JavaScript

### Developer Experience
- ğŸ“ API mais limpa e intuitiva
- ğŸ› Melhor debugging (DevTools integrado)
- ğŸ¯ Network interception nativo

---

## ğŸ“š ReferÃªncias

1. **Guia de MigraÃ§Ã£o:** `SELENIUM_TO_PLAYWRIGHT_MIGRATION.md`
2. **Base Scraper Migrado:** `base_scraper.py`
3. **Exemplo Piloto:** `bcb_scraper.py`
4. **DocumentaÃ§Ã£o Playwright:** https://playwright.dev/python/docs/intro

---

## ğŸ”¥ PrÃ³ximos Passos

1. âœ… **FASE 1:** base_scraper.py migrado
2. âœ… **FASE 2:** bcb_scraper.py como piloto
3. ğŸ”„ **FASE 3:** MigraÃ§Ã£o em massa (EM ANDAMENTO)
   - âœ… Script de migraÃ§Ã£o criado
   - âœ… 2 scrapers migrados
   - â³ 24 scrapers pendentes
4. â­ï¸ **FASE 4:** ValidaÃ§Ã£o e testes
5. â­ï¸ **FASE 5:** RemoÃ§Ã£o de dependÃªncias Selenium

---

**Desenvolvido com:** Claude Code
**Co-Authored-By:** Claude <noreply@anthropic.com>
