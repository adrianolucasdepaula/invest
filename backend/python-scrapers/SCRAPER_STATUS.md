# ğŸ“Š Status de Scrapers - B3 AI Analysis Platform

**Ãšltima atualizaÃ§Ã£o:** 2025-11-07
**Total de fontes:** 30+
**Implementados:** 10
**Em produÃ§Ã£o:** 33%

---

## ğŸ¯ Status Geral

| Categoria | Total | Implementado | % |
|-----------|-------|--------------|---|
| **AnÃ¡lise Fundamentalista** | 6 | 3 | 50% |
| **AnÃ¡lise Geral do Mercado** | 3 | 0 | 0% |
| **AnÃ¡lise GrÃ¡fica/TÃ©cnica** | 1 | 0 | 0% |
| **AnÃ¡lise de OpÃ§Ãµes** | 1 | 1 | 100% âœ… |
| **Criptomoedas** | 1 | 1 | 100% âœ… |
| **Insiders** | 1 | 1 | 100% âœ… |
| **RelatÃ³rios Institucionais** | 4 | 2 | 50% |
| **Busca Geral / Dados Oficiais** | 7 | 2 | 29% |
| **NotÃ­cias** | 6 | 0 | 0% |
| **TOTAL** | **30** | **10** | **33%** |

---

## âœ… Scrapers Implementados (10)

### 1. Fundamentus âœ…
- **Arquivo:** `scrapers/fundamentus_scraper.py` (330 linhas)
- **URL:** https://www.fundamentus.com.br/
- **Login:** âŒ NÃ£o necessÃ¡rio (pÃºblico)
- **Indicadores:** 35+
- **Status:** âœ… PRONTO PARA USO

### 2. Investsite âœ…
- **Arquivo:** `scrapers/investsite_scraper.py` (380 linhas)
- **URL:** https://www.investsite.com.br/
- **Login:** âŒ NÃ£o necessÃ¡rio (pÃºblico)
- **Indicadores:** 40+
- **Status:** âœ… PRONTO PARA USO

### 3. StatusInvest âœ…
- **Arquivo:** `scrapers/statusinvest_scraper.py` (192 linhas)
- **URL:** https://statusinvest.com.br/
- **Login:** âŒ NÃ£o necessÃ¡rio (pode melhorar com login)
- **Indicadores:** 10+
- **Status:** âœ… PRONTO PARA USO (bÃ¡sico)

### 4. B3 âœ…
- **Arquivo:** `scrapers/b3_scraper.py` (200 linhas)
- **URL:** https://www.b3.com.br/
- **Login:** âŒ NÃ£o necessÃ¡rio (pÃºblico)
- **Dados:** InformaÃ§Ãµes oficiais, CNPJ, setor, governanÃ§a
- **Status:** âœ… PRONTO PARA USO

### 5. Griffin âœ…
- **Arquivo:** `scrapers/griffin_scraper.py` (240 linhas)
- **URL:** https://griffin.app.br/
- **Login:** âŒ NÃ£o necessÃ¡rio (pÃºblico)
- **Dados:** MovimentaÃ§Ãµes de insiders, compras/vendas
- **Status:** âœ… PRONTO PARA USO

### 6. CoinMarketCap âœ…
- **Arquivo:** `scrapers/coinmarketcap_scraper.py` (180 linhas)
- **URL:** https://coinmarketcap.com/
- **Login:** âŒ NÃ£o necessÃ¡rio (pÃºblico)
- **Dados:** PreÃ§o, market cap, volume 24h, variaÃ§Ãµes
- **Status:** âœ… PRONTO PARA USO

### 7. Opcoes.net.br âœ…
- **Arquivo:** `scrapers/opcoes_scraper.py` (360 linhas)
- **URL:** https://opcoes.net.br/
- **Login:** âœ… SIM (credenciais especÃ­ficas)
- **Credenciais:** Usuario: 312.862.178-06, Senha: Safra998266@#
- **Dados:** Options chain, IV Rank, Greeks, prÃªmios
- **Status:** âœ… PRONTO PARA USO

### 8. Banco Central do Brasil (BCB) âœ…
- **Arquivo:** `scrapers/bcb_scraper.py` (425 linhas)
- **URL:** https://www.bcb.gov.br/
- **Login:** âŒ NÃ£o necessÃ¡rio (pÃºblico)
- **Dados:** Dados macroeconÃ´micos oficiais
- **Indicadores:** 12 (Selic, IPCA, IGP-M, PIB, CÃ¢mbio, Reservas, Desemprego, CDI)
- **API:** âœ… SIM - SGS (Sistema Gerenciador de SÃ©ries Temporais)
- **Dados HistÃ³ricos:** âœ… Ãšltimos 12 meses por indicador
- **Status:** âœ… PRONTO PARA USO

### 9. EstadÃ£o Investidor âœ…
- **Arquivo:** `scrapers/estadao_scraper.py` (353 linhas)
- **URL:** https://einvestidor.estadao.com.br/
- **Login:** âœ… SIM - Google OAuth
- **Dados:** AnÃ¡lises, relatÃ³rios institucionais, notÃ­cias do mercado
- **EstratÃ©gia:** Cookies salvos via Google OAuth
- **Status:** âœ… PRONTO PARA USO

### 10. Mais Retorno âœ…
- **Arquivo:** `scrapers/maisretorno_scraper.py` (364 linhas)
- **URL:** https://maisretorno.com/
- **Login:** âœ… SIM - Google OAuth
- **Dados:** AnÃ¡lises, educaÃ§Ã£o financeira, relatÃ³rios, notÃ­cias
- **EstratÃ©gia:** Cookies salvos via Google OAuth
- **Status:** âœ… PRONTO PARA USO

---

## ğŸ“‹ Scrapers Planejados (20)

### AnÃ¡lise Fundamentalista (3 faltando)

#### Fundamentei â³
- **URL:** https://fundamentei.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [Google OAuth Template](#template-google-oauth)
- **EstratÃ©gia:** Cookies salvos (ver GOOGLE_OAUTH_STRATEGY.md)
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 2-3 horas

#### Investidor10 â³
- **URL:** https://investidor10.com.br/
- **Login:** ğŸ” Google OAuth
- **Template:** [Google OAuth Template](#template-google-oauth)
- **EstratÃ©gia:** Cookies salvos
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 2-3 horas

### AnÃ¡lise Geral do Mercado (3)

#### Investing.com â³
- **URL:** https://br.investing.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [Google OAuth Template](#template-google-oauth)
- **Prioridade:** ğŸŸ¢ Baixa
- **Estimativa:** 3-4 horas

#### ADVFN â³
- **URL:** https://br.advfn.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [Google OAuth Template](#template-google-oauth)
- **Prioridade:** ğŸŸ¢ Baixa
- **Estimativa:** 3-4 horas

#### Google Finance â³
- **URL:** https://www.google.com/finance/
- **Login:** ğŸ” Google OAuth
- **Template:** [Google OAuth Template](#template-google-oauth)
- **Prioridade:** ğŸŸ¢ Baixa
- **Estimativa:** 2-3 horas

### AnÃ¡lise GrÃ¡fica/TÃ©cnica (1)

#### TradingView â³
- **URL:** https://br.tradingview.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [Google OAuth Template](#template-google-oauth)
- **Dados:** Indicadores tÃ©cnicos, padrÃµes grÃ¡ficos
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 4-5 horas

### RelatÃ³rios Institucionais (2 faltando)

#### BTG Pactual â³ (SKIPPED)
- **URL:** https://content.btgpactual.com/research/
- **Login:** ğŸ”‘ Token no celular (complexo)
- **Template:** N/A (requer 2FA)
- **Prioridade:** ğŸ”´ SKIPPED (2FA complexo)
- **Nota:** Requer autenticaÃ§Ã£o 2FA, considerado nÃ£o viÃ¡vel no momento

#### XPI â³ (SKIPPED)
- **URL:** https://conteudos.xpi.com.br/
- **Login:** ğŸ”‘ Token no celular (complexo)
- **Template:** N/A (requer 2FA)
- **Prioridade:** ğŸ”´ SKIPPED (2FA complexo)
- **Nota:** Requer autenticaÃ§Ã£o 2FA, considerado nÃ£o viÃ¡vel no momento

### IAs via Browser (5)

**NOTA:** Todos requerem scraping via browser (SEM API)

#### ChatGPT â³
- **URL:** https://chatgpt.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [IA Browser Template](#template-ia-browser)
- **Prioridade:** ğŸ”´ Alta (anÃ¡lises IA)
- **Estimativa:** 3-4 horas

#### DeepSeek â³
- **URL:** https://www.deepseek.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [IA Browser Template](#template-ia-browser)
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 3-4 horas

#### Gemini â³
- **URL:** https://gemini.google.com/app
- **Login:** ğŸ” Google OAuth
- **Template:** [IA Browser Template](#template-ia-browser)
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 3-4 horas

#### Claude â³
- **URL:** https://claude.ai/new
- **Login:** ğŸ” Google OAuth
- **Template:** [IA Browser Template](#template-ia-browser)
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 3-4 horas

#### Grok â³
- **URL:** https://grok.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [IA Browser Template](#template-ia-browser)
- **Prioridade:** ğŸŸ¢ Baixa
- **Estimativa:** 3-4 horas

### NotÃ­cias (6)

#### Google News â³
- **URL:** https://news.google.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [News Template](#template-news)
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 2 horas

#### Bloomberg LÃ­nea âœ… (PÃºblico - implementar)
- **URL:** https://www.bloomberglinea.com.br/
- **Login:** âŒ NÃƒO (pÃºblico)
- **Template:** [Public News Template](#template-public-news)
- **Prioridade:** ğŸ”´ Alta (pÃºblico!)
- **Estimativa:** 1-2 horas

#### Investing News â³
- **URL:** https://br.investing.com/news
- **Login:** ğŸ” Google OAuth
- **Template:** [News Template](#template-news)
- **Prioridade:** ğŸŸ¢ Baixa
- **Estimativa:** 2 horas

#### Valor EconÃ´mico â³
- **URL:** https://valor.globo.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [News Template](#template-news)
- **Prioridade:** ğŸŸ¡ MÃ©dia
- **Estimativa:** 2-3 horas

#### Exame â³
- **URL:** https://exame.com/
- **Login:** ğŸ” Google OAuth
- **Template:** [News Template](#template-news)
- **Prioridade:** ğŸŸ¢ Baixa
- **Estimativa:** 2 horas

#### InfoMoney â³
- **URL:** https://www.infomoney.com.br/
- **Login:** ğŸ” Google OAuth
- **Template:** [News Template](#template-news)
- **Prioridade:** ğŸŸ¢ Baixa
- **Estimativa:** 2 horas

---

## ğŸ“„ Templates ReutilizÃ¡veis

### Template: Google OAuth

Arquivo: `scrapers/templates/google_oauth_template.py`

Todos os scrapers com Google OAuth seguem este padrÃ£o:

```python
"""
[Site Name] Scraper - [DescriÃ§Ã£o]
Fonte: [URL]
Requer login via Google OAuth
"""
import pickle
from selenium.webdriver.common.by import By
from loguru import logger

from base_scraper import BaseScraper, ScraperResult


class [SiteName]Scraper(BaseScraper):
    BASE_URL = "[site_url]"
    COOKIES_FILE = "/app/browser-profiles/google_cookies.pkl"

    def __init__(self):
        super().__init__(
            name="[SiteName]",
            source="[SOURCE_NAME]",
            requires_login=True,
        )

    async def initialize(self):
        """Load Google OAuth cookies"""
        if self._initialized:
            return

        if not self.driver:
            self.driver = self._create_driver()

        try:
            # Navigate to site
            self.driver.get(self.BASE_URL)

            # Load cookies
            with open(self.COOKIES_FILE, 'rb') as f:
                cookies = pickle.load(f)

            for cookie in cookies:
                if '[site_domain]' in cookie.get('domain', ''):
                    try:
                        self.driver.add_cookie(cookie)
                    except:
                        pass

            # Refresh
            self.driver.refresh()
            await asyncio.sleep(2)

            # Verify
            if not await self._verify_logged_in():
                raise Exception("Login failed - cookies expired")

            self._initialized = True

        except FileNotFoundError:
            raise Exception("Google cookies not found. Run save_google_cookies.py")

    async def _verify_logged_in(self) -> bool:
        """Check if logged in"""
        # Look for logout button or user menu
        logout_selectors = [
            "//a[contains(text(), 'Sair')]",
            "//button[contains(text(), 'Logout')]",
            ".user-menu",
        ]

        for selector in logout_selectors:
            try:
                if selector.startswith("//"):
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                if elements:
                    return True
            except:
                continue

        return False

    async def scrape(self, ticker: str) -> ScraperResult:
        """Scrape data"""
        await self.initialize()

        # Build URL
        url = f"{self.BASE_URL}/[path]/{ticker}"
        self.driver.get(url)
        await asyncio.sleep(3)

        # Extract data
        data = await self._extract_data(ticker)

        if data:
            return ScraperResult(
                success=True,
                data=data,
                source=self.source,
                metadata={"url": url, "requires_login": True},
            )

        return ScraperResult(
            success=False,
            error="Failed to extract data",
            source=self.source,
        )

    async def _extract_data(self, ticker: str):
        """Extract data from page"""
        # Implement site-specific extraction
        pass
```

**Uso:**
1. Copiar template
2. Substituir `[SiteName]`, `[site_url]`, `[site_domain]`
3. Implementar `_extract_data()`
4. Ajustar `_verify_logged_in()` para o site especÃ­fico

---

### Template: IA Browser

Arquivo: `scrapers/templates/ia_browser_template.py`

Para IAs acessadas via browser (sem API):

```python
"""
[IA Name] Scraper - AnÃ¡lise via IA
Fonte: [URL]
Acesso via browser (SEM API)
"""
import asyncio
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from loguru import logger

from base_scraper import BaseScraper, ScraperResult


class [IAName]Scraper(BaseScraper):
    BASE_URL = "[ia_url]"
    COOKIES_FILE = "/app/browser-profiles/google_cookies.pkl"

    def __init__(self):
        super().__init__(
            name="[IAName]",
            source="[IA_NAME]",
            requires_login=True,
        )

    async def scrape(self, prompt: str) -> ScraperResult:
        """
        Send prompt to IA and get response

        Args:
            prompt: Question/prompt for the IA

        Returns:
            ScraperResult with IA response
        """
        await self.initialize()

        try:
            # Navigate to chat page
            self.driver.get(f"{self.BASE_URL}/chat")
            await asyncio.sleep(3)

            # Find chat input
            input_selectors = [
                "textarea[placeholder*='Message']",
                "textarea[placeholder*='Type']",
                "div[contenteditable='true']",
                "#prompt-textarea",
            ]

            input_field = None
            for selector in input_selectors:
                try:
                    input_field = self.driver.find_element(By.CSS_SELECTOR, selector)
                    break
                except:
                    continue

            if not input_field:
                return ScraperResult(
                    success=False,
                    error="Could not find chat input",
                    source=self.source,
                )

            # Send prompt
            input_field.clear()
            input_field.send_keys(prompt)
            input_field.send_keys(Keys.RETURN)

            # Wait for response
            await asyncio.sleep(5)

            # Extract response
            response = await self._extract_response()

            if response:
                return ScraperResult(
                    success=True,
                    data={"prompt": prompt, "response": response},
                    source=self.source,
                )

            return ScraperResult(
                success=False,
                error="No response from IA",
                source=self.source,
            )

        except Exception as e:
            logger.error(f"Error getting IA response: {e}")
            return ScraperResult(
                success=False,
                error=str(e),
                source=self.source,
            )

    async def _extract_response(self) -> str:
        """Extract IA response from page"""
        # Wait for response to be generated
        max_wait = 60  # 60 seconds max
        waited = 0

        while waited < max_wait:
            # Check if response is ready
            # Look for response container
            response_selectors = [
                ".response-text",
                ".message-content",
                "[data-message-author-role='assistant']",
            ]

            for selector in response_selectors:
                try:
                    response_elem = self.driver.find_element(By.CSS_SELECTOR, selector)
                    response_text = response_elem.text.strip()

                    if response_text and len(response_text) > 10:
                        return response_text

                except:
                    continue

            await asyncio.sleep(2)
            waited += 2

        return None
```

**Uso:**
1. Adaptar seletores para cada IA
2. Ajustar lÃ³gica de detecÃ§Ã£o de resposta pronta
3. Implementar parsing de respostas longas

---

## ğŸš€ PrÃ³ximos Passos Recomendados

### Prioridade ALTA (fazer primeiro)

1. **Bloomberg LÃ­nea** (pÃºblico!) - 1-2 horas
2. **ChatGPT** (IA alta prioridade) - 3-4 horas
3. **Fundamentei** (cookies) - 2-3 horas
4. **Investidor10** (cookies) - 2-3 horas

**Total:** ~10-12 horas para ter 11 scrapers

### Prioridade MÃ‰DIA

5. **TradingView** (anÃ¡lise tÃ©cnica) - 4-5 horas
6. **Gemini** (IA alternativa) - 3-4 horas
7. **Google News** (notÃ­cias) - 2 horas
8. **Valor EconÃ´mico** (notÃ­cias financeiras) - 2-3 horas

**Total acumulado:** ~21-26 horas para 15 scrapers

### Prioridade BAIXA

- Demais fontes de notÃ­cias (4)
- IAs restantes (3)
- Investing.com, ADVFN, Google Finance
- RelatÃ³rios institucionais (requerem 2FA)

---

## ğŸ“Š Roadmap de ImplementaÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: Fontes PÃºblicas (COMPLETA) âœ…               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Fundamentus âœ…                                     â”‚
â”‚ â€¢ Investsite âœ…                                      â”‚
â”‚ â€¢ B3 âœ…                                              â”‚
â”‚ â€¢ Griffin âœ…                                         â”‚
â”‚ â€¢ CoinMarketCap âœ…                                   â”‚
â”‚ â€¢ StatusInvest âœ… (bÃ¡sico)                           â”‚
â”‚ â€¢ BCB âœ… (dados macroeconÃ´micos)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: Scrapers com Credenciais (COMPLETA) âœ…      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Opcoes.net.br âœ…                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 3: Google OAuth - Alta Prioridade (PRÃ“XIMA)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Bloomberg LÃ­nea (pÃºblico!) â³                      â”‚
â”‚ â€¢ ChatGPT (IA) â³                                    â”‚
â”‚ â€¢ Fundamentei â³                                      â”‚
â”‚ â€¢ Investidor10 â³                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 4: AnÃ¡lises Especializadas                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ TradingView (grÃ¡fica) â³                           â”‚
â”‚ â€¢ Gemini (IA) â³                                      â”‚
â”‚ â€¢ Google News â³                                      â”‚
â”‚ â€¢ Valor EconÃ´mico â³                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 5: Fontes SecundÃ¡rias                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Demais notÃ­cias (4) â³                             â”‚
â”‚ â€¢ IAs restantes (3) â³                                â”‚
â”‚ â€¢ RelatÃ³rios institucionais (2FA) â³                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testes

### Testar Scrapers Implementados

```bash
# Todos os scrapers
docker exec -it invest_scrapers python test_scrapers.py all PETR4

# Scraper especÃ­fico
docker exec -it invest_scrapers python test_scrapers.py fundamentus PETR4
docker exec -it invest_scrapers python test_scrapers.py opcoes PETR
docker exec -it invest_scrapers python test_scrapers.py griffin PETR4

# Testar BCB (dados macroeconÃ´micos)
docker exec -it invest_scrapers python -c "
from scrapers import BCBScraper
import asyncio

async def test():
    scraper = BCBScraper()
    result = await scraper.scrape_with_retry('all')
    print(result.to_dict())

asyncio.run(test())
"
```

### Configurar Opcoes.net.br

Adicionar ao `.env`:
```env
OPCOES_USERNAME=312.862.178-06
OPCOES_PASSWORD=Safra998266@#
```

---

**Ãšltima atualizaÃ§Ã£o:** 2025-11-07
**VersÃ£o:** 1.0
**PrÃ³xima revisÃ£o:** ApÃ³s implementar Fase 3
