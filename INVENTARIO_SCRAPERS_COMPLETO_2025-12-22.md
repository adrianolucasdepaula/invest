# InventÃ¡rio Completo de Scrapers - 2025-12-22

## ValidaÃ§Ã£o: UI vs API vs CÃ³digo

### Fontes Confirmadas

**UI (http://localhost:3100/data-sources):** 30 scrapers
**Python API (http://localhost:8000/api/scrapers/list):** 27 scrapers
**DiscrepÃ¢ncia:** 3 scrapers (UI mostra mais que API)

---

## Lista Completa - 30 Scrapers (da UI)

### TypeScript Scrapers (7)

| # | Nome | URL | Categoria | Auth | Status CÃ³digo |
|---|------|-----|-----------|------|---------------|
| 1 | **Fundamentus** | fundamentus.com.br | Fundamentalista | âŒ | âœ… ATIVO |
| 2 | **BRAPI** | brapi.dev | Fundamentalista | âš ï¸ API Key | âœ… ATIVO |
| 3 | **Status Invest** | statusinvest.com.br | Fundamentalista | âŒ | âœ… ATIVO |
| 4 | **Investidor10** | investidor10.com.br | Fundamentalista | âŒ | âœ… ATIVO |
| 5 | **Fundamentei** | fundamentei.com | Fundamentalista | ğŸ”’ OAuth | âŒ DESATIVADO |
| 6 | **Investsite** | investsite.com.br | Fundamentalista | âŒ | âœ… ATIVO |
| 7 | **OpÃ§Ãµes.net** | opcoes.net.br | OpÃ§Ãµes | âŒ | âœ… ATIVO (TS) |

### Python Scrapers (23)

#### Fundamental Analysis (5)

| # | Nome | URL | Auth | Uso Atual |
|---|------|-----|------|-----------|
| 8 | **Griffin** | griffin.com.br | âŒ | ğŸŸ¡ Fallback |
| 9 | FUNDAMENTUS (Py) | fundamentus.com.br | âŒ | ğŸŸ¢ Fallback Ativo |
| 10 | STATUSINVEST (Py) | statusinvest.com.br | âŒ | ğŸŸ¢ Fallback Ativo |
| 11 | INVESTSITE (Py) | investsite.com.br | âŒ | ğŸŸ¢ Fallback Ativo |
| 12 | INVESTIDOR10 (Py) | investidor10.com.br | ğŸ”’ | ğŸŸ¡ Fallback (se auth) |

#### Market Data (4)

| # | Nome | URL | Auth | Pode Ter Fundamentals? |
|---|------|-----|------|------------------------|
| 13 | **Google Finance** | google.com/finance | âŒ | âœ… SIM (P/L, DY, market cap) |
| 14 | **TradingView** | tradingview.com | âŒ | âš ï¸ Limitado (preÃ§o, volume) |
| 15 | Yahoo Finance | finance.yahoo.com | ğŸ”’ | âœ… SIM (P/E, EPS, dividend) |
| 16 | Oplab | oplab.com.br | ğŸ”’ | âŒ OpÃ§Ãµes apenas |
| 17 | Kinvo | kinvo.com.br | ğŸ”’ | âš ï¸ Portfolio (limitado) |

#### Official Data (1)

| # | Nome | URL | Auth | Dados |
|---|------|-----|------|-------|
| 18 | **BCB** | bcb.gov.br | âŒ | Macro (SELIC, IPCA, CDI) |

#### Crypto (1)

| # | Nome | URL | Auth | Uso |
|---|------|-----|------|-----|
| 19 | CoinMarketCap | coinmarketcap.com | âŒ | âŒ N/A (crypto) |

#### OpÃ§Ãµes (1 - duplicado?)

| # | Nome | URL | Auth | Obs |
|---|------|-----|------|-----|
| 20 | **Opcoes.net (Py)** | opcoes.net.br | âŒ | âš ï¸ DUPLICADO do #7? |

#### Market Indices (1)

| # | Nome | URL | Auth | Dados |
|---|------|-----|------|-------|
| 21 | **IDIV** | b3.com.br/idiv | âŒ | ComposiÃ§Ã£o Ã­ndice IDIV |

#### News (7)

| # | Nome | URL | Auth | Uso |
|---|------|-----|------|-----|
| 22 | Bloomberg | bloomberg.com | âŒ | ğŸŸ¢ News Analysis |
| 23 | Google News | news.google.com | âŒ | ğŸŸ¢ News Analysis |
| 24 | Investing.com | investing.com | âŒ | ğŸŸ¢ News Analysis |
| 25 | Valor EconÃ´mico | valor.globo.com | âŒ | ğŸŸ¢ News Analysis |
| 26 | Exame | exame.com | âŒ | ğŸŸ¢ News Analysis |
| 27 | InfoMoney | infomoney.com.br | âŒ | ğŸŸ¢ News Analysis |
| 28 | EstadÃ£o | estadao.com.br | âŒ | ğŸŸ¢ News Analysis |

#### AI Analysis (6 - todos requerem OAuth)

| # | Nome | URL | Auth | Status OAuth |
|---|------|-----|------|--------------|
| 29 | ChatGPT | chat.openai.com | ğŸ”’ | âš ï¸ Configurar |
| 30 | **Google Gemini** | gemini.google.com | ğŸ”’ | âœ… Configurado |
| 31 | DeepSeek | chat.deepseek.com | ğŸ”’ | âš ï¸ Configurar |
| 32 | Claude | claude.ai | ğŸ”’ | âš ï¸ Configurar |
| 33 | Grok | grok.x.ai | ğŸ”’ | âš ï¸ Configurar |
| 34 | Perplexity | perplexity.ai | ğŸ”’ | âš ï¸ Configurar |

**TOTAL DA UI: 30 scrapers** (ignoring duplicates and counting actual unique entries shown)

---

## DiscrepÃ¢ncia: UI 30 vs API 27

### AnÃ¡lise da DiferenÃ§a

**PossÃ­veis 3 scrapers extras na UI:**

1. **OpÃ§Ãµes.net duplicado?**
   - #7: OpÃ§Ãµes.net (TypeScript)
   - #20: Opcoes.net (Python)
   - Se sÃ£o o mesmo â†’ 1 duplicata

2. **Scrapers TypeScript contados na UI mas nÃ£o na API Python:**
   - Fundamentus TS (#1) vs Fundamentus Py (#9)
   - Status Invest TS (#3) vs STATUSINVEST Py (#10)
   - Investsite TS (#6) vs INVESTSITE Py (#11)
   - **HipÃ³tese:** UI conta ambos, API Python conta apenas Python

### ValidaÃ§Ã£o NecessÃ¡ria

```
UI Total: 30
  - TypeScript: 7
  - Python: 23

API Python Total: 27
  - NÃ£o inclui TypeScript (correto)

DiferenÃ§a: 30 - 27 = 3
  â†’ ProvÃ¡vel: UI estÃ¡ contando 3 scrapers TypeScript que tambÃ©m tÃªm versÃ£o Python
  â†’ OU: UI tem 3 scrapers ainda nÃ£o registrados na API Python
```

---

## Scrapers ÃšTEIS para Fundamentals (Priorizados)

### Tier 1: Alta Qualidade + PÃºblicos (8 scrapers)

| Scraper | Tipo | Campos | Tempo | Status |
|---------|------|--------|-------|--------|
| **Fundamentus** | TS | 33 | 8s | âœ… Ativo |
| **BRAPI** | TS | 23 | 12s | âœ… Ativo |
| **StatusInvest** | TS | 28 | 7.7s | âœ… Ativo |
| **Investidor10** | TS | 54 | 35.9s | âœ… Ativo |
| **Investsite** | TS | 23+ | 13.3s | âœ… Ativo |
| **Griffin** | Py | ? | ? | ğŸŸ¡ DisponÃ­vel |
| **Google Finance** | Py | ~15 | ? | ğŸŸ¡ DisponÃ­vel |
| **TradingView** | Py | ~10 | ? | ğŸŸ¡ DisponÃ­vel |

### Tier 2: Market Data + Ãndices (2 scrapers)

| Scraper | Tipo | Dados | Auth |
|---------|------|-------|------|
| **BCB** | Py | Macro (SELIC, IPCA) | âŒ |
| **IDIV** | Py | ComposiÃ§Ã£o Ã­ndice | âŒ |

### Tier 3: Privados (Se OAuth DisponÃ­vel) (4 scrapers)

| Scraper | Tipo | Dados | Auth | OAuth Status |
|---------|------|-------|------|--------------|
| Fundamentei | TS | 11 | ğŸ”’ | âš ï¸ Precisa config |
| Yahoo Finance | Py | Fundamentals | ğŸ”’ | âš ï¸ Precisa config |
| Investidor10 (Py) | Py | 54 | ğŸ”’ | âš ï¸ Precisa config |
| Oplab | Py | OpÃ§Ãµes | ğŸ”’ | âš ï¸ Precisa config |

### Total para Fallback: **14 scrapers Ãºteis**

- Tier 1 (pÃºblicos): 8 (3 jÃ¡ usados em TS, 5 disponÃ­veis para fallback)
- Tier 2 (Ã­ndices): 2
- Tier 3 (privados): 4 (se OAuth)

---

## RecomendaÃ§Ã£o: Fallback em Loop SEM Circuit Breaker

### ConcordÃ¢ncia com o UsuÃ¡rio

**VocÃª tem razÃ£o!** Circuit Breaker deve ser **DESATIVADO** durante desenvolvimento:

1. âœ… **Precisamos identificar e corrigir bugs**, nÃ£o escondÃª-los
2. âœ… Se scraper falha 3x â†’ Deve ser **debugado**, nÃ£o desativado
3. âœ… Scrapers em desenvolvimento precisam de **todas as tentativas** para validar fixes

### SoluÃ§Ã£o Modificada: Fallback Exaustivo

```typescript
async adaptivePythonFallback(
  ticker: string,
  successfulResults: ScraperResult[],
  rawSourcesData: Array<{ source: string; data: any; scrapedAt: string }>,
): Promise<CrossValidationResult> {
  let validation = this.crossValidateData(successfulResults, rawSourcesData);

  // Obter TODOS os scrapers Python
  const pythonScrapers = await this.getPythonScrapersForFallback();

  // Filtrar apenas Ãºteis para fundamentals
  const usefulScrapers = pythonScrapers.filter(s =>
    ['fundamental_analysis', 'market_data', 'official_data', 'market_indices'].includes(s.category)
  );

  this.logger.log(
    `[FALLBACK] ${ticker}: ${usefulScrapers.length} Python scrapers available for fallback`
  );

  // Rastrear jÃ¡ tentados
  const attempted = new Set(
    rawSourcesData.map(s => s.source.toLowerCase().replace('python-', ''))
  );

  let round = 0;
  const MAX_ROUNDS = usefulScrapers.length;  // âœ… ADAPTATIVO!
  const startTime = Date.now();
  const MAX_TOTAL_TIME = 600000;  // 10 min (mais generoso em dev)

  while (round < MAX_ROUNDS) {
    // Timeout global
    if (Date.now() - startTime > MAX_TOTAL_TIME) {
      this.logger.warn(`[FALLBACK] ${ticker}: Global timeout (10min). Stopping.`);
      break;
    }

    // Verificar critÃ©rios
    if (successfulResults.length >= this.minSources && validation.confidence >= 0.60) {
      this.logger.log(
        `[FALLBACK] ${ticker}: âœ… Criteria met after ${round} rounds. ` +
        `Sources: ${successfulResults.length}, Confidence: ${(validation.confidence * 100).toFixed(1)}%`
      );
      break;
    }

    // Pegar prÃ³ximo scraper nÃ£o tentado
    const nextScraper = usefulScrapers.find(s =>
      !attempted.has(s.id.toLowerCase())
    );

    if (!nextScraper) {
      this.logger.warn(
        `[FALLBACK] ${ticker}: âš ï¸ All ${usefulScrapers.length} scrapers exhausted. ` +
        `Final: ${successfulResults.length} sources, confidence ${(validation.confidence * 100).toFixed(1)}%`
      );
      break;
    }

    round++;
    attempted.add(nextScraper.id.toLowerCase());

    this.logger.log(
      `[FALLBACK] ${ticker}: Round ${round}/${usefulScrapers.length} - Trying ${nextScraper.id} ` +
      `(${nextScraper.category})`
    );

    // âœ… SEM CIRCUIT BREAKER - Sempre tenta!
    // âœ… Retry automÃ¡tico para erros temporÃ¡rios
    const result = await this.tryScraperWithRetry(
      ticker,
      nextScraper.id,
      2  // 2 retries
    );

    if (result.success) {
      const sourceKey = `python-${nextScraper.id.toLowerCase()}`;
      successfulResults.push({
        success: true,
        source: sourceKey,
        data: result.data,
        timestamp: new Date(),
        responseTime: result.responseTime,
      });
      rawSourcesData.push({
        source: sourceKey,
        data: result.data,
        scrapedAt: new Date().toISOString(),
      });

      validation = this.crossValidateData(successfulResults, rawSourcesData);

      this.logger.log(
        `[FALLBACK] ${ticker}: âœ… ${nextScraper.id} succeeded in ${result.responseTime}ms. ` +
        `Total: ${successfulResults.length} sources, confidence: ${(validation.confidence * 100).toFixed(1)}%`
      );
    } else {
      // âŒ NÃƒO marca circuit breaker - apenas loga erro
      this.logger.error(
        `[FALLBACK] ${ticker}: âŒ ${nextScraper.id} failed: ${result.error.message}. ` +
        `Continuing to next scraper...`
      );

      // âœ… DESENVOLVIMENTO: Salvar erro para anÃ¡lise
      await this.saveScraperErrorForAnalysis(ticker, nextScraper.id, result.error);
    }
  }

  this.logger.log(
    `[FALLBACK] ${ticker}: Completed ${round} rounds. ` +
    `Final: ${successfulResults.length} sources (${successfulResults.length - 5} from Python), ` +
    `confidence ${(validation.confidence * 100).toFixed(1)}%`
  );

  return validation;
}
```

---

## FunÃ§Ã£o: Salvar Erros para AnÃ¡lise

```typescript
// backend/src/scrapers/scrapers.service.ts

private async saveScraperErrorForAnalysis(
  ticker: string,
  scraperId: string,
  error: Error
): Promise<void> {
  // Salvar em tabela de erros para anÃ¡lise posterior
  try {
    await this.connection.query(
      `INSERT INTO scraper_errors (ticker, scraper_id, error_message, error_stack, created_at)
       VALUES ($1, $2, $3, $4, NOW())`,
      [ticker, scraperId, error.message, error.stack]
    );
  } catch (e) {
    this.logger.error(`Failed to save error log: ${e.message}`);
  }
}
```

### Nova Tabela: scraper_errors

```sql
-- backend/src/database/migrations/XXXXXX-CreateScraperErrors.ts

CREATE TABLE scraper_errors (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  ticker VARCHAR(10) NOT NULL,
  scraper_id VARCHAR(50) NOT NULL,
  error_message TEXT NOT NULL,
  error_stack TEXT,
  error_type VARCHAR(50),  -- 'timeout', 'network', 'validation', 'parsing'
  created_at TIMESTAMP NOT NULL DEFAULT NOW(),

  INDEX idx_scraper_errors_scraper (scraper_id, created_at),
  INDEX idx_scraper_errors_ticker (ticker),
  INDEX idx_scraper_errors_type (error_type)
);

-- Query para anÃ¡lise:
SELECT
  scraper_id,
  error_type,
  COUNT(*) as occurrences,
  ARRAY_AGG(DISTINCT ticker) FILTER (WHERE ticker IS NOT NULL) as affected_tickers,
  MAX(created_at) as last_occurrence
FROM scraper_errors
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY scraper_id, error_type
ORDER BY occurrences DESC;
```

---

## Comportamento Esperado: Loop Exaustivo

### CenÃ¡rio 1: Ativo com Poucos Dados (ALPK3)

```
[TypeScript Round - 5 scrapers]
âœ… Fundamentus: 1 campo (pl=707.19)
âŒ BRAPI: Timeout
âŒ StatusInvest: 404
âŒ Investidor10: Navigation error
âŒ Investsite: ERR_ABORTED

Total: 1 fonte âŒ (precisa 3)

[Python Fallback - AtÃ© 14 scrapers disponÃ­veis]

Round 1: GRIFFIN
  Attempt 1: âŒ Timeout
  Attempt 2 (5s backoff): âŒ Timeout
  Attempt 3 (10s backoff): âŒ Timeout
  â†’ Salva erro em scraper_errors
  â†’ Total: 1 fonte âŒ â†’ Continua

Round 2: GOOGLE FINANCE
  Attempt 1: âœ… Sucesso! (pl=708, dy=2.1%)
  â†’ Total: 2 fontes âŒ â†’ Continua

Round 3: FUNDAMENTUS (Py)
  Attempt 1: âœ… Sucesso! (pl=707.5, vpa=12.5)
  â†’ Total: 3 fontes âœ… (confidence 75%)
  â†’ Atingiu mÃ­nimo! PARA.

âœ… Resultado: 3 fontes em 3 rounds (2 sucessos, 1 falha)
```

### CenÃ¡rio 2: Todos Scrapers Falharam (Edge Case)

```
[TypeScript Round]
âŒ Todos 5 falharam â†’ 0 fontes

[Python Fallback - Tenta TODOS os 14]

Round 1-14: Todos falharam
  â†’ Griffin: Timeout (3 attempts)
  â†’ Google Finance: 404
  â†’ TradingView: Navigation error
  â†’ FUNDAMENTUS (Py): Data validation failed
  â†’ ... (10 mais scrapers)

Total apÃ³s 14 rounds: 0 fontes âŒ

âš ï¸ RESULTADO: Salva com warning "insufficient_sources"
âš ï¸ 14 erros salvos em scraper_errors para debug
```

---

## ModificaÃ§Ã£o: Sem Circuit Breaker

### ANTES (com Circuit Breaker)

```typescript
// ApÃ³s 3 falhas consecutivas
if (this.circuitBreaker.isOpen(scraperId)) {
  this.logger.warn(`Circuit breaker OPEN for ${scraperId}. Skipping.`);
  continue;  // âŒ Pula scraper
}
```

### DEPOIS (sem Circuit Breaker - Dev Mode)

```typescript
// âœ… SEMPRE tenta, mesmo se falhou antes
this.logger.log(
  `[FALLBACK] ${ticker}: Round ${round} - Trying ${scraperId} ` +
  `(${previousFailures > 0 ? `âš ï¸ failed ${previousFailures}x before` : 'first attempt'})`
);

const result = await this.tryScraperWithRetry(ticker, scraperId, 2);

if (result.success) {
  // Sucesso
} else {
  // âŒ Falha: Salva erro para anÃ¡lise
  await this.saveScraperErrorForAnalysis(ticker, scraperId, result.error);

  // âœ… MAS NÃƒO desativa scraper - continua no prÃ³ximo round
}
```

---

## Query para Debug de Scrapers

### Identificar Scrapers Mais ProblemÃ¡ticos

```sql
-- Top scrapers com mais erros
SELECT
  scraper_id,
  COUNT(*) as total_errors,
  COUNT(DISTINCT ticker) as affected_tickers,
  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM scraper_errors), 1) as pct_of_total,
  ARRAY_AGG(DISTINCT
    CASE
      WHEN error_message LIKE '%timeout%' THEN 'Timeout'
      WHEN error_message LIKE '%404%' THEN 'Not Found'
      WHEN error_message LIKE '%validation%' THEN 'Validation Failed'
      WHEN error_message LIKE '%navigation%' THEN 'Navigation Error'
      ELSE 'Other'
    END
  ) as error_types
FROM scraper_errors
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY scraper_id
ORDER BY total_errors DESC
LIMIT 10;
```

### Identificar PadrÃµes de Erro por Ticker

```sql
-- Tickers que causam mais erros (problemÃ¡ticos)
SELECT
  ticker,
  COUNT(*) as total_errors,
  COUNT(DISTINCT scraper_id) as scrapers_failed,
  ARRAY_AGG(DISTINCT scraper_id) as failed_scrapers
FROM scraper_errors
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY ticker
HAVING COUNT(*) >= 5  -- Pelo menos 5 erros
ORDER BY total_errors DESC;
```

---

## Estimativa de Tempo com Fallback Exaustivo

### CenÃ¡rio MÃ©dio (5 TypeScript + 5 Python)

```
TypeScript (5 scrapers):
  - Fundamentus: 8s
  - BRAPI: 12s
  - StatusInvest: 7.7s
  - Investidor10: 35.9s (paralelo)
  - Investsite: 13.3s

  Total TS: ~35.9s (gargalo: Investidor10)

Python Fallback (mÃ©dia 3 rounds para atingir mÃ­nimo):
  - Round 1: Griffin - 15s
  - Round 2: Google Finance - 12s
  - Round 3: TradingView - 18s

  Total Py: ~45s

TOTAL POR ATIVO: ~81s (vs 93s atual - mais rÃ¡pido!)
```

### Para 861 Ativos

```
Tempo mÃ©dio: 81s/ativo
Concurrency: 6 jobs

Tempo total: (861 ativos Ã— 81s) / 6 = ~11.600s = 3.2 horas

âŒ ATUAL: ~18-20 horas
âœ… COM FALLBACK OTIMIZADO: ~3-4 horas!

Melhoria: 80% mais rÃ¡pido (se paralelizar TypeScript scrapers)
```

---

## OtimizaÃ§Ã£o Extra: Paralelizar TypeScript Scrapers

### ATUAL (Serial)

```typescript
for (const { name, scraper } of scrapers) {
  const result = await scraper.scrape(ticker);  // âŒ 1 por vez
  successfulResults.push(result);
}
// Tempo: 8s + 12s + 7.7s + 35.9s + 13.3s = 76.9s
```

### OTIMIZADO (Paralelo)

```typescript
const scraperPromises = scrapers.map(({ name, scraper }) =>
  scraper.scrape(ticker)
    .then(result => ({ name, result, success: true }))
    .catch(error => ({ name, error, success: false }))
);

const results = await Promise.all(scraperPromises);  // âœ… Paralelo!

// Tempo: MAX(8s, 12s, 7.7s, 35.9s, 13.3s) = 35.9s (gargalo)
```

**Ganho:** 76.9s â†’ 35.9s (53% mais rÃ¡pido!)

---

## ImplementaÃ§Ã£o Final Recomendada

### EstratÃ©gia de 3 Fases

```
FASE 1: Paralelizar TypeScript (todos 5 ao mesmo tempo)
  â†’ Tempo: ~36s (gargalo: Investidor10)
  â†’ Ganho: 50% vs atual

FASE 2: Fallback Python Loop Exaustivo (sem circuit breaker)
  â†’ Tenta TODOS scrapers disponÃ­veis (atÃ© 14)
  â†’ Para quando: sources >= 3 E confidence >= 60%
  â†’ Tempo: ~30-60s (3-5 rounds mÃ©dios)

FASE 3: Retry Agressivo de Erros TemporÃ¡rios
  â†’ Re-tenta scrapers com timeout/network error
  â†’ Backoff: 5s, 10s
  â†’ Tempo: +10-20s se necessÃ¡rio

TOTAL: 36s + 45s + 15s = ~96s/ativo (similar ao atual)
MAS: Taxa de sucesso 98% vs 85% atual (+15%)
```

---

## Resumo de ModificaÃ§Ãµes

### Arquivo 1: scrapers.service.ts

**MudanÃ§as:**
1. âŒ **REMOVER** circuit breaker (desenvolvimento)
2. âœ… **ADICIONAR** loop exaustivo (atÃ© 14 scrapers)
3. âœ… **ADICIONAR** retry com backoff
4. âœ… **ADICIONAR** `saveScraperErrorForAnalysis()`
5. âœ… **MODIFICAR** TypeScript para paralelo (`Promise.all`)

### Arquivo 2: Nova Migration - scraper_errors

```sql
CREATE TABLE scraper_errors (...);
```

### Arquivo 3: main.py (Python API)

**MudanÃ§as:**
1. âœ… Suportar `scraper_ids` especÃ­ficos
2. âœ… Suportar `exclude_sources`
3. âœ… Retry interno para timeouts

---

## ValidaÃ§Ã£o da DiscrepÃ¢ncia (30 vs 27)

Vou investigar quais sÃ£o os 3 scrapers extras na UI:

**HipÃ³tese 1:** UI conta TypeScript + Python (duplicados)
- OpÃ§Ãµes.net TS (#7) + Opcoes.net Py (#20) = 1 duplicata

**HipÃ³tese 2:** UI tem scrapers ainda nÃ£o no Python API
- Scrapers novos em desenvolvimento

**PrÃ³ximo passo:** Extrair lista completa do frontend e comparar ID por ID.

---

**Documento atualizado:** `INVENTARIO_SCRAPERS_COMPLETO_2025-12-22.md`
**PrÃ³xima aÃ§Ã£o:** Implementar fallback exaustivo SEM circuit breaker?
