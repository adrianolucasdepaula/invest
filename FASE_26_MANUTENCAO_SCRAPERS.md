# üîß FASE 26: Manuten√ß√£o de Scrapers - Corre√ß√£o de Problemas N√£o-Bloqueantes

**Data:** 2025-11-14 18:45
**Vers√£o:** 1.0
**Tipo:** Manuten√ß√£o/Corre√ß√µes
**Prioridade:** ALTA (Resolver n√£o-bloqueantes antes de novas features)
**Executor:** Claude Code (Sonnet 4.5)

---

## üéØ OBJETIVO

Corrigir **3 problemas n√£o-bloqueantes** identificados na Valida√ß√£o MCP Triplo (2025-11-14) para garantir que o sistema de scrapers esteja 100% funcional e confi√°vel antes de implementar novas features.

---

## üìã PROBLEMAS IDENTIFICADOS

### ‚ö†Ô∏è Problema 1: Fundamentei Scraper - 0% Taxa de Sucesso

**Descri√ß√£o:**
- Scraper "Fundamentei" (https://fundamentei.com) retorna 0.0% de taxa de sucesso
- **Dados do banco:** 5 tentativas, 5 falhas, 0ms tempo m√©dio
- **√öltimo teste:** 14/11/2025, 16:18:28

**Impacto:**
- üü° M√âDIO - Cross-validation reduzida de 6 para 5 fontes (83.3%)
- Confian√ßa das an√°lises ainda aceit√°vel (m√≠nimo 3 fontes atingido)

**Causa Prov√°vel:**
1. ‚ùì Autentica√ß√£o OAuth Google falhando (cookies expirados/inv√°lidos)
2. ‚ùì Estrutura HTML do site alterada (seletores CSS quebrados)
3. ‚ùì Timeout de navega√ß√£o Playwright (site lento)
4. ‚ùì Bloqueio de bot (CloudFlare, Imperva, etc)

**Solu√ß√£o Proposta:**
1. ‚úÖ **Investigar logs do scraper** - Analisar erro exato retornado
2. ‚úÖ **Testar manualmente** - Navegar no site e verificar estrutura HTML atual
3. ‚úÖ **Validar OAuth** - Verificar se cookies de autentica√ß√£o est√£o v√°lidos
4. ‚úÖ **Atualizar seletores CSS** - Se estrutura HTML mudou
5. ‚úÖ **Aumentar timeout** - De 30s para 60s se necess√°rio
6. ‚úÖ **Adicionar retry com backoff** - 3 tentativas com delay exponencial

---

### ‚ö†Ô∏è Problema 2: Fundamentus - Tempo M√©dio Elevado (21 minutos)

**Descri√ß√£o:**
- Scraper "Fundamentus" (https://fundamentus.com.br) retorna tempo m√©dio de **1.263.123ms** (21 minutos)
- **Dados do banco:** 3 tentativas, 100% sucesso
- **√öltimo teste:** 14/11/2025, 12:37:42

**Impacto:**
- üü° M√âDIO - Performance ruim, mas n√£o afeta funcionalidade
- An√°lises em massa ficam lentas
- M√©tricas exibidas na UI ficam confusas (21min √© anormal)

**Causa Prov√°vel:**
1. ‚ùì **C√°lculo de m√©dia incorreto** - Outliers n√£o tratados (timeout de 30s gera valores negativos ou muito altos)
2. ‚ùì **Timeout de navega√ß√£o** - Scraper aguardou 21min por timeout
3. ‚ùì **Site externo lento** - Fundamentus.com.br pode ter tido lentid√£o pontual

**Solu√ß√£o Proposta:**
1. ‚úÖ **Analisar dados brutos** - SELECT * FROM scraper_metrics WHERE scraper_id='fundamentus'
2. ‚úÖ **Validar c√°lculo de avgResponseTime** - Verificar l√≥gica no ScraperMetricsService
3. ‚úÖ **Adicionar mediana ao inv√©s de m√©dia** - Menos sens√≠vel a outliers
4. ‚úÖ **Filtrar outliers** - Ignorar valores > 60s (timeout m√°ximo)
5. ‚úÖ **Adicionar campo `median_response_time`** - M√©trica mais confi√°vel

**An√°lise do C√≥digo Atual:**

```typescript
// backend/src/scrapers/scraper-metrics.service.ts (linhas 60-95)
async getMetricsSummary(scraperId: string): Promise<MetricsSummary | null> {
  const metrics = await this.scraperMetricRepository.find({
    where: { scraperId },
    order: { createdAt: 'DESC' },
    take: 100, // √öltimos 100 registros (aprox. 30 dias)
  });

  if (metrics.length === 0) {
    return null;
  }

  const totalRequests = metrics.length;
  const failedRequests = metrics.filter(m => !m.success).length;
  const successRate = ((totalRequests - failedRequests) / totalRequests) * 100;

  // PROBLEMA: C√°lculo de m√©dia simples (n√£o trata outliers)
  const avgResponseTime = Math.round(
    metrics.reduce((sum, m) => sum + m.responseTime, 0) / totalRequests
  );

  // ...
}
```

**Corre√ß√£o:**
```typescript
// Adicionar c√°lculo de mediana e filtrar outliers
const responseTimes = metrics
  .map(m => m.responseTime)
  .filter(time => time > 0 && time < 60000) // Filtrar outliers (< 60s)
  .sort((a, b) => a - b);

const avgResponseTime = responseTimes.length > 0
  ? Math.round(responseTimes.reduce((sum, t) => sum + t, 0) / responseTimes.length)
  : 0;

const medianResponseTime = responseTimes.length > 0
  ? responseTimes[Math.floor(responseTimes.length / 2)]
  : 0;
```

---

### ‚ö†Ô∏è Problema 3: Investsite - Taxa de Sucesso 61.5%

**Descri√ß√£o:**
- Scraper "Investsite" (https://www.investsite.com.br) retorna **61.5%** de taxa de sucesso
- **Dados do banco:** 13 tentativas, 5 falhas (38.5%)
- **√öltimo teste:** 14/11/2025, 17:00:25

**Impacto:**
- üü° BAIXO - Taxa aceit√°vel, mas inst√°vel
- Cross-validation ainda funcional (5/6 fontes ativas)
- Intermit√™ncia pode indicar problema do site externo

**Causa Prov√°vel:**
1. ‚ùì **Intermit√™ncia do site externo** - Investsite.com.br pode ter instabilidade
2. ‚ùì **Mudan√ßas espor√°dicas no HTML** - Site pode ter A/B testing ou deploy incremental
3. ‚ùì **Bloqueio de bot ocasional** - Pode estar detectando scraper algumas vezes

**Solu√ß√£o Proposta:**
1. ‚úÖ **Monitorar m√©tricas por 7 dias** - Coletar mais dados antes de agir
2. ‚úÖ **Adicionar retry autom√°tico** - 3 tentativas com delay de 2s entre elas
3. ‚úÖ **Adicionar logging detalhado** - Capturar erro exato quando falha
4. ‚úÖ **Criar alerta autom√°tico** - Se taxa < 50% por 24h, notificar

**Implementa√ß√£o de Retry:**
```typescript
// backend/src/scrapers/investsite.scraper.ts
async scrape(ticker: string): Promise<ScraperResult> {
  const MAX_RETRIES = 3;
  const RETRY_DELAY = 2000; // 2s

  for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
    try {
      const result = await this.scrapeInternal(ticker);
      return result;
    } catch (error) {
      this.logger.warn(
        `Investsite scraper failed (attempt ${attempt}/${MAX_RETRIES}): ${error.message}`
      );

      if (attempt < MAX_RETRIES) {
        await this.delay(RETRY_DELAY * attempt); // Backoff exponencial
      } else {
        throw error; // √öltima tentativa falhou
      }
    }
  }
}

private delay(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}
```

---

## üìã PLANO DE IMPLEMENTA√á√ÉO

### Fase 1: Investiga√ß√£o (Ultra-Thinking) ‚è±Ô∏è 30 minutos

**1.1. Analisar Logs do Backend**
```bash
docker logs invest_backend | grep -i "fundamentei\|investsite" | tail -50
```

**1.2. Analisar Dados do Banco**
```sql
-- Fundamentei (problema 1)
SELECT * FROM scraper_metrics
WHERE scraper_id = 'fundamentei'
ORDER BY created_at DESC
LIMIT 10;

-- Fundamentus (problema 2)
SELECT
  scraper_id,
  response_time,
  success,
  error_message,
  created_at
FROM scraper_metrics
WHERE scraper_id = 'fundamentus'
ORDER BY created_at DESC;

-- Investsite (problema 3)
SELECT
  COUNT(*) as total,
  SUM(CASE WHEN success = true THEN 1 ELSE 0 END) as successes,
  SUM(CASE WHEN success = false THEN 1 ELSE 0 END) as failures,
  ROUND(AVG(response_time)) as avg_time
FROM scraper_metrics
WHERE scraper_id = 'investsite';
```

**1.3. Testar Scrapers Manualmente**
```bash
# Via endpoint REST
curl -X POST http://localhost:3101/api/v1/scrapers/test/fundamentei \
  -H "Content-Type: application/json" \
  -d '{"ticker": "PETR4"}' | jq

curl -X POST http://localhost:3101/api/v1/scrapers/test/fundamentus \
  -H "Content-Type: application/json" \
  -d '{"ticker": "PETR4"}' | jq

curl -X POST http://localhost:3101/api/v1/scrapers/test/investsite \
  -H "Content-Type: application/json" \
  -d '{"ticker": "PETR4"}' | jq
```

---

### Fase 2: Corre√ß√£o Problema 1 - Fundamentei Scraper ‚è±Ô∏è 1-2 horas

**2.1. Ler C√≥digo do Scraper**
```bash
# Identificar arquivo do scraper
find . -name "*fundamentei*" -type f
```

**2.2. Analisar Estrutura HTML do Site**
- Navegar manualmente em https://fundamentei.com
- Verificar se requer autentica√ß√£o
- Inspecionar elementos (DevTools)
- Verificar se seletores CSS mudaram

**2.3. Implementar Corre√ß√µes**
- [ ] Atualizar seletores CSS (se mudou estrutura HTML)
- [ ] Validar/Renovar cookies OAuth (se auth falhou)
- [ ] Aumentar timeout de 30s para 60s
- [ ] Adicionar retry com backoff (3 tentativas, delay 2s/4s/8s)
- [ ] Adicionar logging detalhado de erros

**2.4. Testar Corre√ß√£o**
```bash
# Teste unit√°rio do scraper
curl -X POST http://localhost:3101/api/v1/scrapers/test/fundamentei \
  -H "Content-Type: application/json" \
  -d '{"ticker": "PETR4"}' | jq

# Verificar m√©trica salva no banco
docker exec -it invest_postgres psql -U invest_user -d invest_db \
  -c "SELECT * FROM scraper_metrics WHERE scraper_id = 'fundamentei' ORDER BY created_at DESC LIMIT 1;"
```

---

### Fase 3: Corre√ß√£o Problema 2 - Fundamentus Tempo M√©dio ‚è±Ô∏è 30 minutos

**3.1. Ler C√≥digo do ScraperMetricsService**
```typescript
// backend/src/scrapers/scraper-metrics.service.ts
```

**3.2. Implementar Corre√ß√µes**

**Arquivo:** `backend/src/scrapers/scraper-metrics.service.ts`

**Mudan√ßas:**
```typescript
// ANTES (linha 85-88)
const avgResponseTime = Math.round(
  metrics.reduce((sum, m) => sum + m.responseTime, 0) / totalRequests
);

// DEPOIS
const responseTimes = metrics
  .map(m => m.responseTime)
  .filter(time => time > 0 && time < 60000) // Filtrar outliers (0ms e > 60s)
  .sort((a, b) => a - b);

const avgResponseTime = responseTimes.length > 0
  ? Math.round(responseTimes.reduce((sum, t) => sum + t, 0) / responseTimes.length)
  : 0;

const medianResponseTime = responseTimes.length > 0
  ? responseTimes[Math.floor(responseTimes.length / 2)]
  : 0;
```

**3.3. Atualizar DTO (Opcional)**

**Arquivo:** `backend/src/scrapers/scrapers.controller.ts`

Adicionar campo `medianResponseTime` ao DTO se quiser expor na API.

**3.4. Testar Corre√ß√£o**
```bash
# Buscar m√©tricas via API
curl http://localhost:3101/api/v1/scrapers/status | jq '.[] | select(.id == "fundamentus")'

# Verificar se avgResponseTime est√° razo√°vel (< 30s)
```

---

### Fase 4: Corre√ß√£o Problema 3 - Investsite Retry Logic ‚è±Ô∏è 1 hora

**4.1. Ler C√≥digo do Scraper**
```bash
find . -name "*investsite*" -type f
```

**4.2. Implementar Retry com Backoff**

**Arquivo:** `backend/src/scrapers/fundamental/investsite.scraper.ts` (ou similar)

```typescript
export class InvestsiteScraper {
  private readonly MAX_RETRIES = 3;
  private readonly RETRY_DELAY_BASE = 2000; // 2s

  async scrape(ticker: string): Promise<ScraperResult> {
    for (let attempt = 1; attempt <= this.MAX_RETRIES; attempt++) {
      try {
        this.logger.log(`Investsite scraper attempt ${attempt}/${this.MAX_RETRIES} for ${ticker}`);

        const result = await this.scrapeInternal(ticker);

        this.logger.log(`Investsite scraper succeeded for ${ticker} (attempt ${attempt})`);
        return result;

      } catch (error) {
        this.logger.warn(
          `Investsite scraper failed for ${ticker} (attempt ${attempt}/${this.MAX_RETRIES}): ${error.message}`
        );

        if (attempt < this.MAX_RETRIES) {
          const delay = this.RETRY_DELAY_BASE * attempt; // Backoff: 2s, 4s, 6s
          this.logger.log(`Retrying in ${delay}ms...`);
          await this.delay(delay);
        } else {
          this.logger.error(`Investsite scraper failed after ${this.MAX_RETRIES} attempts for ${ticker}`);
          throw error;
        }
      }
    }
  }

  private async scrapeInternal(ticker: string): Promise<ScraperResult> {
    // L√≥gica atual do scraper (renomear m√©todo existente)
    // ...
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

**4.3. Testar Corre√ß√£o**
```bash
# Testar retry (deve tentar 3x se falhar)
curl -X POST http://localhost:3101/api/v1/scrapers/test/investsite \
  -H "Content-Type: application/json" \
  -d '{"ticker": "TICKER_INVALIDO"}' | jq

# Verificar logs (deve mostrar 3 tentativas)
docker logs invest_backend | grep -i "investsite.*attempt" | tail -10
```

---

### Fase 5: Valida√ß√£o com MCP Triplo ‚è±Ô∏è 30 minutos

**5.1. Reiniciar Backend**
```bash
docker restart invest_backend
# Aguardar 30s para backend ficar healthy
docker ps --filter "name=invest_backend" --format "{{.Status}}"
```

**5.2. Testar Todos os Scrapers**
```bash
# Testar cada scraper com PETR4
for scraper in fundamentus brapi statusinvest investidor10 fundamentei investsite; do
  echo "Testing $scraper..."
  curl -X POST http://localhost:3101/api/v1/scrapers/test/$scraper \
    -H "Content-Type: application/json" \
    -d '{"ticker": "PETR4"}' | jq '.success'
  sleep 2
done
```

**5.3. Validar M√©tricas no Banco**
```sql
SELECT
  scraper_id,
  COUNT(*) as total_tests,
  SUM(CASE WHEN success = true THEN 1 ELSE 0 END) as successes,
  ROUND(AVG(CASE WHEN response_time > 0 AND response_time < 60000 THEN response_time END)) as avg_time_filtered
FROM scraper_metrics
WHERE created_at > NOW() - INTERVAL '1 hour'
GROUP BY scraper_id
ORDER BY scraper_id;
```

**5.4. Valida√ß√£o Frontend com MCP Triplo**

**Playwright MCP:**
```javascript
// Navegar para /data-sources
await page.goto('http://localhost:3100/data-sources');
await page.waitForSelector('text=Fontes de Dados');

// Screenshot
await page.screenshot({ path: 'validation-screenshots/data-sources-after-fixes.png', fullPage: true });

// Console errors
const errors = await page.evaluate(() => {
  return window.console.errors || [];
});
console.log('Console Errors:', errors.length);
```

**Chrome DevTools MCP:**
```javascript
// Navegar e verificar m√©tricas atualizadas
await navigate('http://localhost:3100/data-sources');
await waitFor('Fundamentei'); // Deve aparecer com taxa > 0%

// Verificar console
const consoleMessages = await listConsoleMessages({ types: ['error', 'warn'] });
console.log('Console Messages:', consoleMessages);
```

**Sequential Thinking MCP:**
- Analisar se taxas de sucesso melhoraram
- Verificar se tempo m√©dio do Fundamentus est√° razo√°vel (< 30s)
- Confirmar se Fundamentei e Investsite t√™m taxa > 70%

---

### Fase 6: Atualizar Documenta√ß√£o ‚è±Ô∏è 15 minutos

**6.1. Atualizar CLAUDE.md**

Adicionar se√ß√£o:

```markdown
### FASE 26: Manuten√ß√£o de Scrapers ‚úÖ 100% COMPLETO (2025-11-14)
Corre√ß√£o de 3 problemas n√£o-bloqueantes identificados na Valida√ß√£o MCP Triplo.

**Problemas Corrigidos:**
1. ‚úÖ **Fundamentei Scraper - 0% ‚Üí X%**
   - Causa: [DESCREVER CAUSA IDENTIFICADA]
   - Solu√ß√£o: [DESCREVER SOLU√á√ÉO APLICADA]
   - Resultado: Taxa de sucesso agora em X%

2. ‚úÖ **Fundamentus - Tempo M√©dio 21min ‚Üí Xs**
   - Causa: C√°lculo de m√©dia sem filtrar outliers
   - Solu√ß√£o: Filtrar response_time < 60s + usar mediana
   - Resultado: Tempo m√©dio agora em Xs (razo√°vel)

3. ‚úÖ **Investsite - Taxa 61.5% ‚Üí X%**
   - Causa: Intermit√™ncia do site externo
   - Solu√ß√£o: Retry autom√°tico (3 tentativas, backoff exponencial)
   - Resultado: Taxa de sucesso agora em X%

**Arquivos Modificados:**
- `backend/src/scrapers/fundamental/fundamentei.scraper.ts` (+XX linhas)
- `backend/src/scrapers/scraper-metrics.service.ts` (+XX linhas)
- `backend/src/scrapers/fundamental/investsite.scraper.ts` (+XX linhas)

**Valida√ß√£o:**
- ‚úÖ TypeScript: 0 erros
- ‚úÖ Build: Success
- ‚úÖ MCP Triplo: 0 console errors
- ‚úÖ M√©tricas: 6/6 fontes com taxa > 70%

**Commits:**
- [HASH] - fix: Corrigir Fundamentei scraper (atualizar seletores CSS)
- [HASH] - fix: Corrigir c√°lculo de avgResponseTime (filtrar outliers)
- [HASH] - feat: Adicionar retry logic em Investsite scraper

**Tempo:** X horas
**Status:** ‚úÖ 100% COMPLETO
```

**6.2. Marcar FASE 25 como Completa**

Atualizar se√ß√£o FASE 25 no CLAUDE.md:

```markdown
### FASE 25: Refatora√ß√£o Bot√£o "Solicitar An√°lises" ‚úÖ 100% COMPLETO (2025-11-XX)
- [x] Remover bot√£o de /assets ‚úÖ (j√° removido)
- [x] Adicionar bot√£o em /analysis ‚úÖ (j√° implementado - linha 364)
- [x] Adicionar Tooltip sobre coleta multi-fonte ‚úÖ (j√° implementado - linha 373-379)
- [x] Validar backend coleta de TODAS as fontes ‚úÖ
- [x] Testes de funcionalidade ‚úÖ

**Status:** ‚úÖ Implementado anteriormente, documenta√ß√£o atualizada em 2025-11-14
```

---

## ‚úÖ CHECKLIST DE VALIDA√á√ÉO

### T√©cnica
- [ ] TypeScript: 0 erros (backend + frontend)
- [ ] Build: Success (backend + frontend)
- [ ] Console: 0 erros, 0 warnings
- [ ] Testes de scrapers: 6/6 fontes com sucesso
- [ ] M√©tricas no banco: avgResponseTime razo√°vel (< 30s)
- [ ] Taxa de sucesso: Todas as fontes > 70%

### Funcional
- [ ] Fundamentei: Taxa de sucesso > 70%
- [ ] Fundamentus: Tempo m√©dio < 30s
- [ ] Investsite: Taxa de sucesso > 70%
- [ ] Retry logic: Logs mostram 3 tentativas em caso de falha
- [ ] UI /data-sources: M√©tricas atualizadas corretamente

### MCP Triplo
- [ ] Playwright: 0 console errors na p√°gina /data-sources
- [ ] Chrome DevTools: 0 warnings na p√°gina /data-sources
- [ ] Sequential Thinking: An√°lise l√≥gica confirmando corre√ß√µes

### Documenta√ß√£o
- [ ] CLAUDE.md: Se√ß√£o FASE 26 adicionada
- [ ] CLAUDE.md: Se√ß√£o FASE 25 marcada como completa
- [ ] FASE_26_MANUTENCAO_SCRAPERS.md: Completo com resultados
- [ ] Commits: 3 commits com mensagens detalhadas + Co-Authored-By

### Git
- [ ] Git status: Limpo
- [ ] Branch main: Atualizada
- [ ] Push: Realizado com sucesso

---

## üéØ CRIT√âRIOS DE SUCESSO

‚úÖ **APROVADO** se:
1. Fundamentei: Taxa de sucesso ‚â• 70%
2. Fundamentus: Tempo m√©dio ‚â§ 30s
3. Investsite: Taxa de sucesso ‚â• 70%
4. TypeScript: 0 erros
5. Console: 0 erros, 0 warnings
6. Git: Limpo e atualizado

‚ùå **REPROVAR** se:
- Qualquer scraper com taxa < 50%
- Erros de TypeScript
- Console errors n√£o resolvidos
- Git com arquivos n√£o commitados

---

**Criado por:** Claude Code (Sonnet 4.5)
**Data:** 2025-11-14 18:45
**Estimativa:** 3-4 horas
**Prioridade:** ALTA (Resolver n√£o-bloqueantes antes de novas features)
