# Bugs Identificados Durante Coleta - 2025-12-22

## Status: EM COLETA (Op√ß√£o 2 - Corrigir Depois)

**Decis√£o:** Continuar coletando todos os 861 ativos PRIMEIRO, depois corrigir bugs e recoletar.

**Per√≠odo de An√°lise:** 16:32-17:04 (32 minutos)
**Ativos Analisados:** 53 fundamentals salvos
**Bugs Identificados:** 6 cr√≠ticos

---

## BUG #1: Fundamentus - Parsing B/M/K Ausente üî¥ CR√çTICO

**Arquivo:** `backend/python-scrapers/scrapers/fundamentus_scraper.py:345-384`
**Fun√ß√£o:** `_parse_value()`

### Evid√™ncia Real

```json
{
  "ticker": "ATED3",
  "source": "python-fundamentus",
  "receitaLiquida": 283640006306000,
  "ebit": 22.34,
  "lucroLiquido": -4926000,
  "patrimonioLiquido": 20250000
}
```

**An√°lise:**
- `receitaLiquida`: 283.640.006.306.000 = **283 TRILH√ïES** üò±
- Valor esperado: ~283 milh√µes (ou 283.640.006 com casas decimais)
- **Desvio:** 1.000.000x (um milh√£o de vezes maior!)

### Causa Raiz

```python
# C√ìDIGO ATUAL (fundamentus_scraper.py:345-384)
def _parse_value(self, text: str) -> float | None:
    """
    Formato brasileiro: 1.234.567,89 ‚Üí 1234567.89
    Percentuais: "5,75%" ‚Üí 5.75
    """
    # Remove % se existir
    if "%" in text:
        text = text.replace("%", "").strip()

    # Formato BR: troca , por . (decimal)
    text = text.replace(".", "").replace(",", ".")

    # ‚ùå FALTA: Detec√ß√£o de sufixos B/M/K
    # "2,5 Bi" ‚Üí "25 Bi" ‚Üí "25" ‚Üí 2.5 (ERRADO!)
    # Deveria: "2,5 Bi" ‚Üí 2.500.000.000

    return float(text)
```

### Comportamento Observado

| Input | Output Atual | Output Esperado | Erro |
|-------|--------------|-----------------|------|
| "2,5 Bi" | 2.5 | 2.500.000.000 | 1.000.000.000x |
| "283,64 Mi" | 283.64 | 283.640.000 | 1.000.000x |
| "1,5 B" | 1.5 | 1.500.000.000 | 1.000.000.000x |
| "500 K" | 500 | 500.000 | 1.000x |

### Solu√ß√£o (Copiar de investsite_scraper.py)

```python
def _parse_value(self, text: str) -> float | None:
    """
    Suporta formato brasileiro + sufixos B/M/K
    Baseado em: investsite_scraper.py:303-346
    """
    text = text.lower().strip()

    # Remove %
    if "%" in text:
        text = text.replace("%", "").strip()

    # Detectar sufixos de magnitude
    multiplier = 1
    if "bi" in text or " b" in text:
        multiplier = 1_000_000_000
        text = text.replace("bi", "").replace("b", "").strip()
    elif "mi" in text or " m" in text:
        multiplier = 1_000_000
        text = text.replace("mi", "").replace("m", "").strip()
    elif " k" in text:
        multiplier = 1_000
        text = text.replace("k", "").strip()

    # Formato brasileiro: 1.234.567,89 ‚Üí 1234567.89
    text = text.replace(".", "").replace(",", ".")

    try:
        return float(text) * multiplier
    except:
        return None
```

### Campos Afetados

- ‚úÖ receitaLiquida
- ‚úÖ lucroLiquido
- ‚úÖ ebit
- ‚úÖ ebitda
- ‚úÖ patrimonioLiquido
- ‚úÖ ativoTotal
- ‚úÖ dividaBruta
- ‚úÖ dividaLiquida
- ‚úÖ disponibilidades

### Prioridade

**P0 - URGENTE**
- Impacto: Todos valores absolutos financeiros
- Frequ√™ncia: 100% dos ativos com sufixos
- Severidade: Dados 1.000.000x errados

---

## BUG #2: Investidor10 - Parsing Decimal Brasileiro üî¥ CR√çTICO

**Arquivo:** `backend/python-scrapers/scrapers/investidor10_scraper.py:351-378`
**Fun√ß√µes:** `_parse_indicator_value()` + `_parse_number()` (DUAS fun√ß√µes - inconsist√™ncia!)

### Evid√™ncia Real

```json
{
  "ticker": "ASRF11",
  "source": "investidor10",
  "price": 1110974,
  "pl": 0,
  "pvp": 1.13
}
```

**An√°lise:**
- `price`: 1.110.974 (deveria ser 10,974 ou 10.974 em formato BR)
- `pvp`: 1.13 ‚úÖ (CORRETO - parsing funcionou aqui!)
- **Inconsist√™ncia:** Mesma fun√ß√£o trata PVP certo mas pre√ßo errado

### Causa Raiz

```python
# C√ìDIGO ATUAL (investidor10_scraper.py:351-378)
def _parse_indicator_value(self, text: str) -> float | None:
    # Remove formata√ß√£o brasileira
    text = text.replace(".", "").replace(",", ".")
    # "10.974" ‚Üí "10974" ‚Üí float("10974") ‚Üí 10974.0 ‚ùå

    # Problema: N√£o identifica se √© pre√ßo com 3 decimais
    # "10.974" no BR = R$ 10,974 (v√≠rgula ap√≥s 10)
    # Mas c√≥digo interpreta como "10974" (dez mil)

    return float(text)
```

### Exemplos de Falha

| Input BR | Ap√≥s Replace | Float | Esperado | Erro |
|----------|--------------|-------|----------|------|
| "10.974" | "10974" | 10974.0 | 10.974 | 1000x |
| "1.234,56" | "123456" | 123456.0 | 1234.56 | 100x |
| "109,74" | "10974" | 10974.0 | 109.74 | 100x |

### Solu√ß√£o

```python
def _parse_number(self, text: str) -> float | None:
    """
    Parsing robusto de n√∫meros brasileiros
    """
    text = text.strip()

    # Se tem v√≠rgula, √© decimal brasileiro
    if "," in text:
        # "1.234,56" ‚Üí remove pontos ‚Üí "1234,56" ‚Üí troca v√≠rgula ‚Üí "1234.56"
        text = text.replace(".", "")
        text = text.replace(",", ".")
        return float(text)

    # Se tem ponto mas n√£o tem v√≠rgula, pode ser milhar OU decimal
    if "." in text:
        parts = text.split(".")
        if len(parts[-1]) == 3:  # √öltimo grupo tem 3 d√≠gitos = milhar
            # "10.974" ‚Üí "10974"
            return float(text.replace(".", ""))
        elif len(parts[-1]) <= 2:  # 1-2 d√≠gitos = decimal
            # "10.97" ‚Üí 10.97
            return float(text)

    return float(text)
```

**Problema da solu√ß√£o:** Ambiguidade! "10.974" pode ser:
- R$ 10,974 (dez reais e 974 centavos)
- 10.974 (dez mil novecentos e setenta e quatro)

**Necessita contexto do campo!**

### Prioridade

**P0 - URGENTE**
- Impacto: Pre√ßos completamente errados
- Frequ√™ncia: ~30% dos casos
- Severidade: Impossibilita uso dos dados

---

## BUG #3: Investsite - Seletor Captura Data em Vez de Pre√ßo üî¥ CR√çTICO

**Arquivo:** `backend/python-scrapers/scrapers/investsite_scraper.py`
**Fun√ß√£o:** Extra√ß√£o de `price`

### Evid√™ncia Real

```json
{
  "ticker": "ATED3",
  "source": "investsite",
  "price": 19122025,  // 19/12/2025!
  "companyName": "ATOM EDUC () Principais Indicadores"
}
```

**An√°lise:**
- `price`: 19122025 = 19/12/2025 (data de hoje!)
- `companyName`: "ATOM EDUC () Principais Indicadores" (tem "() " vazio - bug HTML)

### Causa Raiz

**Seletor CSS/XPath est√° capturando elemento errado:**
- Elemento correto: `<span class="price">2,12</span>`
- Elemento capturado: `<span class="date">19/12/2025</span>`

**Poss√≠veis causas:**
1. Seletor muito gen√©rico: `.price` tamb√©m existe em outro lugar
2. Ordem de elementos mudou no HTML
3. JavaScript din√¢mico muda estrutura da p√°gina

### Solu√ß√£o

```python
# Adicionar valida√ß√£o p√≥s-parsing
def _extract_price(self, soup):
    price_text = soup.select_one('.cotacao .value').text  # Seletor mais espec√≠fico

    price = self._parse_value(price_text)

    # VALIDA√á√ÉO: Pre√ßo n√£o pode ser > 1 milh√£o (suspeito de ser data)
    if price and price > 1_000_000:
        self.logger.warning(f"Price suspiciously high: {price}, might be parsing date")
        return None

    return price
```

### Prioridade

**P0 - URGENTE**
- Impacto: Pre√ßos completamente inv√°lidos
- Frequ√™ncia: ~20% dos casos (alguns tickers)
- Severidade: Cross-validation falha

---

## BUG #4: Normaliza√ß√£o de Percentuais Inconsistente üî¥ CR√çTICO

**Arquivo:** `backend/src/scrapers/scrapers.service.ts` (orquestra√ß√£o)

### Evid√™ncia Real

```json
{
  "ticker": "ANCR11",
  "roe": -2595.29,  // -2595%!
  "source": "fundamental_data (ap√≥s cross-validation)"
}
```

**An√°lise:**
- ROE: -2595.29% (ABSURDO - imposs√≠vel!)
- Valor esperado: -25.95% ou -0.2595 (formato decimal)
- **Erro:** Multiplica√ß√£o 100x

### Causa Raiz

**Scrapers retornam formatos DIFERENTES:**

| Scraper | Formato ROE | Exemplo | Valor Real |
|---------|-------------|---------|------------|
| Fundamentus | `25.95` | "25.95%" na p√°gina | 25.95% |
| StatusInvest | `25.95` | "25.95%" na p√°gina | 25.95% |
| Investidor10 | `0.2595` | Decimal 0-1 | 25.95% |
| BRAPI | N/A | N√£o fornece | - |

**Cross-validation n√£o normaliza antes de comparar:**
- Compara 25.95 vs 0.2595 ‚Üí Desvio 9.900% (!)
- Depois multiplica por 100 em algum lugar ‚Üí -2595%

### Solu√ß√£o

```typescript
// backend/src/scrapers/scrapers.service.ts
private normalizePercentageField(
  value: number,
  field: string,
  source: string
): number {
  const percentFields = [
    'roe', 'roa', 'roic',
    'margemBruta', 'margemEbit', 'margemLiquida',
    'dividendYield', 'payout'
  ];

  if (!percentFields.includes(field)) return value;

  // Detectar formato por source
  const decimalSources = ['investidor10'];  // Retorna 0-1
  const percentSources = ['fundamentus', 'statusinvest', 'investsite'];  // Retorna 0-100

  if (decimalSources.includes(source) && Math.abs(value) <= 1) {
    return value * 100;  // 0.2595 ‚Üí 25.95
  }

  if (percentSources.includes(source) && Math.abs(value) > 100) {
    return value / 100;  // 2595 ‚Üí 25.95 (caso de erro)
  }

  return value;
}
```

### Prioridade

**P0 - URGENTE**
- Impacto: ROE, margens, DY com valores absurdos
- Frequ√™ncia: ~10% dos ativos
- Severidade: Dados financeiros in√∫teis

---

## BUG #5: StatusInvest - Ticker Redirect üü° M√âDIO

**Arquivo:** `backend/python-scrapers/scrapers/statusinvest_scraper.py`

### Evid√™ncia Real

```json
{
  "requestedTicker": "ATED3",
  "returnedData": {
    "ticker": "ATED3",           // ‚Üê Retorna ticker solicitado
    "companyName": "ATSA11",     // ‚Üê Mas dados s√£o de ATSA11!
    "sector": "Shoppings",        // ‚Üê Setor de FII (ATSA11)
    "price": 58                   // ‚Üê Pre√ßo de ATSA11 (~R$ 58)
  }
}
```

**Compara√ß√£o:**
- **ATED3** (Atom Educ): A√ß√£o de educa√ß√£o, pre√ßo ~R$ 2,12
- **ATSA11** (FII Hatrium): FII de shopping, pre√ßo ~R$ 58

**An√°lise:**
Site StatusInvest **redirecionou** ATED3 ‚Üí ATSA11 (tickers similares), mas scraper n√£o detectou.

### Causa Raiz

```python
# Scraper navega para: https://statusinvest.com.br/acoes/ATED3
# Site redireciona para: https://statusinvest.com.br/fiis/ATSA11
# Scraper extrai dados sem verificar URL final ou ticker no HTML
```

### Solu√ß√£o

```python
async def scrape(self, ticker: str):
    url = f"https://statusinvest.com.br/acoes/{ticker}"
    await self.page.goto(url)

    # VALIDA√á√ÉO: Verificar ticker no HTML
    actual_ticker = await self.page.locator('.ticker-name').text_content()

    if actual_ticker.strip().upper() != ticker.upper():
        raise ValueError(
            f"Ticker mismatch: requested {ticker}, got {actual_ticker}. "
            f"Possible redirect."
        )

    # Continuar scraping...
```

### Prioridade

**P1 - IMPORTANTE**
- Impacto: Cross-validation compara ativos diferentes
- Frequ√™ncia: ~5% (tickers similares)
- Severidade: Dados incorretos mas detect√°vel

---

## BUG #6: Data Validation Failed em FIIs üü° M√âDIO

**Arquivos:**
- `backend/python-scrapers/scrapers/fundamentus_scraper.py`
- `backend/python-scrapers/scrapers/investsite_scraper.py`

### Evid√™ncias Reais

```
[ERROR] Failed to scrape BBFO11 from fundamentus: Data validation failed
[ERROR] Failed to scrape BBIG11 from fundamentus: Data validation failed
[ERROR] Failed to scrape BBRC11 from fundamentus: Data validation failed
[ERROR] Failed to scrape BBFI11 from investsite: Data validation failed
[ERROR] Failed to scrape ASMT11 from investsite: Data validation failed
[ERROR] Failed to scrape ASRF11 from investsite: Data validation failed (mas depois passou)
[ERROR] Failed to scrape ATSA11 from fundamentus: Data validation failed
[ERROR] Failed to scrape APTO11 from fundamentus: Data validation failed
[ERROR] Failed to scrape AURB11 from fundamentus: Data validation failed
```

**Padr√£o:** 100% dos erros s√£o em **FIIs** (ticker termina em "11")

### Causa Raiz

**Schema validation est√° muito restrito para FIIs:**

```python
# Valida√ß√£o atual (hip√≥tese):
required_fields = ['pl', 'pvp', 'roe', 'roic']

# Problema: FIIs N√ÉO T√äM esses campos!
# - FII n√£o tem P/L (fundos n√£o t√™m lucro da mesma forma)
# - FII n√£o tem ROE (n√£o √© equity)
# - FII tem: DY, P/VP, Liquidez, Cota√ß√£o
```

### Solu√ß√£o

```python
def validate_data(self, data: dict, ticker: str) -> bool:
    # Detectar tipo de ativo
    is_fii = ticker.endswith('11')

    if is_fii:
        # FIIs: validar campos espec√≠ficos
        required = ['price', 'pvp', 'dy']  # Dividend Yield √© cr√≠tico
        optional = ['pl', 'roe']  # Podem ser null
    else:
        # A√ß√µes: validar campos tradicionais
        required = ['price']
        optional = ['pl', 'pvp', 'roe']

    # Validar apenas required fields
    for field in required:
        if data.get(field) is None:
            return False

    return True
```

### Prioridade

**P1 - IMPORTANTE**
- Impacto: FIIs n√£o s√£o coletados por 2 scrapers (Fundamentus, Investsite)
- Frequ√™ncia: ~40% dos ativos (todos FIIs)
- Severidade: Perda de cobertura para FIIs

---

## BUG #7: Investidor10 - Navega√ß√£o com "page.content: Unable to retrieve" üü° M√âDIO

**Arquivo:** `backend/python-scrapers/scrapers/investidor10_scraper.py`

### Evid√™ncia Real

```
[ERROR] Failed to scrape ADMF3 from investidor10:
  page.content: Unable to retrieve content because the page is
  navigating and changing the content.
```

### Causa Raiz

```python
# Scraper chama page.content() ANTES da p√°gina terminar de carregar
await page.goto(url)
html = await page.content()  # ‚ùå P√°gina ainda navegando!
```

### Solu√ß√£o

```python
await page.goto(url, wait_until='networkidle')  # Aguardar rede estabilizar
await page.wait_for_load_state('domcontentloaded')  # DOM completo
html = await page.content()  # ‚úÖ Agora √© seguro
```

### Prioridade

**P1 - IMPORTANTE**
- Impacto: Falhas intermitentes
- Frequ√™ncia: ~5% dos casos
- Severidade: Reduz cobertura

---

## BUG #8: BRAPI - Rate Limiting e Timeouts üü¢ BAIXO

**Arquivo:** `backend/src/scrapers/fundamental/brapi.scraper.ts`

### Evid√™ncias

```
Tempo m√©dio BRAPI: ~12s (alguns chegam a 71s!)
Timeout observado: 71.518s para AERI3
```

### Causa Raiz

- API p√∫blica com rate limiting
- Sem retry exponential backoff
- Timeout muito alto permite scraper "travar"

### Solu√ß√£o

```typescript
// Adicionar retry com backoff
const response = await retry(
  () => fetch(url, { timeout: 15000 }),  // 15s timeout
  {
    retries: 3,
    factor: 2,  // Exponential backoff
    minTimeout: 1000,
    maxTimeout: 5000,
  }
);
```

### Prioridade

**P2 - BAIXA**
- Impacto: Performance (n√£o dados)
- Frequ√™ncia: ~10% dos requests
- Severidade: Apenas lentid√£o

---

## Resumo de Bugs por Prioridade

### P0 - CR√çTICOS (Corrigir Primeiro)

| # | Bug | Arquivo | Impacto | Frequ√™ncia |
|---|-----|---------|---------|------------|
| 1 | Parsing B/M/K | fundamentus_scraper.py | Valores 1.000.000x errados | 100% valores absolutos |
| 2 | Parsing Decimal | investidor10_scraper.py | Pre√ßos 100-1000x errados | ~30% |
| 3 | Seletor de Pre√ßo | investsite_scraper.py | Pre√ßos = datas | ~20% |
| 4 | Normaliza√ß√£o % | scrapers.service.ts | ROE/margens 100x | ~10% |

**Total P0:** 4 bugs
**Tempo Estimado:** 4-6 horas
**Impacto ao Corrigir:** Confidence deve subir de 48.8% ‚Üí ~70%+

### P1 - IMPORTANTES (Corrigir em Seguida)

| # | Bug | Impacto | Tempo |
|---|-----|---------|-------|
| 5 | Ticker Redirect | Cross-validation errada | 1h |
| 6 | Valida√ß√£o FIIs | FIIs n√£o coletados | 2h |
| 7 | Page Navigation | Falhas intermitentes | 1h |

**Total P1:** 3 bugs
**Tempo Estimado:** 4 horas

### P2 - MELHORIAS (Backlog)

| # | Bug | Impacto | Tempo |
|---|-----|---------|-------|
| 8 | BRAPI Timeouts | Performance | 1h |
| 9 | Duas fun√ß√µes parse (Inv10) | Inconsist√™ncia | 1h |

**Total P2:** 2 bugs
**Tempo Estimado:** 2 horas

---

## Estrat√©gia de Corre√ß√£o (Op√ß√£o 2)

### Fase 1: Continuar Coleta (EM ANDAMENTO)

```
‚úÖ Deixar coleta completar 861 ativos (~20h)
‚úÖ Documentar TODOS os bugs encontrados
‚úÖ Coletar estat√≠sticas de erro por scraper
‚úÖ Identificar padr√µes de falha
```

### Fase 2: An√°lise P√≥s-Coleta

```
1. Analisar discrep√¢ncias geradas
2. Classificar por severidade
3. Identificar campos mais problem√°ticos
4. Priorizar corre√ß√µes
```

### Fase 3: Corre√ß√µes em Bloco

```
1. [4-6h] Implementar todas corre√ß√µes P0
2. [2h] Testes com 100 ativos
3. [1h] Valida√ß√£o TypeScript + Build
```

### Fase 4: Limpeza + Recoleta

```
1. Limpar dados antigos (DELETE FROM fundamental_data)
2. Re-executar bulk update com scrapers corrigidos
3. Validar confidence > 70%
4. Confirmar 0 outliers
```

---

## Monitoramento Cont√≠nuo

### Comando para Acompanhar Progresso

```bash
# Executar em terminal separado
docker logs invest_backend -f | grep -E "Successfully|Failed|Python fallback|confidence:"
```

### Queries de An√°lise

```sql
-- Progresso atual
SELECT COUNT(*) FROM fundamental_data WHERE updated_at > NOW() - INTERVAL '24 hours';

-- Bugs de valores
SELECT ticker, roe, margem_liquida, receita_liquida
FROM fundamental_data fd
JOIN assets a ON a.id = fd.asset_id
WHERE ABS(roe) > 100 OR receita_liquida > 1000000000000
ORDER BY updated_at DESC;

-- Confidence distribution
SELECT
    CASE
        WHEN (metadata->>'confidence')::numeric >= 0.70 THEN 'HIGH (70%+)'
        WHEN (metadata->>'confidence')::numeric >= 0.50 THEN 'MEDIUM (50-70%)'
        ELSE 'LOW (<50%)'
    END as confidence_bucket,
    COUNT(*) as count
FROM fundamental_data
WHERE updated_at > NOW() - INTERVAL '24 hours'
GROUP BY confidence_bucket;
```

---

## Pr√≥ximas Revis√µes

- **Ap√≥s 4h:** Verificar progresso (deve ter ~100 ativos)
- **Ap√≥s 12h:** Verificar progresso (deve ter ~300 ativos)
- **Ap√≥s 20h:** Coleta completa (861 ativos)
- **Ap√≥s 24h:** An√°lise consolidada + in√≠cio das corre√ß√µes

---

**Documentado por:** Claude Code
**Data:** 2025-12-22 17:07
**Status:** COLETA ATIVA - AGUARDANDO CONCLUS√ÉO
**Pr√≥xima A√ß√£o:** Monitorar progresso e aguardar 20h para an√°lise final
