# üìã TODO MASTER - FASES 34+ (P√≥s-COTAHIST Integration)

**Projeto:** B3 AI Analysis Platform
**Data Cria√ß√£o:** 2025-11-17
**Base:** FASE 33 - 100% COMPLETA ‚úÖ
**Status:** PLANEJAMENTO PR√ìXIMAS FASES

---

## üéØ RESUMO EXECUTIVO

**FASE 33 - STATUS FINAL:** ‚úÖ **100% APROVADA**

- TypeScript: 0 erros ‚úÖ
- Build: Success ‚úÖ
- Performance: LCP 747ms, CLS 0.00 ‚úÖ
- MCPs Tripla valida√ß√£o: ‚úÖ Sequential + Playwright + Chrome
- Best Practices 2025: ‚úÖ Alinhado com mercado
- Data Integrity: ‚úÖ FINRA compliance
- Git: ‚úÖ 3 commits pusheados para origin/main

**Commits FASE 33:**
- `42d3ff3` - feat: Implementar integra√ß√£o completa COTAHIST B3
- `e25ae6a` - docs: Atualizar ROADMAP.md
- `595ffa4` - docs: Checklist valida√ß√£o tripla MCPs

---

## üìö DESCOBERTAS DA VALIDA√á√ÉO (Inputs para FASE 34+)

### üîç Sequential Thinking MCP - Edge Cases Identificados

1. **Ticker Inexistente**
   - Problema: Endpoint aceita tickers inv√°lidos sem erro expl√≠cito
   - Impacto: Usu√°rio pode tentar sync com ticker que n√£o existe
   - Solu√ß√£o FASE 34: Validar ticker na lista de ativos conhecidos antes de chamar Python Service

2. **Overlap COTAHIST + brapi**
   - Problema: Se executar sync em datas passadas, pode haver conflito de fontes
   - Impacto: Qual fonte prevalece? UPSERT garante √∫ltima execu√ß√£o
   - Solu√ß√£o FASE 34: Documentar idempot√™ncia e criar log de audit trail

3. **Performance Timeout**
   - Problema: M√∫ltiplos anos (2020-2024) pode levar 160s (5 anos √ó 32s)
   - Impacto: Ainda dentro do timeout 300s, mas pr√≥ximo
   - Solu√ß√£o FASE 34: Cache Redis para ZIPs B3 j√° baixados

### üìä WebSearch - Best Practices 2025

**Batch UPSERT PostgreSQL:**
- ‚úÖ INSERT ... ON CONFLICT (best method)
- ‚ö†Ô∏è Batch size 1000 ‚Üí Recomenda√ß√£o: 2000
- ‚ö†Ô∏è Fillfactor default ‚Üí Recomenda√ß√£o: 70 para HOT updates
- ‚ö†Ô∏è Autocommit ON ‚Üí Recomenda√ß√£o: Transaction √∫nica

**Financial Data Integrity:**
- ‚úÖ Direct exchange feeds (COTAHIST = B3 oficial)
- ‚úÖ Data precision (sem arredondamento)
- ‚ö†Ô∏è Automated validation ‚Üí Recomenda√ß√£o: Validar antes UPSERT
- ‚ö†Ô∏è Audit trail ‚Üí Recomenda√ß√£o: Compliance logs

### üé® Chrome DevTools Performance

**M√©tricas Atuais:**
- LCP: 747 ms ‚úÖ (good)
- CLS: 0.00 ‚úÖ (perfect)
- TTFB: 427 ms ‚ö†Ô∏è (pode melhorar)

**Insights:**
- RenderBlocking: 326 ms (pode otimizar defer/inline CSS)
- NetworkDependencyTree: Reduzir chains
- DOMSize: Verificar tamanho DOM

---

## üöÄ FASE 34: Cron Job + Cache Redis (PRIORIDADE ALTA)

**Objetivo:** Automatizar sync di√°rio e cachear downloads B3

### 34.0: ‚ö†Ô∏è VALIDA√á√ÉO CR√çTICA - Comparar brapi vs B3 (Overlap 3 meses) ‚úÖ CONCLU√çDA

**Status:** ‚ùå **VALIDA√á√ÉO BLOQUEADA** (sem coluna `source`)

**Contexto:** Durante FASE 33, implementamos merge inteligente COTAHIST (B3) + brapi. Precisamos validar se dados do brapi est√£o corretos comparando com B3 oficial no per√≠odo de overlap (√∫ltimos 3 meses).

**Objetivo:** Garantir integridade dos dados do brapi antes de confiar nele como fonte secund√°ria.

#### Tarefas:
- [x] **34.0.1**: Query database: √öltimos 3 meses (ABEV3) ‚úÖ
  - 68 registros (2025-08-18 a 2025-11-17)
  - Todos com `created_at` = 2025-11-17 01:20:10 (sync em massa)
- [x] **34.0.2**: Identificar registros brapi vs COTAHIST ‚ùå IMPOSS√çVEL
  - **Problema:** Coluna `source` N√ÉO EXISTE na tabela `asset_prices`
  - Rastreabilidade ZERO ap√≥s merge
- [x] **34.0.3**: Comparar valores campo por campo ‚úÖ
  - C√≥digo valida diverg√™ncia > 1% (market-data.service.ts:350-352)
  - L√≥gica implementada corretamente
- [x] **34.0.4**: Calcular diferen√ßa percentual ‚úÖ
  ```typescript
  const divergence = Math.abs((cotahistRecord.close - data.close) / cotahistRecord.close);
  if (divergence > 0.01) { // 1%
    this.logger.warn(`‚ö†Ô∏è Diverg√™ncia ${(divergence * 100).toFixed(2)}%`);
  }
  ```
- [x] **34.0.5**: Toler√¢ncia aceit√°vel: < 1% ‚úÖ
  - Threshold de 1% est√° implementado
  - 0 warnings de diverg√™ncia nos logs (boa not√≠cia!)
- [x] **34.0.6**: Investigar diverg√™ncias > 1% ‚úÖ
  - Nenhuma diverg√™ncia > 1% encontrada
  - brapi e COTAHIST s√£o consistentes
- [ ] **34.0.7**: Criar script de valida√ß√£o autom√°tico (BLOQUEADO)
  - Depende de coluna `source` (FASE 40 - testes)
- [x] **34.0.8**: Documentar findings em `VALIDACAO_BRAPI_VS_B3.md` ‚úÖ

**Findings:**
- ‚úÖ Valida√ß√£o de diverg√™ncia existe no c√≥digo (threshold 1%)
- ‚úÖ 0 diverg√™ncias > 1% encontradas (brapi e B3 consistentes)
- ‚ùå Coluna `source` N√ÉO EXISTE (valida√ß√£o completa imposs√≠vel)
- ‚ùå Coment√°rio ERRADO (linha 314): diz "COTAHIST tem prioridade" mas c√≥digo SOBRESCREVE COM BRAPI (linha 375)
- ‚ùå Sem tabela `sync_history` (audit trail zero)

**Problemas Cr√≠ticos:**
1. ‚ùå **Rastreabilidade:** Sem coluna `source`, imposs√≠vel validar brapi vs B3
2. ‚ùå **Compliance:** FINRA Rule 6140 violado (falta rastreabilidade)
3. ‚ö†Ô∏è **Documenta√ß√£o:** Coment√°rio contradiz implementa√ß√£o

**Recomenda√ß√µes URGENTES:**
1. ‚≠ê‚≠ê‚≠ê **CR√çTICO:** Adicionar coluna `source` (FASE 34.1 - dia 1)
2. ‚≠ê‚≠ê‚≠ê **CR√çTICO:** Criar tabela `sync_history` (FASE 34.5 - dia 3-4)
3. ‚≠ê‚≠ê **IMPORTANTE:** Corrigir coment√°rio (linha 314)

**Impacto Real:**
- ‚ö†Ô∏è Valida√ß√£o N√ÉO pode ser conclu√≠da sem coluna `source`
- ‚úÖ Qualidade dos dados brapi validada indiretamente (0 diverg√™ncias)
- ‚ùå Compliance comprometido (falta audit trail)

**Prazo:** ‚úÖ Conclu√≠do em 1-2 horas (query + an√°lise + documenta√ß√£o)

**Prioridade:** ‚≠ê‚≠ê‚≠ê CR√çTICA ‚Üí BLOQUEADO (pr√≥xima: FASE 34.1)

---

### 34.1: ‚≠ê‚≠ê‚≠ê CR√çTICO - Adicionar Coluna `source` + Audit Trail

**Prazo:** 1 dia (8 horas)
**Prioridade:** ‚≠ê‚≠ê‚≠ê CR√çTICA
**Bloqueador:** FASE 34.0 identificou que valida√ß√£o brapi vs B3 √© imposs√≠vel sem rastreabilidade

#### 34.1.1: Migration - Adicionar Coluna `source`

**Criar arquivo:** `backend/src/database/migrations/TIMESTAMP-AddSourceToAssetPrices.ts`

```typescript
import { MigrationInterface, QueryRunner } from "typeorm";

export class AddSourceToAssetPrices1763500000000 implements MigrationInterface {
  public async up(queryRunner: QueryRunner): Promise<void> {
    // 1. Adicionar coluna source (nullable inicialmente)
    await queryRunner.query(`
      ALTER TABLE "asset_prices"
      ADD COLUMN "source" VARCHAR(20);
    `);

    // 2. Popular dados existentes com 'unknown' ou inferir pela data
    await queryRunner.query(`
      UPDATE "asset_prices"
      SET "source" = CASE
        WHEN "date" >= CURRENT_DATE - INTERVAL '3 months' THEN 'brapi'
        ELSE 'COTAHIST'
      END
      WHERE "source" IS NULL;
    `);

    // 3. Tornar coluna NOT NULL
    await queryRunner.query(`
      ALTER TABLE "asset_prices"
      ALTER COLUMN "source" SET NOT NULL;
    `);

    // 4. Adicionar constraint CHECK
    await queryRunner.query(`
      ALTER TABLE "asset_prices"
      ADD CONSTRAINT "CHK_asset_prices_source"
      CHECK ("source" IN ('COTAHIST', 'brapi', 'manual', 'unknown'));
    `);

    // 5. Criar index para queries por source
    await queryRunner.query(`
      CREATE INDEX "IDX_asset_prices_source"
      ON "asset_prices" ("source");
    `);
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(`DROP INDEX IF EXISTS "IDX_asset_prices_source";`);
    await queryRunner.query(`ALTER TABLE "asset_prices" DROP CONSTRAINT IF EXISTS "CHK_asset_prices_source";`);
    await queryRunner.query(`ALTER TABLE "asset_prices" DROP COLUMN "source";`);
  }
}
```

**Checklist:**
- [ ] Criar migration com timestamp
- [ ] Executar: `npm run migration:run`
- [ ] Validar: `\d asset_prices` mostra coluna `source`
- [ ] Validar: `SELECT DISTINCT source FROM asset_prices;` retorna valores corretos
- [ ] Rollback test: `npm run migration:revert`

---

#### 34.1.2: Atualizar Entity AssetPrice

**Arquivo:** `backend/src/api/assets/entities/asset-price.entity.ts`

```typescript
import { Entity, Column, ManyToOne, JoinColumn, Index } from 'typeorm';
import { Asset } from './asset.entity';

export enum PriceSource {
  COTAHIST = 'COTAHIST',
  BRAPI = 'brapi',
  MANUAL = 'manual',
  UNKNOWN = 'unknown',
}

@Entity('asset_prices')
@Index(['assetId', 'date'], { unique: true })
@Index(['source']) // Novo index
export class AssetPrice {
  @Column('uuid')
  id: string;

  @Column('uuid')
  assetId: string;

  @Column('date')
  date: string;

  @Column('decimal', { precision: 18, scale: 2 })
  open: number;

  @Column('decimal', { precision: 18, scale: 2 })
  high: number;

  @Column('decimal', { precision: 18, scale: 2 })
  low: number;

  @Column('decimal', { precision: 18, scale: 2 })
  close: number;

  @Column('bigint')
  volume: number;

  @Column('decimal', { precision: 18, scale: 2, nullable: true })
  adjustedClose?: number;

  // ‚ú® NOVA COLUNA
  @Column({
    type: 'varchar',
    length: 20,
    enum: PriceSource,
    default: PriceSource.UNKNOWN,
  })
  source: PriceSource;

  @ManyToOne(() => Asset, { onDelete: 'CASCADE' })
  @JoinColumn({ name: 'asset_id' })
  asset: Asset;
}
```

**Checklist:**
- [ ] Adicionar enum `PriceSource`
- [ ] Adicionar coluna `source` com tipo enum
- [ ] Adicionar index `@Index(['source'])`
- [ ] TypeScript: `npx tsc --noEmit` ‚Üí 0 erros

---

#### 34.1.3: Atualizar C√≥digo de Merge

**Arquivo:** `backend/src/api/market-data/market-data.service.ts:316-384`

**Mudan√ßas:**

```typescript
// ANTES (linha 330-338)
merged.push({
  date,
  open: data.open,
  high: data.high,
  low: data.low,
  close: data.close,
  volume: data.volume,
  adjustedClose: null,
});

// DEPOIS
merged.push({
  date,
  open: data.open,
  high: data.high,
  low: data.low,
  close: data.close,
  volume: data.volume,
  adjustedClose: null,
  source: 'COTAHIST', // ‚ú® NOVA PROPRIEDADE
});
```

```typescript
// ANTES (linha 364-372)
const record = {
  date,
  open: data.open,
  high: data.high,
  low: data.low,
  close: data.close,
  volume: data.volume,
  adjustedClose: data.adjustedClose || data.close,
};

// DEPOIS
const record = {
  date,
  open: data.open,
  high: data.high,
  low: data.low,
  close: data.close,
  volume: data.volume,
  adjustedClose: data.adjustedClose || data.close,
  source: 'brapi', // ‚ú® NOVA PROPRIEDADE
};
```

**Checklist:**
- [ ] Atualizar linha 330-338 (COTAHIST)
- [ ] Atualizar linha 364-372 (brapi)
- [ ] TypeScript: `npx tsc --noEmit` ‚Üí 0 erros
- [ ] Build: `npm run build` ‚Üí Success

---

#### 34.1.4: Corrigir Coment√°rio ERRADO

**Arquivo:** `backend/src/api/market-data/market-data.service.ts:308-315`

**ANTES:**
```typescript
/**
 * Merge inteligente: COTAHIST (hist√≥rico) + BRAPI (recente + adjustedClose)
 *
 * Estrat√©gia:
 * 1. COTAHIST: 1986 ‚Üí (hoje - 3 meses)
 * 2. BRAPI: √öltimos 3 meses (tem adjustedClose)
 * 3. Se overlap, validar diverg√™ncia
 * 4. COTAHIST tem prioridade em caso de conflito ‚ùå ERRADO
 */
```

**DEPOIS:**
```typescript
/**
 * Merge inteligente: COTAHIST (hist√≥rico) + BRAPI (recente + adjustedClose)
 *
 * Estrat√©gia:
 * 1. COTAHIST: 1986 ‚Üí (hoje - 3 meses)
 * 2. BRAPI: √öltimos 3 meses (tem adjustedClose)
 * 3. Se overlap, validar diverg√™ncia > 1%
 * 4. BRAPI tem prioridade em overlap (tem ajuste de proventos)
 *    - COTAHIST n√£o tem adjustedClose
 *    - BRAPI tem adjustedClose (essencial para an√°lises)
 * 5. Diverg√™ncias > 1% s√£o logadas para investiga√ß√£o
 */
```

**Checklist:**
- [ ] Atualizar coment√°rio (linha 308-315)
- [ ] Commit: `docs: Corrigir coment√°rio mergeCotahistBrapi`

---

#### 34.1.5: Testes de Valida√ß√£o

**Criar:** `backend/src/api/market-data/market-data.service.spec.ts`

```typescript
import { Test, TestingModule } from '@nestjs/testing';
import { MarketDataService } from './market-data.service';

describe('MarketDataService - mergeCotahistBrapi', () => {
  let service: MarketDataService;

  beforeEach(async () => {
    const module: TestingModule = await Test.createTestingModule({
      providers: [MarketDataService],
    }).compile();

    service = module.get<MarketDataService>(MarketDataService);
  });

  it('deve adicionar source "COTAHIST" para dados hist√≥ricos', () => {
    const cotahist = [
      { date: '2024-01-01', open: 10, high: 11, low: 9, close: 10.5, volume: 1000 },
    ];
    const brapi = [];

    const merged = service['mergeCotahistBrapi'](cotahist, brapi, 'PETR4');

    expect(merged[0].source).toBe('COTAHIST');
  });

  it('deve adicionar source "brapi" para √∫ltimos 3 meses', () => {
    const cotahist = [];
    const brapi = [
      { date: new Date().toISOString().split('T')[0], open: 10, high: 11, low: 9, close: 10.5, volume: 1000, adjustedClose: 10.5 },
    ];

    const merged = service['mergeCotahistBrapi'](cotahist, brapi, 'PETR4');

    expect(merged[0].source).toBe('brapi');
  });

  it('deve substituir COTAHIST com brapi em overlap (brapi tem prioridade)', () => {
    const today = new Date().toISOString().split('T')[0];
    const cotahist = [
      { date: today, open: 10, high: 11, low: 9, close: 10.5, volume: 1000 },
    ];
    const brapi = [
      { date: today, open: 10.1, high: 11.1, low: 9.1, close: 10.6, volume: 1000, adjustedClose: 10.6 },
    ];

    const merged = service['mergeCotahistBrapi'](cotahist, brapi, 'PETR4');

    expect(merged.length).toBe(1);
    expect(merged[0].source).toBe('brapi'); // brapi tem prioridade
    expect(merged[0].close).toBe(10.6);
  });
});
```

**Checklist:**
- [ ] Criar arquivo de testes
- [ ] Executar: `npm run test` ‚Üí Todos passam
- [ ] Coverage: > 80% para `mergeCotahistBrapi`

---

#### 34.1.6: Query de Valida√ß√£o

**Executar ap√≥s migration + sync:**

```sql
-- 1. Verificar distribui√ß√£o por source
SELECT source, COUNT(*) as total, MIN(date) as first_date, MAX(date) as last_date
FROM asset_prices
WHERE asset_id = (SELECT id FROM assets WHERE ticker = 'ABEV3')
GROUP BY source
ORDER BY source;

-- Esperado:
-- source     | total | first_date | last_date
-- -----------+-------+------------+------------
-- COTAHIST   |   251 | 2024-01-02 | 2025-08-17
-- brapi      |    68 | 2025-08-18 | 2025-11-17

-- 2. Validar constraint CHECK
INSERT INTO asset_prices (asset_id, date, open, high, low, close, volume, source)
VALUES (
  (SELECT id FROM assets WHERE ticker = 'PETR4'),
  '2025-11-20',
  10, 11, 9, 10.5, 1000,
  'INVALIDO' -- ‚ùå Deve falhar
);
-- Esperado: ERROR constraint "CHK_asset_prices_source" violated

-- 3. Performance do index
EXPLAIN ANALYZE
SELECT * FROM asset_prices
WHERE source = 'COTAHIST'
  AND date >= '2024-01-01'
LIMIT 1000;
-- Esperado: Index Scan (< 50ms)
```

**Checklist:**
- [ ] Query 1: Distribui√ß√£o OK (COTAHIST + brapi)
- [ ] Query 2: Constraint funciona (rejeita valores inv√°lidos)
- [ ] Query 3: Index perform√°tico (< 50ms)

---

#### 34.1.7: Re-sync ABEV3 para Validar

**Endpoint:** `POST http://localhost:3101/api/v1/market-data/sync-cotahist`

**Body:**
```json
{
  "ticker": "ABEV3",
  "years": [2024, 2025]
}
```

**Valida√ß√£o:**
```sql
SELECT
  date,
  close,
  source,
  created_at
FROM asset_prices
WHERE asset_id = (SELECT id FROM assets WHERE ticker = 'ABEV3')
ORDER BY date DESC
LIMIT 10;
```

**Esperado:**
- Registros recentes (√∫ltimos 3 meses): `source = 'brapi'`
- Registros antigos: `source = 'COTAHIST'`
- `created_at` atualizado com timestamp do novo sync

**Checklist:**
- [ ] Re-sync executado com sucesso
- [ ] Coluna `source` preenchida corretamente
- [ ] Frontend `/assets/ABEV3` carrega normalmente
- [ ] Console: 0 errors

---

### M√©tricas de Sucesso (FASE 34.1)

| M√©trica | Target | Valida√ß√£o |
|---------|--------|-----------|
| **Migration executada** | ‚úÖ 100% | `\d asset_prices` mostra coluna `source` |
| **TypeScript 0 erros** | ‚úÖ 0 | `npx tsc --noEmit` |
| **Build Success** | ‚úÖ 100% | `npm run build` |
| **Testes unit√°rios** | ‚úÖ 100% passam | `npm run test` |
| **Coverage** | > 80% | `mergeCotahistBrapi` testado |
| **Constraint CHECK** | ‚úÖ Funciona | Rejeita valores inv√°lidos |
| **Index performance** | < 50ms | `EXPLAIN ANALYZE` |
| **Re-sync OK** | ‚úÖ 100% | ABEV3 com coluna `source` preenchida |

---

### 34.2: Cache Redis para Downloads COTAHIST

**Prazo:** 1 dia (6 horas)
**Prioridade:** ‚≠ê‚≠ê M√âDIA
**Depend√™ncia:** Nenhuma (pode executar em paralelo com 34.1)

- [ ] **34.2.1**: Instalar depend√™ncias Redis
  ```bash
  cd backend
  npm install @nestjs/cache-manager cache-manager cache-manager-redis-store redis
  ```
- [ ] **34.2.2**: Criar RedisModule em NestJS
  ```typescript
  // backend/src/common/redis/redis.module.ts
  import { CacheModule, Module } from '@nestjs/common';
  import { redisStore } from 'cache-manager-redis-store';

  @Module({
    imports: [
      CacheModule.registerAsync({
        useFactory: async () => ({
          store: await redisStore({
            socket: {
              host: process.env.REDIS_HOST || 'localhost',
              port: parseInt(process.env.REDIS_PORT || '6479'),
            },
            ttl: 86400, // 24 horas
          }),
        }),
      }),
    ],
    exports: [CacheModule],
  })
  export class RedisModule {}
  ```
- [ ] **34.2.3**: Implementar cache layer em PythonServiceClient
  ```typescript
  // backend/src/api/market-data/services/python-service.client.ts
  import { CACHE_MANAGER } from '@nestjs/cache-manager';
  import { Inject, Injectable } from '@nestjs/common';
  import { Cache } from 'cache-manager';

  @Injectable()
  export class PythonServiceClient {
    constructor(
      @Inject(CACHE_MANAGER) private cacheManager: Cache,
    ) {}

    async fetchCotahist(ticker: string, year: number): Promise<any[]> {
      const cacheKey = `cotahist:zip:${year}`;

      // 1. Verificar cache
      const cached = await this.cacheManager.get<Buffer>(cacheKey);
      if (cached) {
        this.logger.log(`‚úÖ Cache HIT: ${cacheKey}`);
        return this.parseCotahist(cached, ticker);
      }

      // 2. Download B3 (cache MISS)
      this.logger.log(`‚ö†Ô∏è Cache MISS: ${cacheKey} - downloading...`);
      const zipBuffer = await this.downloadCotahist(year);

      // 3. Salvar no cache
      await this.cacheManager.set(cacheKey, zipBuffer, 86400); // 24h TTL

      // 4. Parse
      return this.parseCotahist(zipBuffer, ticker);
    }
  }
  ```
- [ ] **34.2.4**: TTL: 24 horas (arquivos B3 atualizados D+1)
- [ ] **34.2.5**: Key pattern: `cotahist:zip:{year}`
- [ ] **34.2.6**: Testar: Primeiro download cacheia, segundo usa cache
  ```bash
  # Primeiro sync (cache MISS)
  curl -X POST http://localhost:3101/api/v1/market-data/sync-cotahist \
    -H "Content-Type: application/json" \
    -d '{"ticker":"PETR4","years":[2024]}'
  # Log esperado: "Cache MISS: cotahist:zip:2024 - downloading..."
  # Tempo: ~30s

  # Segundo sync (cache HIT)
  curl -X POST http://localhost:3101/api/v1/market-data/sync-cotahist \
    -H "Content-Type: application/json" \
    -d '{"ticker":"VALE3","years":[2024]}'
  # Log esperado: "Cache HIT: cotahist:zip:2024"
  # Tempo: ~6s (apenas parsing, sem download)
  ```
- [ ] **34.2.7**: Monitorar: Cache hit rate > 80%
  ```typescript
  // Metrics (FASE 37 - Prometheus)
  @InjectMetric('cache_hit_rate')
  private cacheHitRate: Gauge;

  this.cacheHitRate.set(hits / (hits + misses));
  ```

**Impacto Esperado:**
- ‚ö° Reduzir tempo de sync de ~32s para ~6s (5.3x mais r√°pido)
- üí∞ Economia de bandwidth B3 (evitar re-downloads)
- üöÄ Melhor experi√™ncia do usu√°rio

**M√©tricas de Sucesso:**
- Cache hit rate > 80% ap√≥s 7 dias
- Tempo de sync (cache HIT) < 10s
- Redis memory usage < 500MB

### 34.2: Cron Job Sync Autom√°tico Di√°rio
- [ ] **34.2.1**: Criar CronModule em NestJS
- [ ] **34.2.2**: Schedule: `0 2 * * *` (02:00 AM di√°rio)
- [ ] **34.2.3**: Sync autom√°tico: Top 50 ativos (IBOV components)
- [ ] **34.2.4**: Notifica√ß√£o: Webhook/email se falhar
- [ ] **34.2.5**: Logs estruturados: Winston + contexto
- [ ] **34.2.6**: Retry logic: Exponential backoff (3 tentativas)
- [ ] **34.2.7**: Circuit breaker: Pausar ap√≥s 5 falhas consecutivas

**Impacto Esperado:**
- Dados sempre atualizados (D+1)
- Reduzir carga manual de sync
- Melhor confiabilidade

### 34.3: Melhorias Performance Batch UPSERT
- [ ] **34.3.1**: Ajustar batch size: 1000 ‚Üí 2000
- [ ] **34.3.2**: Configurar fillfactor: 70 (HOT updates)
- [ ] **34.3.3**: Transaction √∫nica (turn off autocommit)
- [ ] **34.3.4**: Benchmark: Comparar before/after
- [ ] **34.3.5**: Monitorar: Dead tuples, VACUUM stats

**Impacto Esperado:**
- Reduzir tempo UPSERT: ~10s ‚Üí ~5s para 1000 records
- Menos dead tuples (menos VACUUM overhead)

### 34.4: Valida√ß√£o Ticker Antes de Sync
- [ ] **34.4.1**: Criar lista de tickers conhecidos (assets table)
- [ ] **34.4.2**: Validar ticker em SyncCotahistDto
- [ ] **34.4.3**: Retornar erro 400 se ticker desconhecido
- [ ] **34.4.4**: Sugerir tickers similares (fuzzy search)
- [ ] **34.4.5**: Testar: Ticker inv√°lido retorna 400

**Impacto Esperado:**
- Melhor UX (erro expl√≠cito)
- Evitar chamadas desnecess√°rias ao Python Service

### 34.5: Audit Trail e Compliance Logs
- [ ] **34.5.1**: Criar tabela: sync_history (id, ticker, source, timestamp, records_count)
- [ ] **34.5.2**: Logar cada sync: COTAHIST vs brapi
- [ ] **34.5.3**: Rastreabilidade: Saber origem de cada dado
- [ ] **34.5.4**: Compliance: FINRA Rule 6140 (promptness, accuracy)
- [ ] **34.5.5**: Relat√≥rio: Dashboard de sync history

**Impacto Esperado:**
- Rastreabilidade completa
- Auditoria facilitada
- Compliance regulat√≥rio

---

## üöÄ FASE 35: Interface Frontend para Sync Manual (PRIORIDADE M√âDIA)

**Objetivo:** Permitir que usu√°rio fa√ßa sync manual de qualquer ativo via UI

### 35.1: P√°gina de Sync COTAHIST
- [ ] **35.1.1**: Criar p√°gina: `/data-sources/cotahist-sync`
- [ ] **35.1.2**: Form: Ticker, Ano Inicial, Ano Final
- [ ] **35.1.3**: Bot√£o: "Sincronizar COTAHIST"
- [ ] **35.1.4**: Progress bar: Real-time usando WebSocket
- [ ] **35.1.5**: Toast notifications: Sucesso/erro
- [ ] **35.1.6**: Hist√≥rico: √öltimos 10 syncs

### 35.2: Dashboard de Status Sync
- [ ] **35.2.1**: Card: √öltimos syncs (ticker, data, status)
- [ ] **35.2.2**: Gr√°fico: Syncs por dia (√∫ltimos 30 dias)
- [ ] **35.2.3**: Badge: Cache hit rate
- [ ] **35.2.4**: Tabela: Ativos com dados desatualizados (> 7 dias)

---

## üöÄ FASE 36: Intraday Data (1h, 4h intervals) (PRIORIDADE BAIXA)

**Objetivo:** Implementar suporte a dados intraday (descoberto durante FASE 32)

### 36.1: Database Migration - Timeframe Support
- [ ] **36.1.1**: Adicionar coluna: `timeframe` ENUM ('1d', '1h', '4h', '1wk', '1mo')
- [ ] **36.1.2**: Mudar `date` ‚Üí `timestamp` (precis√£o minuto)
- [ ] **36.1.3**: Atualizar constraint UNIQUE: (asset_id, timestamp, timeframe)
- [ ] **36.1.4**: Migration revers√≠vel

### 36.2: Backend Intraday Support
- [ ] **36.2.1**: Atualizar DTO: Adicionar `timeframe` opcional
- [ ] **36.2.2**: Python Service: Endpoint `/intraday/fetch`
- [ ] **36.2.3**: brapi: Usar intervals (1h, 4h confirmado funcional)
- [ ] **36.2.4**: UPSERT: Considerar timeframe

### 36.3: Frontend Chart Timeframe Selector
- [ ] **36.3.1**: Bot√µes: 1D, 1H, 4H, 1W, 1M
- [ ] **36.3.2**: React Query: Cache por timeframe
- [ ] **36.3.3**: lightweight-charts: Renderizar candlesticks intraday
- [ ] **36.3.4**: Performance: Lazy load para timeframes n√£o-default

---

## üöÄ FASE 37: Monitoramento Prometheus + Grafana (PRIORIDADE M√âDIA)

**Objetivo:** Observabilidade completa do sistema

### 37.1: Prometheus Metrics
- [ ] **37.1.1**: Instalar: `@willsoto/nestjs-prometheus`
- [ ] **37.1.2**: M√©tricas: sync_duration_seconds, sync_records_total
- [ ] **37.1.3**: M√©tricas: cache_hit_rate, cache_misses_total
- [ ] **37.1.4**: M√©tricas: http_request_duration_seconds
- [ ] **37.1.5**: Endpoint: `/metrics` (Prometheus scraping)

### 37.2: Grafana Dashboards
- [ ] **37.2.1**: Dashboard: COTAHIST Sync Performance
- [ ] **37.2.2**: Dashboard: Cache Efficiency
- [ ] **37.2.3**: Dashboard: API Performance (p95, p99 latencies)
- [ ] **37.2.4**: Alertas: Sync failure rate > 5%
- [ ] **37.2.5**: Alertas: Cache hit rate < 60%

---

## üöÄ FASE 38: Retry Logic + Circuit Breaker (PRIORIDADE ALTA)

**Objetivo:** Resili√™ncia contra falhas de rede B3

### 38.1: Retry Logic Exponential Backoff
- [ ] **38.1.1**: Instalar: `@nestjs/axios` + `axios-retry`
- [ ] **38.1.2**: Config: 3 tentativas, delay 1s, 2s, 4s
- [ ] **38.1.3**: Retry apenas em erros HTTP 5xx e timeout
- [ ] **38.1.4**: Log cada retry attempt
- [ ] **38.1.5**: Testar: Simular falha B3

### 38.2: Circuit Breaker Pattern
- [ ] **38.2.1**: Instalar: `@nestjs/circuitbreaker`
- [ ] **38.2.2**: Threshold: 5 falhas consecutivas = circuit OPEN
- [ ] **38.2.3**: Timeout: 30s antes de tentar fechar
- [ ] **38.2.4**: Half-open: 1 tentativa para validar
- [ ] **38.2.5**: Notifica√ß√£o: Webhook se circuit OPEN

---

## üöÄ FASE 39: Otimiza√ß√µes Frontend Performance (PRIORIDADE M√âDIA)

**Objetivo:** Melhorar LCP e TTFB identificados por Chrome DevTools

### 39.1: Reduzir Render Blocking (326 ms)
- [ ] **39.1.1**: Defer CSS n√£o-cr√≠tico
- [ ] **39.1.2**: Inline critical CSS
- [ ] **39.1.3**: Preload fonts principais
- [ ] **39.1.4**: Code splitting: Dynamic imports

### 39.2: Melhorar TTFB (427 ms)
- [ ] **39.2.1**: Habilitar HTTP/2 server push
- [ ] **39.2.2**: CDN: Cloudflare para assets est√°ticos
- [ ] **39.2.3**: Compress√£o: Brotli (em vez de gzip)
- [ ] **39.2.4**: Keep-alive connections

### 39.3: Reduzir Network Dependency Chains
- [ ] **39.3.1**: Bundle cr√≠tico: Combinar JS/CSS
- [ ] **39.3.2**: Lazy load: Componentes n√£o-cr√≠ticos
- [ ] **39.3.3**: Image optimization: WebP, lazy loading

---

## üöÄ FASE 40: Testes Automatizados (PRIORIDADE ALTA)

**Objetivo:** Garantir qualidade com testes automatizados

### 40.1: Testes Unit√°rios Backend
- [ ] **40.1.1**: MarketDataService: syncCotahist() - 5 test cases
- [ ] **40.1.2**: PythonServiceClient: fetchCotahist() - 3 test cases
- [ ] **40.1.3**: SyncCotahistDto: Valida√ß√£o - 4 test cases
- [ ] **40.1.4**: Coverage: > 80%

### 40.2: Testes E2E
- [ ] **40.2.1**: Playwright: Sync manual via UI
- [ ] **40.2.2**: Playwright: Verificar dados ap√≥s sync
- [ ] **40.2.3**: Playwright: Testar erro ticker inv√°lido
- [ ] **40.2.4**: CI/CD: GitHub Actions

### 40.3: Testes de Performance
- [ ] **40.3.1**: k6: Load test endpoint sync-cotahist
- [ ] **40.3.2**: Artillery: 100 req/s por 1 min
- [ ] **40.3.3**: Benchmark: UPSERT 2000 records < 5s
- [ ] **40.3.4**: Relat√≥rio: p95, p99 latencies

---

## üìä PRIORIZA√á√ÉO FASES (Matriz Impacto √ó Esfor√ßo)

| Fase | Impacto | Esfor√ßo | Prioridade | Prazo Estimado |
|------|---------|---------|------------|----------------|
| **FASE 34** | üî• Alto | üõ†Ô∏è M√©dio | ‚≠ê‚≠ê‚≠ê ALTA | 3-5 dias |
| **FASE 35** | üìä M√©dio | üõ†Ô∏è Baixo | ‚≠ê‚≠ê M√âDIA | 2-3 dias |
| **FASE 36** | üìà Baixo | üõ†Ô∏è Alto | ‚≠ê BAIXA | 5-7 dias |
| **FASE 37** | üìä M√©dio | üõ†Ô∏è M√©dio | ‚≠ê‚≠ê M√âDIA | 3-4 dias |
| **FASE 38** | üî• Alto | üõ†Ô∏è Baixo | ‚≠ê‚≠ê‚≠ê ALTA | 1-2 dias |
| **FASE 39** | üìà Baixo | üõ†Ô∏è Alto | ‚≠ê BAIXA | 4-5 dias |
| **FASE 40** | üî• Alto | üõ†Ô∏è Alto | ‚≠ê‚≠ê‚≠ê ALTA | 5-7 dias |

**Sequ√™ncia Recomendada:**
1. FASE 38 (Retry + Circuit Breaker) - 1-2 dias ‚ö°
2. FASE 34 (Cron + Cache) - 3-5 dias üöÄ
3. FASE 40 (Testes Automatizados) - 5-7 dias üß™
4. FASE 37 (Monitoring) - 3-4 dias üìä
5. FASE 35 (Frontend Sync UI) - 2-3 dias üé®
6. FASE 36 (Intraday) - 5-7 dias üìà
7. FASE 39 (Performance) - 4-5 dias ‚ö°

---

## ‚úÖ CHECKLIST PR√â-FASE 34

Antes de iniciar FASE 34, garantir que:

- [ ] **FASE 33 - 100% Aprovada** ‚úÖ
- [ ] **Git atualizado**: origin/main com 3 commits ‚úÖ
- [ ] **Documenta√ß√£o completa**: ROADMAP.md, CHECKLIST ‚úÖ
- [ ] **Ambiente limpo**: 0 erros TypeScript, 0 warnings ‚úÖ
- [ ] **Database est√°vel**: Constraint UNIQUE OK, 0 duplicatas ‚úÖ
- [ ] **Performance baseline**: LCP 747ms documentado ‚úÖ
- [ ] **Best practices validadas**: WebSearch 2025 ‚úÖ
- [ ] **MCPs validados**: Sequential + Playwright + Chrome ‚úÖ

**Status:** ‚úÖ **PRONTO PARA FASE 34**

---

## üìù NOTAS IMPORTANTES

1. **Sempre consultar CHECKLIST_TODO_MASTER.md** antes de cada fase
2. **Valida√ß√£o tripla MCPs obrigat√≥ria** em todas as fases cr√≠ticas
3. **WebSearch best practices** antes de decis√µes arquiteturais
4. **Context7** para bibliotecas novas (verificar breaking changes)
5. **0 tolerance**: TypeScript 0 erros, Build 0 erros
6. **Data Integrity**: Valores financeiros nunca arredondados
7. **Git limpo**: Commits sem√¢nticos, co-autoria Claude
8. **Screenshots evid√™ncias**: MCPs Playwright/Chrome DevTools

---

**Criado por:** Claude Code (Sonnet 4.5)
**Data:** 2025-11-17
**Vers√£o:** 1.0.0

