# Relat√≥rio de Investiga√ß√£o - Scrapers Alternativos

**Data:** 2025-11-27
**Executor:** Claude Code
**Objetivo:** Investigar scrapers para ativos sem dados

---

## üîç Problema Identificado

**Apenas 2 de 30 scrapers est√£o ativos**, causando falta de dados para muitos ativos.

### Status Atual dos Scrapers

| Status | Quantidade | Scrapers |
|--------|-----------|----------|
| ‚úÖ **Ativos (migrados)** | 2 | FundamentusScraper, BCBScraper |
| ‚ö†Ô∏è **Migrado mas desabilitado** | 1 | ADVFNScraper |
| ‚ùå **Pendentes (Selenium)** | 24 | StatusInvest, Investidor10, B3, e outros |
| ‚úîÔ∏è **API-only (OK)** | 4 | ANBIMA, FRED, IPEAData, CoinMarketCap |

---

## üö® Scrapers CR√çTICOS Pendentes de Migra√ß√£o

### 1. StatusInvestScraper ‚≠ê‚≠ê‚≠ê
- **Import√¢ncia:** ALTA - Dados fundamentalistas completos
- **Status:** ‚ùå Usando Selenium
- **Requer Login:** N√ÉO (p√∫blico)
- **Complexidade de Migra√ß√£o:** BAIXA
- **Fonte:** https://statusinvest.com.br/acoes/
- **Dados Fornecidos:**
  - P/L, P/VP, ROE, ROIC
  - Dividend Yield
  - Indicadores fundamentalistas
  - Rankings e compara√ß√µes

### 2. B3Scraper ‚≠ê‚≠ê‚≠ê
- **Import√¢ncia:** ALTA - Fonte oficial da bolsa
- **Status:** ‚ùå Usando Selenium
- **Requer Login:** N√ÉO (p√∫blico)
- **Complexidade de Migra√ß√£o:** M√âDIA
- **Fonte:** https://www.b3.com.br/
- **Dados Fornecidos:**
  - Dados oficiais da empresa
  - Informa√ß√µes de listagem
  - √öltimos neg√≥cios
  - Informa√ß√µes corporativas

### 3. Investidor10Scraper ‚≠ê‚≠ê
- **Import√¢ncia:** M√âDIA-ALTA - Rankings e an√°lise detalhada
- **Status:** ‚ùå Usando Selenium
- **Requer Login:** SIM (Google OAuth)
- **Complexidade de Migra√ß√£o:** ALTA (OAuth)
- **Fonte:** https://investidor10.com.br/
- **Dados Fornecidos:**
  - An√°lise fundamentalista completa
  - Rankings setoriais
  - Scores de qualidade
  - Hist√≥rico de dividendos

### 4. ADVFNScraper ‚ö†Ô∏è
- **Import√¢ncia:** M√âDIA - An√°lise t√©cnica e indicadores
- **Status:** ‚úÖ J√Å MIGRADO mas DESABILITADO
- **Requer Login:** SIM (Google OAuth)
- **Complexidade:** ZERO (apenas habilitar)
- **Fonte:** https://br.advfn.com/
- **Dados Fornecidos:**
  - Cota√ß√µes em tempo real
  - An√°lise t√©cnica
  - Indicadores de mercado
  - Raz√µes financeiras

---

## üìä An√°lise de Cobertura Atual

### Cobertura de Dados por Tipo

| Tipo de Dado | Scrapers Ativos | Scrapers Dispon√≠veis (migrados) | Scrapers Potenciais (pendentes) |
|--------------|----------------|--------------------------------|--------------------------------|
| **Pre√ßo Atual** | 1 (Fundamentus) | 2 (+ADVFN) | 5 (+StatusInvest, B3, Investidor10) |
| **Dados Fundamentalistas** | 1 (Fundamentus) | 2 (+ADVFN) | 3 (+StatusInvest, Investidor10) |
| **Informa√ß√µes Oficiais** | 0 | 0 | 1 (+B3) |
| **An√°lise T√©cnica** | 0 | 1 (+ADVFN) | 2 (+TradingView, Investing) |
| **Dividendos** | 1 (Fundamentus) | 1 | 2 (+Investidor10, StatusInvest) |
| **Market Cap/Volume** | 1 (Fundamentus) | 2 (+ADVFN) | 3 (+StatusInvest, B3) |

### Cross-Validation

**Situa√ß√£o Atual:**
- ‚úÖ BCBScraper: Dados macroecon√¥micos (Selic, IPCA, etc.)
- ‚úÖ FundamentusScraper: Dados fundamentalistas de a√ß√µes

**Problema:**
- ‚ùå **Sem cross-validation** - Apenas 1 fonte para cada tipo de dado
- ‚ùå **Pol√≠tica de 3 fontes N√ÉO atendida** (`.gemini/context/financial-rules.md`)

**Com scrapers adicionais:**
- ‚úÖ Pre√ßo: 3+ fontes (Fundamentus, ADVFN, StatusInvest)
- ‚úÖ Fundamentalistas: 3+ fontes (Fundamentus, ADVFN, StatusInvest)
- ‚úÖ Dados oficiais: 1 fonte autoritativa (B3)

---

## üéØ Plano de A√ß√£o Recomendado

### FASE 1: A√ß√£o Imediata (0 esfor√ßo) ‚ö°

**Objetivo:** Ativar scraper j√° migrado

1. ‚úÖ Habilitar ADVFNScraper em `__init__.py`
2. ‚úÖ Testar scraping com ticker de exemplo (PETR4)
3. ‚úÖ Validar dados retornados
4. ‚úÖ Verificar se Google OAuth cookies est√£o dispon√≠veis

**Resultado esperado:** +1 fonte de dados (total: 3 scrapers ativos)

---

### FASE 2: Migra√ß√£o Priorit√°ria (baixa complexidade) üöÄ

**Objetivo:** Migrar scrapers p√∫blicos (sem login)

#### 2.1. StatusInvestScraper
- **Esfor√ßo:** 1-2 horas
- **Complexidade:** BAIXA (p√∫blico, sem login)
- **Impacto:** ALTO (dados fundamentalistas completos)
- **Passos:**
  1. Converter Selenium ‚Üí Playwright usando guia de migra√ß√£o
  2. Testar com 5+ tickers (PETR4, VALE3, ITUB4, ABEV3, BBDC4)
  3. Validar dados extra√≠dos
  4. Habilitar em `__init__.py`

#### 2.2. B3Scraper
- **Esfor√ßo:** 2-3 horas
- **Complexidade:** M√âDIA (site oficial com estrutura complexa)
- **Impacto:** ALTO (dados oficiais autoritativos)
- **Passos:**
  1. Converter Selenium ‚Üí Playwright
  2. Adaptar l√≥gica de busca por CVM code
  3. Testar com 5+ tickers
  4. Validar dados extra√≠dos
  5. Habilitar em `__init__.py`

**Resultado esperado:** +2 fontes (total: 5 scrapers ativos)

---

### FASE 3: Migra√ß√£o Avan√ßada (alta complexidade) üîê

**Objetivo:** Migrar scrapers que requerem autentica√ß√£o

#### 3.1. Investidor10Scraper
- **Esfor√ßo:** 3-4 horas
- **Complexidade:** ALTA (Google OAuth + estrutura complexa)
- **Impacto:** M√âDIO-ALTO (dados premium)
- **Pr√©-requisitos:**
  - Google OAuth cookies v√°lidos em `/app/browser-profiles/google_cookies.pkl`
  - Teste de login funcional
- **Passos:**
  1. Converter Selenium ‚Üí Playwright
  2. Adaptar l√≥gica de cookies OAuth
  3. Implementar verifica√ß√£o de login
  4. Testar com 5+ tickers
  5. Validar dados extra√≠dos
  6. Habilitar em `__init__.py`

**Resultado esperado:** +1 fonte premium (total: 6 scrapers ativos)

---

### FASE 4: Scrapers Complementares (opcional) üìà

**Objetivo:** Adicionar fontes adicionais para cross-validation

- **FundamenteiScraper** - Dados fundamentalistas alternativos
- **InvestingScraper** - Dados internacionais e an√°lise t√©cnica
- **TradingViewScraper** - An√°lise t√©cnica avan√ßada
- **GoogleFinanceScraper** - Dados de mercado Google

**Esfor√ßo total:** 8-12 horas
**Impacto:** M√âDIO (fontes adicionais para cross-validation)

---

## üîß Ferramentas Dispon√≠veis

### Script de Migra√ß√£o Autom√°tica
**Arquivo:** `backend/python-scrapers/migrate_selenium_to_playwright.py`

**Capacidades:**
- Convers√£o autom√°tica de imports Selenium ‚Üí Playwright
- Substitui√ß√£o de `driver` por `page`
- Convers√£o de seletores (By.CSS_SELECTOR, By.XPATH, etc.)
- Convers√£o de opera√ß√µes (get, find_element, text, click, etc.)

### Documenta√ß√£o
- **Guia Completo:** `backend/python-scrapers/SELENIUM_TO_PLAYWRIGHT_MIGRATION.md`
- **Relat√≥rio de Status:** `backend/python-scrapers/MIGRATION_REPORT.md`
- **Base Scraper:** `backend/python-scrapers/base_scraper.py` (j√° migrado)

---

## üìã Checklist de Implementa√ß√£o

### FASE 1: Habilitar ADVFN ‚úÖ
- [ ] Descomentar import de ADVFNScraper em `__init__.py`
- [ ] Testar scraping com PETR4
- [ ] Verificar se Google OAuth cookies existem
- [ ] Validar dados retornados
- [ ] Commit com mensagem descritiva

### FASE 2.1: Migrar StatusInvest ‚è≥
- [ ] Criar backup do arquivo original
- [ ] Executar script de migra√ß√£o ou converter manualmente
- [ ] Remover imports de Selenium
- [ ] Converter `self.driver` ‚Üí `self.page`
- [ ] Converter `driver.get()` ‚Üí `await page.goto()`
- [ ] Converter `find_element()` ‚Üí `await page.query_selector()`
- [ ] Converter `elem.text` ‚Üí `await elem.text_content()`
- [ ] Adicionar `await` em todas opera√ß√µes I/O
- [ ] Testar com 5+ tickers
- [ ] Validar TypeScript compila√ß√£o (backend)
- [ ] Habilitar em `__init__.py`
- [ ] Commit

### FASE 2.2: Migrar B3 ‚è≥
- [ ] Criar backup do arquivo original
- [ ] Executar script de migra√ß√£o ou converter manualmente
- [ ] Remover imports de Selenium
- [ ] Converter opera√ß√µes de driver
- [ ] Adaptar l√≥gica de busca por CVM code
- [ ] Testar com 5+ tickers
- [ ] Validar dados oficiais
- [ ] Habilitar em `__init__.py`
- [ ] Commit

### FASE 3: Migrar Investidor10 ‚è≥
- [ ] Verificar cookies OAuth dispon√≠veis
- [ ] Criar backup do arquivo original
- [ ] Converter para Playwright
- [ ] Adaptar l√≥gica de cookies
- [ ] Implementar verifica√ß√£o de login
- [ ] Testar autentica√ß√£o
- [ ] Testar com 5+ tickers
- [ ] Habilitar em `__init__.py`
- [ ] Commit

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√µes

### Risco 1: Scrapers quebrados ap√≥s migra√ß√£o
**Probabilidade:** M√âDIA
**Impacto:** ALTO
**Mitiga√ß√£o:**
- ‚úÖ Criar backups antes de modificar
- ‚úÖ Testar com m√∫ltiplos tickers antes de habilitar
- ‚úÖ Validar dados extra√≠dos comparando com Fundamentus
- ‚úÖ Habilitar um scraper por vez

### Risco 2: Google OAuth cookies inv√°lidos/expirados
**Probabilidade:** ALTA
**Impacto:** ALTO (para scrapers com login)
**Mitiga√ß√£o:**
- ‚ö†Ô∏è Verificar exist√™ncia de `/app/browser-profiles/google_cookies.pkl`
- ‚ö†Ô∏è Testar login antes de migrar scrapers OAuth
- ‚ö†Ô∏è Implementar fallback gracioso (tentar sem login)
- ‚ö†Ô∏è Documentar processo de obten√ß√£o de cookies

### Risco 3: Mudan√ßas na estrutura dos sites
**Probabilidade:** BAIXA-M√âDIA
**Impacto:** M√âDIO
**Mitiga√ß√£o:**
- ‚úÖ Usar m√∫ltiplos seletores (fallbacks)
- ‚úÖ Implementar error handling robusto
- ‚úÖ Logging detalhado de falhas
- ‚úÖ Cross-validation com outras fontes

---

## üìà Benef√≠cios Esperados

### Cobertura de Dados
- **Atual:** 2 scrapers ativos (20-30% cobertura)
- **Fase 1:** 3 scrapers (40-50% cobertura)
- **Fase 2:** 5 scrapers (70-80% cobertura)
- **Fase 3:** 6+ scrapers (85-95% cobertura)

### Cross-Validation
- **Atual:** ‚ùå Sem cross-validation (1 fonte)
- **Ap√≥s Fase 2:** ‚úÖ 3+ fontes para pre√ßo e fundamentalistas
- **Ap√≥s Fase 3:** ‚úÖ 4+ fontes premium

### Confiabilidade
- **Atual:** Dados de apenas 1 fonte (risco alto)
- **Ap√≥s Fases:** Consenso de m√∫ltiplas fontes (risco baixo)
- **Detec√ß√£o de outliers:** Automatizada com 3+ fontes

---

## üèÅ Pr√≥ximos Passos Imediatos

1. **AGORA:** Habilitar ADVFNScraper (5 minutos)
2. **Hoje:** Migrar StatusInvestScraper (1-2 horas)
3. **Amanh√£:** Migrar B3Scraper (2-3 horas)
4. **Esta Semana:** Migrar Investidor10Scraper (3-4 horas)

---

**Desenvolvido com:** Claude Code
**Co-Authored-By:** Claude <noreply@anthropic.com>
